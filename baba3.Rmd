---
title: '馬場本'
author: "Toshihide Imaruoka"
output:
  rmdformats::downcute:
    highlight: kate
    css: mycss.css
    dev: "ragg_png"
---
# 3章

# 3-1章: 一般化線形モデルの基本
## 1. 目的と概要
  * 一般化線形モデル(GLM): 実践的モデル & 複雑なモデルの部品
  * 確率分布、線形予測子、リンク関数
  * リファレンス的に使える章

## 2. 複雑なモデルを構築する際の手続きの標準化
  * モデルをどう構築するか
  * ビールの売り上げの例
    * $y \sim Normal(\mu,\sigma^2)$
    * これを複雑にしようとしたとき、"勝手に"やるばかりだと非効率かも
    * 「モデルの方」「フレームワーク」
  * 一般化線形モデルにおけるモデルの変更手続き
    1. 確率分布を変える
    2. 線形予測子を変える
    3. リンク関数を変える

## 3. 確率分布・線形予測子・リンク関数
  * 確率分布
    * 観測データを生む確率的過程を表現するためのもの。データに合わせて変える。
      * ビールなら正規分布
      * 小動物の数ならポアソン分布
      * 購入比率なら二項分布
  * 変数
    * 応答変数・従属変数
    * 説明変数
  * 線形予測子
    * 説明変数の線型結合
  * リンク関数
    * 応答変数と線形予測子を関係付けること
  
## 4. 一般化線形モデルの例: 説明変数が無く、正規分布を仮定するモデル
  * ビール売り上げの例
    * 凡例
      * $y_i$:売り上げデータ
      * $\mu_i$: $y_i$の期待値
      * $_i$: 何番目のデータか
      * $g$: 恒等関数（$g(y)=y$となる関数=何も起きない関数）
    * 一般化線形モデル
      * $g(\mu_i)=\beta_0$
      * $y_i \sim Normal(\mu, \sigma^2)$
      * $\beta_0$が線形予測子、恒等関数$g()$がリンク関数
    * 書き換え
      * $\mu_i=\beta_0$
      * $y_i \sim Normal(\mu, \sigma^2)$
    * 従属変数の平均値$\mu_i$が値$\beta_0$をとることを想定したモデル
    
## 5. 単回帰モデル: 説明変数が1つだけあり、正規分布を仮定するモデル
  * ビールの売り上げが気温$x$によって変化するというモデル
    * $g(\mu_i)=\beta_0+\beta_1x_i$
    * $y_i \sim Normal(\mu_i, \sigma^2)$
    * $\beta_0+\beta_1x_i$が線形予測子、恒等関数$g()$がリンク関数
  * 書き換え
    * $\mu_i = \beta_0 + \beta_1x_i$
    * $y_i \sim Normal(\mu_i, \sigma^2)$
  * 気温$x$が1変化すると$\beta_1$増減する
  * 単回帰モデル
    * $\beta_0$を切片
    * $\beta_1$を$x$の係数・傾き
  * 単回帰モデルを使うことで..
    * 説明変数と従属変数の関係の考察
    * 従属変数の予測
  
## 6. 分散分析モデル：ダミー変数を利用するモデル
  * 説明変数が質的変数のとき
    * ダミー変数を使う必要性
      * ダミー変数：0 / 1
      * 晴れ・雨・曇りを表現する
        * 晴れ：0/1
        * 雨: 0/1
      * 状態-1の変数
        * 1 0 -> 晴れ
        * 0 1 -> 雨
        * 0 0 -> 曇り
  * ビールの例
    * 売上が天気の影響を受ける
      * $x_1$:晴れなら1, $x_2$: 雨なら1, $g()$: 恒等関数
        * $g(\mu_i)=\beta_0+\beta_1x_{i1}+\beta_{i2}$
        * y \sim Normal(\mu_i, \sigma^2)
      * 書き換え
        *  $\mu_i=\beta_0+\beta_1x_{i1}+\beta_{i2}$
      * 分散分析モデル
        * 説明変数が質的データ
        * 確率分布として正規分布
        
## 7. 正規線形モデル：正規分布を仮定するモデル
  * 単回帰モデルも分散分析モデルも含まれる
  * リンク関数は恒等関数
  * 確率分布は正規分布
  * 説明変数は量的だけ（単回帰モデル）、質的だけ（分散分析モデル）、両方とも（？）

## 8. ポアソン回帰モデル
  * 魚の釣果尾数のモデル化
    * あまり釣れないし生の数のみ、ポアソン分布に従う
    * 分布のパラメータ$\lambda$は気温と天気の影響を受ける
      * $p(y_i|\lambda_i)=\frac{\lambda_i^{y_i} exp(-\lambda_i)}{y_i!}$
      * ここから、ちょっと馬場本の式3.10, 3.11が分かりにくく感じたので、緑本p159の説明順を参考に表現を変えます。なんでexp()なのか、logなのかの説明がなくて分からない。
        * パラメータ$\lambda$が次の式に従うとする
          * $\lambda_i = exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)$
        * この式を変形すると
          * $log\lambda_i = \beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3$
          * リンク関数: $log\lambda_i$ -> 対数リンク関数
          * 線形予測子：$\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3$
        * 馬場本P159の式3.11
          * $\lambda=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3$ (3.11)
        * は誤解しそう
        * 緑本のように
          * $\lambda=exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)$
        * とした方がいい気がする。
        * ポアソン回帰には対数リンク関数、ロジスティック回帰にはロジットリンク関数＝正準リンク関数
          * Rのglm()では特に指定しなけば確率分布ごとに異なる正準リンク関数が使われる
          * なぜポアソン回帰には対数リンク関数を使うのか？
            1. 推定計算に都合がいいから(緑本P48): $\lambda_i$がexp(線形予測子)になるので、負になることがない。都合がいい。
            2. わかりやすいから（緑本P59あたり）：効果が掛け算になる。$exp(\beta_0+\beta_1x_1)$は$exp(\beta_0)\times exp(\beta_1x_1)$。複数の効果が掛け算で効いてくる方がもっともらしい。
  
## 9. ロジスティック回帰モデル: 二項分布を仮定するモデル
  * コインの裏表、種子の発芽率（発芽するかしないか）、商品の購入率（するしない）
    * 二値確率変数
    * 二項分布
  * 例：植物の種子の発芽率
    * 10粒中発芽する種子数をモデル化
      * 試行回数10の二項分布、成功確率$p$
      * $p$は日照の有無と栄養素の量に影響される
      * $y_i$: 10粒のうち発芽した数
      * $x_{i1}$: 日が当たっていれば1、当たっていなければ0のダミー変数
      * $x_{i2}$: 栄養素の量
      * $logit(p_i)=\beta_0+\beta_1x_1+\beta_2x_2$
      * $y\sim Binom(10,p_i)$
    * ロジット関数$logit()$
      * $logit(p)+log(\frac{p}{1-p})$
    * ロジット関数の逆関数＝ロジスティック関数
      * $logistic(x)=\frac{1}{1+exp(-x)}$
```{r}
x<-seq(-10,10,0.01)
y<-1/(1+exp(-x))
plot(x,y,type='l')
```

  * ここで馬場本では、「二項分布のリンク関数はロジット関数なので、その逆関数であるロジスティック関数を使った回帰モデルを使う」という書き方をしてるけど、これだとやっぱりなぜリンク関数がロジット関数なのかが不明のまま。
  * 緑本(P120)より
    * $z_i$についてのロジスティック関数$q_i=logistic(z_i)$は上↑のような形をしているので、$z_i=\beta_1+\beta_2x_2...$としたときの$z_i$（つまり線形予測子）がどのような値をとっても$0\leq q_i \leq 1$が成り立つ。だからロジスティック関数を使いたい。
    * ロジスティック関数を変形すると$log\frac{q_i}{1-q_i}=z_i$となり、この左辺をロジット関数と呼ぶ。
      * だから、$logit(p_i)=\beta_0+\beta_1x_1+\beta_2x_2$（＝線形予測子）と、ロジット関数がリンク関数となり、
      * 二項分布 $y \sim Binom(10,p_i)$のパラメータ$p_i$が$p_i=logistic(線形予測子)$と表せると理解すべきかと。
    * このあたり、P217のポアソン回帰モデルのStanファイル、P226のロジスティック回帰モデルのStanファイル（の下の説明）ではパラメータ＝exp(線形予測子)やパラメータ＝inv_logit(線形予測子)としていて、理解しやすい。
    
## 10. 一般化線形モデルの行列表現
  * 説明変数がj個ある、i番目のデータに関する一般化線形モデルの線形予測子は、1行j列のデータのベクトル$x_i$とj行1列の係数のベクトル$\boldsymbol{\beta}$の積で表すと簡潔だよっていう話
  * $\lambda=exp(x_i\beta)$ # こう書ききたい。本ではここにはexp()はついていない
  * $y_i \sim Poiss(\lambda_i)$ # こう書きたい。こっちにexp()がついている
    * ただし、データ$x_i$はデザイン行列$\boldsymbol{X}$の$i$行目。
    
## 11. 補足：データの表記とベクトル・行列
  * データ：$y_1, y_2, ..., y_N$
  * ベクトルとスカラー
    * ベクトル: $\boldsymbol{y}=[y_1\ y_2\ y_3]^T$ #さすがに面倒なので列ベクトルは表示しない
      * ベクトルは$\textbf{小文字太字}$で表す。Rstudioでギリシャ文字の太文字は結構めんどうで\\boldsymbol{}を使うらしい
      * Tは$transpose$転置のこと
    * スカラーは量、1要素
  * 2つ以上の変数をまとめるときは行列とする
    * 行列は$\textbf{大文字太字}$で表す
    * これも面倒なので表記は省略
    * m行n列の行列という呼び方

## 12. 補足：行列の基本的な演算
  * 行列の足し算：同じサイズの行列のみ。要素同士の足し算。
  * 行列のスカラ倍：各要素$\times$スカラ量
```{r}
A<-matrix(seq(1,6), 3, 2)
B<-matrix(seq(7,12), 3, 2)
A+B
3*A
```

## 13. 行列の掛け算
  * 行列の掛け算は知ってますよね、みなさん。
  * Rでの演算子は %*%
  * *は要素同士の掛け算
```{r}
A<-matrix(seq(1,6), 3, 2)
C<-matrix(seq(10,15),2,3)
A %*% C
C %*% A
```
  
## 14. 一般化線形モデルのさまざまなトピック
  * 交互作用：説明変数同士の影響を考えるモデル。交互作用項を作るなど。$x_1x_2$。緑本P127
  * オフセット項：係数を1に固定することである説明変数による影響を固定する？わざ。緑本P133
  * 多項ロジスティック回帰：3つ以上のカテゴリでどの比率が高くなるか、のような問題のモデル化。確率分布としてカテゴリカル分布、リンク関数としてソフトマックス関数。
  * ガンマ回帰：0以上の連続型データ。ガンマ分布、対数関数。
  * brms。

## 例題: 伊丸岡研の希望人数に実験科目を担当していたかがどう影響するか
  * imrlab.csv
    * year
    * population: クラス人数
    * imrlab: 伊丸岡研希望数
    * wtnblab: 渡邊研希望数（参考）
    * basic: 基礎実験担当かどうか（ダミー変数）
    * senior: 専門実験担当かどうか（ダミー変数）
  * imrlab.stan
```{r}
DATA<-read.csv('imrlab.csv')
library(rstan)
data_list<-list(population=DATA[,1], applicant=DATA[,2],basic=DATA[,3],senior=DATA[,4], N=9)
mr <- stan(
  file="imrlab.stan",
  data=data_list,
  iter=2000,
  warmup=1000,
  thin=1
)
print(mr,probs=c(0.025,0.5,0.975))
stan_trace(mr)
stan_dens(mr)
```
# 3-2: 単回帰モデル

## 2.1 目的と概要
  * 一般化線形モデルの初歩
  
## 2.2 分析の準備
  * パッケージの読み込み(rstan, beysplot)
  * オプション指定

## 2.3 データ読み込みと可視化
  * ビールの売り上げ
```{r, dev='ragg_png'}
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
library(rstan)
library(bayesplot)
bs2<-read.csv('3-2-1-beer-sales-2.csv')
sample_size<-nrow(bs2)
ggplot(bs2, aes(x=temperature, y=sales)) + geom_point()+labs(title='ビールの売り上げと気温の関係')

```

## 2.4 モデルの構造
  * 3部1章でやった形
    * $\mu_i = \beta_0 + \beta_1x_i$
    * $y \sim Normal(\mu_i, \sigma^2)$
    * 気温によってビールの売り上げの平均値($\mu_i$)が増減する
  * Stanで便利なように偏数名などを合わせる。恒等関数なので$\mu_i$もまとめる。
    * $sales_i\sim Normal(Intercept+beta\times temperature_i,sigma^2)$
  * 上の式に合わせてStanファイル実装

## 2.5 単回帰モデルのためのStanファイルの実装
  * chunkを使って書いてみる
    * var=beerでモデルのオブジェクトを作成、使用できる
    * rstan::samplingの第1引数でモデルオブジェクト、dataオプションでデータオブジェクトを指定。
    
```{stan output.var='beer'}
data{
  int N;
  vector[N] sales;
  vector[N] temperature;
}
parameters{
  real Intercept;
  real beta;
  real<lower=0> sigma;
}
model{
  sales ~ normal(Intercept+beta * temperature, sigma);
}
```

## 2.6 MCMCの実行, 2.7 事後分布の可視化
  * ここでは前で作ったモデルオブジェクトを使う

```{r beer, eval=TRUE}
library(bayesplot)
data_list<-list(
  N=sample_size,
  sales=bs2$sales,
  temperature=bs2$temperature
)
mr<-rstan::sampling(beer, data=data_list, seed=1)
print(mr, probs=c(0.025, 0.5, 0.975))
mcs<-rstan::extract(mr, permuted=FALSE)
mcmc_combo(
  mcs,
  parc=c("Intercept","beta","sigma")
)
```

## 2.8 まとめ
  1. Rパッケージ読み込み
  2. データ読み込み、可視化して確認
  3. Stanファイルの実装
  4. MCMC実行
  5. 収束していることの確認（Rhatなど）
  6. 興味あるパラメータの事後分布確認

# 3-1章: 一般化線形モデルの基本
## 1. 目的と概要
  * 一般化線形モデル(GLM): 実践的モデル & 複雑なモデルの部品
  * 確率分布、線形予測子、リンク関数
  * リファレンス的に使える章

## 2. 複雑なモデルを構築する際の手続きの標準化
  * モデルをどう構築するか
  * ビールの売り上げの例
    * $y \sim Normal(\mu,\sigma^2)$
    * これを複雑にしようとしたとき、"勝手に"やるばかりだと非効率かも
    * 「モデルの方」「フレームワーク」
  * 一般化線形モデルにおけるモデルの変更手続き
    1. 確率分布を変える
    2. 線形予測子を変える
    3. リンク関数を変える

## 3. 確率分布・線形予測子・リンク関数
  * 確率分布
    * 観測データを生む確率的過程を表現するためのもの。データに合わせて変える。
      * ビールなら正規分布
      * 小動物の数ならポアソン分布
      * 購入比率なら二項分布
  * 変数
    * 応答変数・従属変数
    * 説明変数
  * 線形予測子
    * 説明変数の線型結合
  * リンク関数
    * 応答変数と線形予測子を関係付けること
  
## 4. 一般化線形モデルの例: 説明変数が無く、正規分布を仮定するモデル
  * ビール売り上げの例
    * 凡例
      * $y_i$:売り上げデータ
      * $\mu_i$: $y_i$の期待値
      * $_i$: 何番目のデータか
      * $g$: 恒等関数（$g(y)=y$となる関数=何も起きない関数）
    * 一般化線形モデル
      * $g(\mu_i)=\beta_0$
      * $y_i \sim Normal(\mu, \sigma^2)$
      * $\beta_0$が線形予測子、恒等関数$g()$がリンク関数
    * 書き換え
      * $\mu_i=\beta_0$
      * $y_i \sim Normal(\mu, \sigma^2)$
    * 従属変数の平均値$\mu_i$が値$\beta_0$をとることを想定したモデル
    
## 5. 単回帰モデル: 説明変数が1つだけあり、正規分布を仮定するモデル
  * ビールの売り上げが気温$x$によって変化するというモデル
    * $g(\mu_i)=\beta_0+\beta_1x_i$
    * $y_i \sim Normal(\mu_i, \sigma^2)$
    * $\beta_0+\beta_1x_i$が線形予測子、恒等関数$g()$がリンク関数
  * 書き換え
    * $\mu_i = \beta_0 + \beta_1x_i$
    * $y_i \sim Normal(\mu_i, \sigma^2)$
  * 気温$x$が1変化すると$\beta_1$増減する
  * 単回帰モデル
    * $\beta_0$を切片
    * $\beta_1$を$x$の係数・傾き
  * 単回帰モデルを使うことで..
    * 説明変数と従属変数の関係の考察
    * 従属変数の予測
  
## 6. 分散分析モデル：ダミー変数を利用するモデル
  * 説明変数が質的変数のとき
    * ダミー変数を使う必要性
      * ダミー変数：0 / 1
      * 晴れ・雨・曇りを表現する
        * 晴れ：0/1
        * 雨: 0/1
      * 状態-1の変数
        * 1 0 -> 晴れ
        * 0 1 -> 雨
        * 0 0 -> 曇り
  * ビールの例
    * 売上が天気の影響を受ける
      * $x_1$:晴れなら1, $x_2$: 雨なら1, $g()$: 恒等関数
        * $g(\mu_i)=\beta_0+\beta_1x_{i1}+\beta_{i2}$
        * y \sim Normal(\mu_i, \sigma^2)
      * 書き換え
        *  $\mu_i=\beta_0+\beta_1x_{i1}+\beta_{i2}$
      * 分散分析モデル
        * 説明変数が質的データ
        * 確率分布として正規分布
        
## 7. 正規線形モデル：正規分布を仮定するモデル
  * 単回帰モデルも分散分析モデルも含まれる
  * リンク関数は恒等関数
  * 確率分布は正規分布
  * 説明変数は量的だけ（単回帰モデル）、質的だけ（分散分析モデル）、両方とも（？）

## 8. ポアソン回帰モデル
  * 魚の釣果尾数のモデル化
    * あまり釣れないし生の数のみ、ポアソン分布に従う
    * 分布のパラメータ$\lambda$は気温と天気の影響を受ける
      * $p(y_i|\lambda_i)=\frac{\lambda_i^{y_i} exp(-\lambda_i)}{y_i!}$
      * ここから、ちょっと馬場本の式3.10, 3.11が分かりにくく感じたので、緑本p159の説明順を参考に表現を変えます。なんでexp()なのか、logなのかの説明がなくて分からない。
        * パラメータ$\lambda$が次の式に従うとする
          * $\lambda_i = exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)$
        * この式を変形すると
          * $log\lambda_i = \beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3$
          * リンク関数: $log\lambda_i$ -> 対数リンク関数
          * 線形予測子：$\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3$
        * 馬場本P159の式3.11
          * $\lambda=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3$ (3.11)
        * は誤解しそう
        * 緑本のように
          * $\lambda=exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)$
        * とした方がいい気がする。
        * ポアソン回帰には対数リンク関数、ロジスティック回帰にはロジットリンク関数＝正準リンク関数
          * Rのglm()では特に指定しなけば確率分布ごとに異なる正準リンク関数が使われる
          * なぜポアソン回帰には対数リンク関数を使うのか？
            1. 推定計算に都合がいいから(緑本P48): $\lambda_i$がexp(線形予測子)になるので、負になることがない。都合がいい。
            2. わかりやすいから（緑本P59あたり）：効果が掛け算になる。$exp(\beta_0+\beta_1x_1)$は$exp(\beta_0)\times exp(\beta_1x_1)$。複数の効果が掛け算で効いてくる方がもっともらしい。
  
## 9. ロジスティック回帰モデル: 二項分布を仮定するモデル
  * コインの裏表、種子の発芽率（発芽するかしないか）、商品の購入率（するしない）
    * 二値確率変数
    * 二項分布
  * 例：植物の種子の発芽率
    * 10粒中発芽する種子数をモデル化
      * 試行回数10の二項分布、成功確率$p$
      * $p$は日照の有無と栄養素の量に影響される
      * $y_i$: 10粒のうち発芽した数
      * $x_{i1}$: 日が当たっていれば1、当たっていなければ0のダミー変数
      * $x_{i2}$: 栄養素の量
      * $logit(p_i)=\beta_0+\beta_1x_1+\beta_2x_2$
      * $y\sim Binom(10,p_i)$
    * ロジット関数$logit()$
      * $logit(p)+log(\frac{p}{1-p})$
    * ロジット関数の逆関数＝ロジスティック関数
      * $logistic(x)=\frac{1}{1+exp(-x)}$
```{r}
x<-seq(-10,10,0.01)
y<-1/(1+exp(-x))
plot(x,y,type='l')
```

# 3-2章: 単回帰モデル
## 2. 分析の準備 - 8. まとめ
  * beerと気温の例の実施例
  
# 3-3章: モデルを用いた予測
## 2. 分析の準備
## 3. 単回帰モデルにおける予測の考え方
  * モデル: $sales_i \sim Normal(Intercept + beta \times temperature_i, sigma^2)$
  * モデル推定で切片とベータが分かっていれば、ある気温の売り上げを計算できる
    * ただし、その切片は単に「分布の代表値」

## 4. 予測のためのデータの整理
  * 予測したい気温のリストを作成
  
## 5. 予測のためのStanファイルの修正
  * generated quantitiesブロックを作成
    * 事後予測分布を取得

## 6. MCMCの実行
  * モデル推定と事後予測分布が得られる
  
## 7. 予測分布の可視化
  * beyesplotパッケージなどで図示
    * 正規表現を使うための引数: regex_pars
  * 95%予測区間
  * 予測分布
  
# 3-4章: デザイン行列を用いた一般化線形モデルの推定
## 2. 分析の準備
  * beerの例
  
```{r}
library(rstan)
library(bayesplot)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

beerf<-read.csv("3-2-1-beer-sales-2.csv")
sample_size <- nrow(beerf)

```

## 3. デザイン行列を使ったモデルの数学的な表現
  * ビールの売り上げ
    * $\mu_i = \beta_0 + \beta_1x_i$
    * $y_i \sim Normal(\mu_i, \sigma^2)$
  * ここで期待値のベクトル$\boldsymbol{\mu}$, デザイン行列$\boldsymbol{X}$とすると、
    * $\boldsymbol{\mu} = \boldsymbol{X\beta}$
    
## 4. formula構文を用いたデザイン行列の作成
  * formula記法
  * $formula(応答変数 \sim 説明変数)$
  * model.matrix関数
  
```{r}
flm <- formula(sales ~ temperature)
X <- model.matrix(flm, beerf)
```

## 5. デザイン行列を使うためのStanファイルの設定
  * stanファイルを修正する
```{stan output.var='beer_design'}
data{
  int N;
  int K;
  vector[N] Y;
  matrix[N, K] X;
}

parameters{
  vector[K] b;
  real<lower = 0> sigma;
}

transformed parameters{
  vector[N] mu = X * b;
}

model{
  Y ~ normal(mu, sigma);
}
```

## 6. MCMCの実行

```{r beer_design}
N <- nrow(beerf)
K <- 2
Y <- beerf$sales
dl <- list(N = N, K = K, Y = Y, X = X)

res<-rstan::sampling(beer_design, data=dl, seed=1)
print(res, probs = c(0.025, 0.5, 0.975))

```

# 3-5. brmsの使い方
## 2. brmsとは
  * Stanを使ったベイジアン回帰モデル
  
## 3. 本書での実装の方針
## 4. 分析の準備
  * brmsパッケージが必要
  
```{r}
library(rstan)
library(brms)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

beersf<-read.csv('3-2-1-beer-sales-2.csv')
```
## 5. brmsによる単回帰モデルの推定
  * Stanファイル不要
  * 指定が必要なもの
    * 線形予測子
    * 確率分布
    * リンク関数
  * 結果
    * 切片、係数
    * Estimate: 点推定値
  * as.mcmc(): MCMCサンプル取得
  * plot(): 事後分布、トレースプロットの図示

```{r}
lm_brms<-brm(
  formula = sales ~ temperature,
  family = gaussian(link='identity'),
  data = beersf,
  seed = 1
)
print(lm_brms)
# as.mcmc(lm_brms, combine_chains = TRUE)
plot(lm_brms)
```
  
## 6. brmsの基本的な使い方
  * bf(): formulaをbrmの外で定義可能
    * lm_formula <- bf(sales ~ temperature) など
  * familyに使える分布
    * gaussian()
    * binomial()
    * poisson()
    * などなど
    * Rで関数実行すると標準で指定されているlink関数が表示される
  
## 7. 事前分布の変更
  * prior_summary(): 事前分布一覧の表示
  
```{r}
prior_summary(lm_brms)
```
  
  * 一覧
    * flatは一様分布?
    * 切片には自由度3、中心位置71.5、分布の裾の広さ20のstudent t分布を使ってるということ
    * sigmaの分布は中心0、広さ20
  * 事前分布を変更したい場合
  
```{r}
lm_brms2 <- brm(
  formula=sales~temperature,
  family = gaussian(),
  data = beersf,
  seed = 1,
  prior=c(set_prior("",class="Intercept"),
          set_prior("",class="sigma"))
)
prior_summary(lm_brms2)
```
  
  * stanコードの抽出
    * stancode(lm_brms2)
  * データの抽出
    * standata(lm_brms2)
    
## 8. 補足：brmsの基本的な仕組み
  * make_stancode関数で Stanコードを生成
  * make_standata関数でデータを生成
  
## 9. 補足：make_stancode関数によるStanコードの作成
  * データ、パラメータはベクトル化
  * modelはサンプリング文ではなく、対数密度加算文として記述される
    * なぜ対数密度加算文か
      * 2部6章ではサンプリング文を基本として、対数密度加算文でも書けると説明
      * 実際には、Stan内部では対数密度の加算をしていて、それを理解しやすいようにサンプリング文でも書けるということらしい（[Stanマニュアル: 対数密度加算文](https://github.com/stan-ja/stan-ja/blob/master/part02/chap05/chap05.md#53-対数密度加算文)）。
      * 対数密度加算文で使う target の意味が良く分からなかったけど、これは変数ではなく、Stanであらかじめ決められた対数密度を示すものらしい。以前はlp__(log probability)という変数だった?
  * generated quantitiesでは標準化をもとに戻す処理。標準化後の切片ー平均*効果

## 10. 補足：make_standata関数による、Stanに渡すデータの作成

## 11. 補足：rstanでbrmsの結果を再現する

## 12. brmsによる事後分布の可視化
  * パラメータで正規表現使用可能
    * ^ は文字列の先頭を示す正規表現
    * stanplot()関数
    
## 13. brmsによる予測
  * 予測
```{r}
new_data <- data.frame(temperature = 20)
fitted(lm_brms, new_data)

```
```{r}
set.seed(1)
predict(lm_brms, new_data)

```
  * fitted(事後平均値とベイズ信用区間)、predict(事後平均値とベイズ予測区間)の違い
    * fitted/信用区間：推定されたパラメータの範囲
    * predict/予測区間：推定されたモデルから得られるデータの範囲（サンプリング誤差も含む）
  
## 14. 補足：predict関数を使わない予測の実装
  * 手順の確認のための実装
  * fittedとpredictの違いも分かりやすい
    1. as.mcmc()でMCMCサンプル取り出し
    2. 取り出したMCMCサンプルの切片と傾きを使って予測値を算出し、モデルを作る
    3. 作成したモデルを使って予測値の生成
    
## 15. 回帰直線の図示
  * 可視化のため
  * marginal_effects()関数で作成可能
  * 回帰直線＋信用区間  
  * 回帰直線＋予測区間
  * 引数effectを追加することで、特定の説明変数に注目した図示が可能
  
## 反応時間練習問題

```{r}
library(brms)
dat_mr=read.table("mentalrotation.csv",header = TRUE,sep = ",")
sort(unique(dat_mr$angle))
dat_mr$angle=dat_mr$angle/180*pi
hist(dat_mr$rt,xlim=c(0,5),breaks=20)
formula_mr <- bf(rt ~ angle)
#fit <- brm(
#  formula = formula_mr,
#  family = exgaussian(link="identity", link_sigma = "log", link_beta = "log"),
#  data = dat_mr, 
#  seed = 1) 
fit <- brm(
  formula = formula_mr,
  family = shifted_lognormal(link="identity", link_sigma = "log"),
  data = dat_mr, 
  seed = 1) 
set.seed(1)
eff_predict_mr <- conditional_effects(fit, method="predict")
plot(eff_predict_mr, points = TRUE)
fit
```

# 3-6章: ダミー変数と分散分析モデル
## 2. モデルの構造
  * 質的説明変数：ダミー変数
  * 例
    * ビールの売り上げ$y_i$
    * 天気$x_{i1}$, $x_{i2}$
    * 売り上げは正規分布($\mu_i$,$\sigma$)に従う
    * $\mu_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}$
    * $y_i \sim Normal(\mu_i, \sigma^2)$
    
```{r}
library(ggplot2)
sales_w<-read.csv('3-6-1-beer-sales-3.csv')
ggplot(data=sales_w, mapping=aes(x=weather, y=sales))+geom_violin()+geom_point(aes(color=weather))+labs(title='beer sales ans weather')
```
    
## 5. brmsによる分散分析モデルの推定
```{r}
library(brms)
anova_brms<-brm(
  formula=sales~weather,
  family=gaussian(link="log"),
  data=sales_w,
  seed=1,
  prior=c(set_prior("", class="Intercept"),
          set_prior("", class="sigma"))
)

anova_brms

eff<-conditional_effects(anova_brms)
plot(eff, points=FALSE)
```

## 6. 補足: 分散分析モデルのデザイン行列
```{r}
formula_anova<-formula(sales~weather)
design_mat<-model.matrix(formula_anova, sales_w)

data_list<-list(
  N=nrow(sales_w),
  K=3,
  Y=sales_w$sales,
  X=design_mat
)

library(rstan)
anova_stan<-rstan::sampling(beer_design,
                            data=data_list,
                            seed=1
)
```

# 3-7: 正規線形モデル
## 2. モデルの構造
  * 正規線形モデル：リンク関数が恒等関数であるモデルの総称
  * ここで使うモデル
    * $売り上げの平均値=晴れ＋雨＋気温$
    * $\mu_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\beta_3x_{i3}$
    * $y_i\sim Normal(\mu_i, \sigma^2)$

## 3. 分析の準備
  * いつもの
```{r}
library(rstan)
library(brms)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```
  
## 4. データの読み込み
  * 天気と気温が売り上げの平均値に影響するというモデルのためのデータ
```{r}
data37<-read.csv('3-7-1-beer-sales-4.csv')
summary(data37)

ggplot(data=data37,
       mapping=aes(x=temperature, y=sales))+
      geom_point(aes(color=weather))+labs(title="effect of temperature and weather on beer sales")
```

## 5. brmsによる正規線形モデルの推定
```{r}
brms37<-brm(
  formula = sales ~ weather + temperature,
  family = gaussian(),
  data = data37,
  seed = 1,
  prior = c(set_prior("", class="Intercept"),
            set_prior("", class="sigma"))
)
brms37
eff<-conditional_effects(brms37, effect="temperature:weather")
plot(eff, points=TRUE)
eff_pre<-conditional_effects(brms37, effect="temperature:weather", method="predict")
plot(eff_pre, points=TRUE)
```

  * weathersunnyの推定値が29.45（信用区間は0をまたがない）: 晴れの日には＋29万円の効果
  * temperatureの推定値が2.55（信用区間は0をまたがない）：気温1℃で2.55万円増加
 
## 6. 補足：正規線形モデルのデザイン行列（Stanによる解析）
  * まずはbrmsによる解析からstanファイルを生成してみる
  
```{r}
stancode(brms37)
```
  
  * 続いて3部4章のStanファイル
  
```{stan output.var='stan37'}
data{
  int N;
  int K; //デザイン行列列数
  vector[N] Y; //売り上げを代入するベクトル
  matrix[N, K] X; //デザイン行列
}
parameters{
  vector[K] b;
  real<lower=0> sigma;
}
model{
  vector[N] mu = X * b;
  Y ~ normal(mu, sigma);
}
```

  * Stanコードを実行
  
```{r stan37}
# デザイン行列
formula37<-formula(sales ~ weather + temperature)
mtx37<-model.matrix(formula37, data37) ## data37はcsvファイルを読み込んだデータ

standata37<-list(
  N=nrow(data37),
  K=4, # 切片、天気雨、天気晴れ、気温
  Y=data37$sales,
  X=mtx37
)

library(rstan)
stanres37<-rstan::sampling(stan37,
                           data=standata37,
                           seed=1)
stanres37

```
  * brmsとほぼ同じ結果になった

# 3-8: ポアソン回帰モデル
## 2. モデルの構造
  * ポアソン分布：離散型で0以上の整数データのとき
    * パラメータ$\lambda$
    * 期待値も分散も$\lambda$
    * リンク関数は$log$
  * ここでの例
    * 釣り
    * 釣果＝天気＋気温
      * ただしポアソン分布を考えるので
      * $log(\lambda) = \beta_0 + \beta_1x_1 + \beta_2x_2$
        * $個人的には\lambda_i = exp(\beta_0 + \beta_1x_1 + \beta_2x_2)$の方が理解しやすい（と、3-1でも書いた。緑本にはこう書いてある。）
      * $y_i \sim Poiss(\lambda_i)$
      * 馬場本では$log(\lambda)=$の式もあって、下の式もあるのが分かりにくい感じがする
        * $\lambda = \beta_0 + \beta_1x_1 + \beta_2x_2$
        * $y_i \sim Poiss(exp(\lambda_i))$

## 3. 分析の準備
  * いつもの
```{r}
library(rstan)
library(brms)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```
  
## 4. データの読み込みと可視化
```{r}
data38<-read.csv("3-8-1-fish-num-1.csv")
summary(data38)
ggplot(data=data38,
       mapping=aes(x=temperature, y=fish_num))+
  geom_point(aes(color=weather))+
  labs(title="effect of temperature and weather on num of fishes")
```

## 5. brmsによるポアソン回帰モデルの推定
  * 正規線形モデルとほぼ同じだけど、sigmaの事前分布の指定がない（推定しないから）
  
```{r}
brms38<-brm(
  formula = fish_num ~ weather + temperature,
  family=poisson(),
  data=data38,
  seed=1,
  prior=c(set_prior("",class="Intercept"))
)
brms38
```

## 6. 推定されたモデルの解釈
  * weathersunnyの係数の推定値は-0.60
    * ただし、exp(-0.60)=0.5488
    * 晴れると0.54倍になる
      * 倍でいいの？と思ったけど、expの中の足し算は掛け算。
  * temperatureは0.08
    * exp(0.08)=1.0832
    * 晴れると微妙に増える
  * 釣果数の期待値$\lambda=exp(-.78-0.60 \times 晴れかどうか+0.08 \times 気温)$
  
## 7. 回帰曲線の図示
  * 95%ベイズ信用区間つき
```{r}
eff38<-conditional_effects(brms38,
                          effects="temperature:weather") # weatherを前にすれば横軸がweatherになる
plot(eff38, points=TRUE)
```

  * 予測区間
    * 過分散となることがある
      * 期待値と分散が一つのパラメータで決まるから、とあるけど、なぜ？
      * 緑本で「過分散」を調べてみる
        * P149脚注: 「現実のカウントデータでは平均よりも分散の方が大きくなる場合がほとんどです。詳しくは7.6節（以下略）」
        * P165 7.6節: ここでは過分散の原因として個体差を挙げている。種子数の例を使っていて、本来正規分布する植物の大きさが観測されていないため、という理屈。緑本的にはここから一般化線形混合モデル（GLMM）を使うという流れ。
        * 馬場本でも第4分階層ベイズ（一般化線形混合モデル）と進む
```{r}
set.seed(1)
eff_pre38<-conditional_effects(brms38,
                              method='predict',
                              effects='temperature:weather',
                              probs=c(0.05, 0.995))
plot(eff_pre38, points=TRUE)
```


## 8. 補足：ポアソン回帰モデルのためのStanファイルの実装
  * ここでもStanファイルから実行してみる
  
```{stan output.var='stan38'}
data{
  int N;
  int fish_num[N];
  vector[N] temp;
  vector[N] sunny;
}
parameters{
  real Intercept;
  real b_temp;
  real b_sunny;
}
model{
  vector[N] lambda=exp(Intercept + b_sunny*sunny + b_temp*temp);
  fish_num~poisson(lambda);
}
```

  * 上のStanファイルを実行
    * 下の計算ではデータからダミー変数を作ったけど、それをやる必要はない？
  
```{r stan38}
data38<-read.csv('3-8-1-fish-num-1.csv') #データ読み込み
data38$sunny<-as.integer(data38$weather=='sunny') # 晴れの日ダミー変数作成
standata38<-list(  # Stanに渡すためにリストにまとめる
  N=nrow(data38),
  fish_num=data38$fish_num,
  temp=data38$temp,
  sunny=data38$sunny
)

res38<-rstan::sampling(stan38, data=standata38, seed=1)
print(res38)
```
  * デザイン行列バージョンも一応。

```{stan output.var='modelmtx38'}
data{
  int N;
  int K;
  int Y[N];
  matrix[N, K] X;
}
parameters{
  vector[K] b;
}
model{
  vector[N] lambda = X * b;
  Y ~ poisson_log(lambda);
}
```

  * この下で使ってるformula関数、model.matrix関数が結構謎。model.matrixは名義尺度のweatherからダミー変数weathersunnyを自動的に生成しているように見える。

```{r modelmtx38}
data38<-read.csv('3-8-1-fish-num-1.csv') #データ読み込み
formula38<-formula(fish_num~weather+temperature)
mtx38<-model.matrix(formula38, data38)
standatamtx38<-list(
  N=nrow(data38),
  K=3,
  Y=data38$fish_num,
  X=mtx38
)
resmtx38<-rstan::sampling(modelmtx38, data=standatamtx38, seed=1)
print(resmtx38)
```

# 3-9. ロジスティック回帰モデル
## 2. モデルの構造
  * 2値データ
  * 種子が発芽するかしないか
    * 発芽率$p$
    * 確率分布：二項分布
    * リンク関数：ロジット関数
    * $p_i$: 発芽確率
    * $y_i$: 10粒中の発芽数
    * $x_{i1}$: 日当たり有無のダミー変数
    * $x_{i2}$: 栄養素量
    * $p_i = logostic(\beta_0+\beta_1x_{i1}+\beta_2{xi})$ :パラメータ$p$は0から1の間で変化するロジスティック関数に従う
    * $y_i\sim Binom(10, p_i)$
    
## 3. 分析の準備
```{r}
library(rstan)
library(brms)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```

## 4. データの読み込みと可視化
```{r}
dat39<-read.csv('3-9-1-germination.csv')
summary(dat39)
ggplot(data=dat39, 
       mapping=aes(x=nutrition, y=germination, color=solar)) + geom_point() + labs(title='relation between germination and solar and nutrition')
```

## 5. brmsによるロジスティック回帰モデルの推定
```{r}
brms39<-brm(
  germination | trials(size) ~ solar + nutrition,
  family = binomial(),
  data=dat39,
  seed=1,
  prior=c(set_prior("", class="Intercept"))
)
print(brms39)
```
  * 結果
    * solarsunshineの効果あり
    * nutritionの効果あり
  * ただし、係数の解釈に注意が必要（リンク関数がロジット関数だから）
  * オッズ比：$オッズ=\frac{p}{1-p}$
  * ロジスティック回帰モデルの係数＝対数オッズ比
    * 係数にexp()をかけるとオッズ比になる
  * 例を使ってオッズ比の説明
    *日光と栄養素が発芽に与える影響。データ3つ。
    * やってみる
```{r}
egdata<-data.frame(
  solar=c('shade','sunshine','sunshine'),
  nutrition=c(2,2,3),
  size=c(10,10,10)
)
egdata
linear_fit<-fitted(brms39, egdata, scale='linear')[,1] # 最後の[,1]は1列目のみという意味
fit<-1/(1+exp(-linear_fit))
fit
```
    * ここまでやったこと
      * データ（日照の有無、栄養素の量、個数を指定）
      * fitted関数を使って、データに対してさっき推定したモデルを適用、線形予測子の予測値を知る（linear_fitted）。
        * fitted関数についてはちょっと調べてみたけど、詳細は不明。'linear'ではなく'response'を指定するとロジスティック関数に入れた値に近い値が出てくるけど、ちょっと違う。
      * 線形予測子が出す値をロジスティック関数に与えることで、各データに対する発芽率が得られる（fit）。
```{r}
odds_1 <- fit[1]/(1-fit[1])
odds_2 <- fit[2]/(1-fit[2])
odds_3 <- fit[3]/(1-fit[3])
```

  * この後、オッズ比を算出する
    * odds_2/odds_1: 1と2の違いは日照の有無なので、日照によって成功率がどう変わるかが分かることになる
    * で、この値が日照の係数のexpと同じと言っている
    
```{r}
odds_2/odds_1

coef<-fixef(brms39)[,1] 
exp(coef["solarsunshine"])
```
  * 確かに同じになる

## 7. 回帰曲線の図示
  * 図示。これまで同様。ただし、引数conditionsが必要（本のサポートページに記述あり）。
```{r}
eff<-conditional_effects(brms39, effects='nutrition:solar', conditions=data.frame(size=10))
plot(eff, points=TRUE)
```
  
  * せっかくなので予測区間も書いてみる
  
```{r}
eff_pre<-conditional_effects(brms39, effects='nutrition:solar', conditions=data.frame(size=10), method='predict')
plot(eff_pre, points=TRUE)
```
  * ポアソン回帰同様、こちらもギザギザに。二項分布に従う乱数は整数だからという解釈でOK？
  * ところで、「○○回帰モデル」命名の謎
    * ポアソン分布に従うデータのモデル推定を、リンク関数を対数関数で実施する（線形予測子をexpで処理）→これをポアソン回帰と呼ぶ
    * 二項分布に従うデータのモデル推定を、リンク関数をロジット関数で実施する（線形予測子をlogisticで処理）→これをロジスティック回帰と呼ぶ
    * なんで？
    
## 8. 補足: ロジスティック回帰のためのStanファイルの実装
  * Stanでもやってみる。デザイン行列で。
```{stan output.var='stanmodel39'}
data{
  int N;
  int K;
  int Y[N];
  int binom_size[N];
  matrix[N, K] X;
}
parameters{
  vector[K] b;
}
model{
  vector[N] prob = X * b;
  Y ~ binomial_logit(binom_size, prob); #binomial_logitには引数2つ必要
}
```

```{r stanmodel39}
dat39<-read.csv('3-9-1-germination.csv')
formula39<-formula(germination|size~solar+nutrition)
mtx39<-model.matrix(formula39, dat39)
standatamtx39<-list(
  N=nrow(dat39),
  K=3,
  binom_size=dat39$size,
  Y=dat39$germination,
  X=mtx39
)
resmtx39<-rstan::sampling(stanmodel39, data=standatamtx39, seed=1)
print(resmtx39)

```

##9. 補足: 試行回数が常に1の場合
  * そういうときは二項分布ではなくベルヌーイ分布を使おうね、という話
