---
title: 'midori3'
author: "Toshihide Imaruoka"
output:
  rmdformats::downcute:
    highlight: kate
    css: mycss.css
    dev: "ragg_png"
---
# 3. 一般化線形モデルーポアソン回帰
  * 説明変数を組み込んだモデル
    * 個体ごとに異なる説明変数を組み込む
    * ポアソン回帰
  
## 3.1 例題：個体ごとに平均種子数が異なる場合
  * 架空の植物100個
    * 個体$_i$
    * 種子数$y_i$
    * 体サイズ$x_i$: 正の実数
    * 施肥処理$f_i$: C処理なし, T処理あり; 50体ずつ
      * 体サイズと施肥処理は独立
      
## 3.2 観測されたデータの概要を調べる
  * R でデータ読み込み、処理
  
```{r}
dat<-read.csv('kubobook_2012-2/poisson/data3a.csv')
dat$f<-as.factor(dat$f)
summary(dat)
```
## 3.3 統計モデリングの前にデータを図示する

  * データをよく見ておくこと大事
```{r}
plot(dat$x, dat$y, pch=c(21,19)[dat$f])
legend('topleft', legend=c("C","T"), pch=c(21,19))
plot(dat$f,dat$y)
```
  
## 3.4 ポアソン回帰の統計モデル

  * カウントデータなのでポアソン分布でばらつきを表現できるはず
  * 平均種子数$\lambda_i$が体サイズxや施肥処理fに影響される
  * まずは体サイズ$x_i$だけに影響されるというモデル
    * $p(y_i|\lambda_i)=\frac{\lambda_i^{y_i}exp(-\lambda_i)}{y_i!}$
    
### 3.4.1 線形予測子と対数リンク関数
  * ここでは平均$\lambda_i$は説明変数$x_i$の関数であるとしている。そこで、
    * $\lambda_i=exp(\beta_1+\beta_2x_i)$
    * 図示してみると、パラメータ($\beta_1, \beta_2$)によって体サイズと平均種子数の関係が大きく変化することが分かる
    * ここでは、右辺がexp()である理由は説明されていないことに注意
  * 線形予測子(linear predictor)とリンク関数(link function)
    * さっきの式は、下のように変形可能（両辺にlog）
      * $log\lambda_i=\beta_1+\beta_2x_i$
    * 右辺が項の線形和となったので、これを線形予測子と呼ぶ
    * このとき、左辺が$\lambda$の関数となり、右辺が線形予測子。このときの左辺の関数をリンク関数と呼ぶ。今の場合は対数リンク関数。
      * ポアソン回帰の場合は、対数リンク関数を使うのが普通。
    * 正準リンク関数
      * ポアソン回帰には対数リンク関数
      * ロジスティック回帰にはリジットリンク関数
      * これらを正準リンク関数と呼ぶ
        * 計算に都合が良い＝ポアソン回帰の場合、パラメータが負になり得ない
        * 分かりやすい＝効果が項同士の積で表される(expだから)→3.6で説明

### 3.4.2 あてはめとあてはまりの良さ
  * ポアソン回帰＝データに対するポアソン分布を使った統計モデルの「あてはめ」
    * いろいろなあてはめの可能性がある中で、対数尤度logLが最大になるパラメータを決める
    * あるデータYのもとでの対数尤度は
      * $logL(\beta_1,\beta_2)=\Sigma_ilog\frac{\lambda^{y_i}exp(-\lambda_i)}{y_i!}$
      * ここで、$\lambda_i$はパラメータ$\beta_1と\beta_2$の関数
      * 2章ではパラメータが1つだったので対数尤度の最大値は簡単に求められたけど、2つだとそうはいかない。
        * そこで「数値を使った試行錯誤」＝MCMC
        * ただし、いきなりMCMCというわけではなく、RではGLMについてはglm関数で最尤推定ができる。以下、ここで使ってるデータの例。

```{r}
fit<-glm(y~x, data=dat, family=poisson)
print(fit)
summary(fit)
logLik(fit)
```

  * 結果の読み方まとめ
    * (Intercept)は$\beta_1$
    * xは$\beta_2$
    * Estimateは推定値
    * Std. Error は標準誤差
      * 推定値$\beta_1と\beta_2$のばらつき（標準偏差）
      * パラメータ推定値のばらつきSEの推定方法
        * パラメータ推定値のばらつきを正規分布と仮定、さらに対数尤度関数の形が正規分布に近いと仮定。それによってSEを求めている。
    * z valueは統計量z。最尤推定値/SE（Wald統計量）。最尤推定値が0から離れているかどうかの目安となり得る。
    * Pr(>|z|)は、平均z値（の絶対値）、標準偏差1の正規分布の無限大から0の面積の2倍。値が大きいと、z値（つまり推定値）が0に近いということになる。今の例でいうと$\beta_1$は0と十分に離れてるけど、$\beta_2$は結構近い。信頼区間くらいで考えた方が良さそう。
  * ある説明変数をモデルに含めるべきかどうかは、第4章のモデル選択で判断すべき
    * あてはまりの改善か、予測の改善か
    * じゃああてはまりの完全にはWald信頼区間？そういうわけでもなさそうだけど。
  * 最大対数尤度＝あてはまりの良さ（goodness of fit)
    * logLik()関数
    
## 3.4.3 ポアソン回帰モデルによる予測
  * ポアソン回帰の推定結果を使って、体サイズに対する種子数の予測ができる
  
```{r}
plot(dat$x, dat$y, pch=c(21,19)[dat$f], ylim=c(min(dat$y), max(dat$y)))
xx<-seq(min(dat$x), max(dat$x), length=100)
par(new=T)
plot(xx, exp(1.29 + 0.0757 * xx), type='l', lwd=2, ylim=c(min(dat$y), max(dat$y)))
```

## 3.5 説明変数が因子型の統計モデル
  * 因子型の変数について考えるために施肥効果$f_i$について考えてみる
    * まずは体サイズは無視して、施肥効果だけのモデル
    * glm()を使えば簡単で、y~fとするだけ
    * ただし、本ではダミー変数を使うという考え方の確認をしている
      * ダミー変数$d_i$が
        * $f_i$がCのときには$d_i$=0
        * $f_i$がTのときには$d_i$=1
  
```{r}
fit.f<-glm(y~f, data=dat, family=poisson)
print(fit.f)
logLik(fit.f)
```

  * 最大対数尤度を出すと、体サイズだけのモデルよりも値が小さい＝あてはまりが悪い
  * ちなみに因子型変数が3水準の場合(肥料Aを与える、Bを与える、どちらも与えない）、A,B,CをAが与えられたかどうか、Bが与えられたかどうかの組み合わせで表す＝項が2つとなる
    * 項$d_{i.A}$と$d_{i.B}$を置き、それぞれを0,1で表現する（肥料Aを与えたー与えない、肥料Bを与えたー与えない）
  
## 3.6 説明変数が数量型＋因子型の統計モデル
  * 体サイズ$x_i$と施肥処理$f_i$を両方組み込んだモデル
  
```{r}
f.all<-glm(y~x+f, family=poisson, data=dat)
print(f.all)
logLik(f.all)
```
  
  * 最大対数尤度は体サイズのみのときと比べ、少しだけよくなってる
    * これについては第4章で検討

### 3.6.1 対数リンク関数のわかりやすさ：かけ算される効果
  * y ~ x + f としているけど、対数リンク関数なので実は掛け算
    * log(y) = x + f ということは y = exp(x + f)ということで、y = exp(x) * exp(f) ということだから。
  * ただし、だから対数リンク関数が妥当だ、あるいは正しいという話ではない
  * 図3.8
    * 対数リンク関数（種子数はexpで増加）の場合と恒等リンク関数（種子数は線形の増加）を比較
    * 対数リンク関数の場合、種子数が大きいときは施肥の効果が大きくなる
    * 恒等リンク関数の場合、種子数の絶対値に関わらず施肥の効果は一定
  * どちらのモデルがより妥当かを意味をよく考えるべき
    * 単に当てはまりの良さだけではなく

## 3.7 「何でも正規分布」「何でも直線」には無理がある
  * GLMで確率分布を正規分布、リンク関数を恒等リンク関数とすれば、線形モデルあるいは一般線形モデル
    * 線形モデルの一つである直線回帰（よくやりがち）と一般線形モデルのポアソン回帰を仮想データで比較してみる。ポアソン回帰は線形モデルでは絶対に実現できないことに注意。
  * 図3.9のデータ
    * 左は直線回帰しようとしている
      * 多くのおかしな点
        * xが小さいときにはyのばらつきが小さい（0がたくさん）のに対して、xが大きくなるとyのばらつきが大きくなる＝等分散ではない
        * yが離散値（正規分布は連続量に対する確率分布のはず）
        * 直線回帰の結果、yの予測値が負になるところがある
      * おかしい
    * 右はポアソン回帰の例
      * 離散値に無理なく対応
      * 対数リンク関数を使うことでyは負にならない（リンク関数は選べる）
      * ばらつきの変化にも対応できる
    * データの変換（対数変換・角変換など）も以前はよく使われていた（例えば、だんだんばらつきが大きくなるデータに対数変換とか）けど、それが妥当なわけではない
  