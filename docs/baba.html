<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="generator" content="pandoc" />

        <meta name="author" content="Toshihide Imaruoka" />
    
    
    <title>馬場本</title>

        <script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
        <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link href="site_libs/bootstrap-3.3.7/css/bootstrap.min.css" rel="stylesheet" />
        <script src="site_libs/bootstrap-3.3.7/js/bootstrap.min.js"></script>
        <script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
        <script src="site_libs/navigation-1.1/tabsets.js"></script>
        <link href="site_libs/magnific-popup-1.1.0/magnific-popup.css" rel="stylesheet" />
        <script src="site_libs/magnific-popup-1.1.0/jquery.magnific-popup.min.js"></script>
        <link href="site_libs/downcute-0.1/downcute.css" rel="stylesheet" />
        <link href="site_libs/downcute-0.1/downcute_fonts_embed.css" rel="stylesheet" />
        <script src="site_libs/downcute-0.1/downcute_styles.js"></script>
        <script src="site_libs/downcute-0.1/downcute.js"></script>
        <script src="site_libs/prism-1.22/prism.js"></script>
    
    
    
        <link rel="stylesheet" href="mycss.css" type="text/css" />
    
    <!-- tabsets -->
    <script>
      $(document).ready(function () {
	  window.buildTabsets("toc");
      });
      $(document).ready(function () {
	  $('.tabset-dropdown > .nav-tabs > li').click(function () {
	      $(this).parent().toggleClass('nav-tabs-open')
	  });
      });
    </script>

    <!-- code folding -->
    
    <!-- code download -->
    
    <!-- tabsets dropdown -->

    <style type="text/css">
      .tabset-dropdown > .nav-tabs {
	  display: inline-table;
	  max-height: 500px;
	  min-height: 44px;
	  overflow-y: auto;
	  background: white;
	  border: 1px solid #ddd;
	  border-radius: 4px;
      }
      
      .tabset-dropdown > .nav-tabs > li.active:before {
	  content: "";
	  font-family: 'Glyphicons Halflings';
	  display: inline-block;
	  padding: 10px;
	  border-right: 1px solid #ddd;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
	  content: "&#xe258;";
	  border: none;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
	  content: "";
	  font-family: 'Glyphicons Halflings';
	  display: inline-block;
	  padding: 10px;
	  border-right: 1px solid #ddd;
      }
      
      .tabset-dropdown > .nav-tabs > li.active {
	  display: block;
      }

      .tabset-dropdown > .nav-tabs > li.active a {
  	  padding: 0 15px !important;
      }

      .tabset-dropdown > .nav-tabs > li > a,
      .tabset-dropdown > .nav-tabs > li > a:focus,
      .tabset-dropdown > .nav-tabs > li > a:hover {
	  border: none;
	  display: inline-block;
	  border-radius: 4px;
	  background-color: transparent;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open > li {
	  display: block;
	  float: none;
      }
      
      .tabset-dropdown > .nav-tabs > li {
	  display: none;
	  margin-left: 0 !important;
      }
    </style>
    
</head>

<body class="preload">

   	
               <!-- downcute start -->   
   <div id="docute" class="Root theme-default">
     <div class="Page layout-narrow">
      <div class="Wrap">
        <div class="Sidebar">
          <div class="SidebarItems" id="toc">
            <ul>
            <li><a href="#章ベイズ統計モデリングの基本">1-1章：ベイズ統計モデリングの基本</a>
            <ul>
            <li><a href="#統計モデリング">2. 統計モデリング</a></li>
            <li><a href="#統計モデルの有用性">3. 統計モデルの有用性</a></li>
            </ul></li>
            <li><a href="#章統計学の基本">1-2章：統計学の基本</a>
            <ul>
            <li><a href="#記述統計と推測統計">2. 記述統計と推測統計</a></li>
            <li><a href="#データの種類">3. データの種類</a></li>
            <li><a href="#母集団と標本">4. 母集団と標本</a></li>
            <li><a href="#確率変数と確率分布">5. 確率変数と確率分布</a></li>
            <li><a href="#単純ランダムサンプリングたまたまの意味">6. 単純ランダムサンプリング：「たまたま」の意味</a></li>
            </ul></li>
            <li><a href="#章確率の基本">1-3章：確率の基本</a>
            <ul>
            <li><a href="#標本空間と事象">2. 標本空間と事象</a></li>
            <li><a href="#確率">3. 確率</a></li>
            <li><a href="#確率の加法定理">4. <u>確率の加法定理</u></a></li>
            <li><a href="#条件付き確率">5. 条件付き確率</a></li>
            <li><a href="#確率の乗法定理">6. <u>確率の乗法定理</u></a></li>
            <li><a href="#独立">7. 独立</a></li>
            </ul></li>
            <li><a href="#章確率分布の基本">1-4章：確率分布の基本</a>
            <ul>
            <li><a href="#確率分布">2. 確率分布</a></li>
            <li><a href="#離散型の確率分布と確率質量関数">3. 離散型の確率分布と確率質量関数</a></li>
            <li><a href="#連続型の確率分布と確率密度関数">4. 連続型の確率分布と確率密度関数</a></li>
            <li><a href="#確率変数の期待値">5. 確率変数の期待値</a></li>
            <li><a href="#確率変数の分散と標準偏差">6. 確率変数の分散と標準偏差</a></li>
            <li><a href="#確率変数のパーセント点中央値四分位点">7. 確率変数のパーセント点・中央値・四分位点</a></li>
            <li><a href="#同時分布周辺分布条件付き分布">8. 同時分布・周辺分布・条件付き分布</a></li>
            <li><a href="#離散型の確率分布離散位置用分布">9. 離散型の確率分布：離散位置用分布</a></li>
            <li><a href="#離散型の確率分布ベルヌーイ分布">10. 離散型の確率分布：ベルヌーイ分布</a></li>
            <li><a href="#母数">11. 母数</a></li>
            <li><a href="#離散型の確率分布二項分布">12. 離散型の確率分布：二項分布</a></li>
            <li><a href="#二項分布">★二項分布</a></li>
            <li><a href="#離散型の確率分布ポワソン分布">13. 離散型の確率分布：ポワソン分布</a></li>
            <li><a href="#ポワソン分布">★ポワソン分布</a></li>
            <li><a href="#連続型の確率分布連続一様分布">14. 連続型の確率分布：連続一様分布</a></li>
            <li><a href="#連続型の確率分布正規分布とその周辺">15. 連続型の確率分布：正規分布とその周辺</a></li>
            <li><a href="#正規分布">★正規分布</a></li>
            <li><a href="#対数正規分布">★対数正規分布</a></li>
            <li><a href="#ガンマ分布">★ガンマ分布</a></li>
            </ul></li>
            <li><a href="#章統計モデルの基本">1-5章：統計モデルの基本</a>
            <ul>
            <li><a href="#モデルとは何か">2. モデルとは何か</a></li>
            <li><a href="#コイン投げモデルと白玉黒玉抽出モデル">3. コイン投げモデルと白玉黒玉抽出モデル</a></li>
            <li><a href="#確率分布と確率密度関数確率質量関数">4. 確率分布と確率密度関数、確率質量関数</a></li>
            <li><a href="#正規分布を用いたモデル">5. 正規分布を用いたモデル</a></li>
            <li><a href="#説明変数を導入したモデル">6. 説明変数を導入したモデル</a></li>
            <li><a href="#正規分布に従うけど気温による線形の影響も受ける売り上げの分布">★正規分布に従うけど、気温による線形の影響も受ける売り上げの分布</a></li>
            <li><a href="#確率モデルとデータの対応づけ">7. 確率モデルとデータの対応づけ</a></li>
            <li><a href="#尤度">8. 尤度</a></li>
            <li><a href="#確率モデルと尤度の関係">9. 確率モデルと尤度の関係</a></li>
            </ul></li>
            <li><a href="#章ベイズ推論の基本">1-6章:ベイズ推論の基本</a>
            <ul>
            <li><a href="#不確実性を確率で表現">2. 不確実性を確率で表現</a></li>
            <li><a href="#事前確率と事後確率">3. 事前確率と事後確率</a></li>
            <li><a href="#理由不十分の原則">4. 理由不十分の原則</a></li>
            <li><a href="#尤度周辺尤度">5. 尤度、周辺尤度</a></li>
            <li><a href="#ベイズの定理">6. ベイズの定理</a></li>
            <li><a href="#ベイズの定理の導出">7. ベイズの定理の導出</a></li>
            <li><a href="#ベイズの定理と統計モデルの関係">8. ベイズの定理と統計モデルの関係　</a></li>
            <li><a href="#無情報事前分布">9. 無情報事前分布</a></li>
            <li><a href="#事後分布の計算例と事後分布のカーネル">10. 事後分布の計算例と事後分布のカーネル(?)</a></li>
            <li><a href="#モデルに基づく現象の解釈">11. モデルに基づく現象の解釈</a></li>
            <li><a href="#ベイズ推論の難点とmcmc">12. ベイズ推論の難点とMCMC</a></li>
            </ul></li>
            <li><a href="#章-mcmcの基本">1-7章: MCMCの基本</a>
            <ul>
            <li><a href="#概要">1. 概要</a></li>
            <li><a href="#mcmcとは何か">2. MCMCとは何か</a></li>
            <li><a href="#確率分布に従う乱数の例">★確率分布に従う乱数の例</a></li>
            <li><a href="#mcmcと統計モデリングの関わり">3. MCMCと統計モデリングの関わり</a></li>
            <li><a href="#モンテカルロ法">4. モンテカルロ法</a></li>
            <li><a href="#モンテカルロ積分">5. モンテカルロ積分</a></li>
            <li><a href="#マルコフ連鎖">6. マルコフ連鎖</a></li>
            <li><a href="#定常分布">7. 定常分布</a></li>
            <li><a href="#スマホユーザーの例">★スマホユーザーの例</a></li>
            <li><a href="#mcmcが目指すこと">8. MCMCが目指すこと</a></li>
            <li><a href="#メトロポリスヘイスティングス法mh法">9. メトロポリス・ヘイスティングス法（MH法）</a></li>
            <li><a href="#mh法の計算例">10. MH法の計算例</a></li>
            <li><a href="#メトロポリスヘイスティングス法の実装例">★メトロポリス・ヘイスティングス法の実装例</a></li>
            <li><a href="#mh法の欠点">11. MH法の欠点</a></li>
            <li><a href="#ハミルトニアンモンテカルロ法hmc法">12. ハミルトニアン・モンテカルロ法（HMC法）</a></li>
            <li><a href="#乱数の取り扱いの注意点">13. 乱数の取り扱いの注意点</a></li>
            <li><a href="#繰り返し数iterの設定">14. 繰り返し数(iter)の設定</a></li>
            <li><a href="#バーンイン期間warmupの設定">15. バーンイン期間(warmup)の設定</a></li>
            <li><a href="#間引きthinの設定">16. 間引き(thin)の設定</a></li>
            <li><a href="#チェーンchainsの設定">17. チェーン(chains)の設定</a></li>
            <li><a href="#収束の判定">18. 収束の判定</a></li>
            <li><a href="#点推定と区間推定">19. 点推定と区間推定</a></li>
            <li><a href="#ベイズ信用区間">20. ベイズ信用区間</a></li>
            <li><a href="#事後中央値med-posteriori-median">21. 事後中央値(MED; posteriori median)</a></li>
            <li><a href="#事後期待値eap-expected-a-posteriori">22. 事後期待値(EAP; expected a posteriori)</a></li>
            <li><a href="#事後確率最大値map-maximum-a-posteriori">23. 事後確率最大値(MAP; maximum a posteriori)</a></li>
            </ul></li>
            <li><a href="#の補足-緑本のmcmc">1-7の補足: 緑本のMCMC</a>
            <ul>
            <li><a href="#緑本の-種子の例のヒストグラムと対数尤度関数">★緑本の 「種子の例」のヒストグラムと対数尤度関数</a></li>
            <li><a href="#ふらふら最尤推定">★ふらふら最尤推定</a></li>
            <li><a href="#メトロポリス法の実装例">★メトロポリス法の実装例</a></li>
            </ul></li>
            <li><a href="#章">2章</a></li>
            <li><a href="#章rの基本">2-1章：Rの基本</a>
            <ul>
            <li><a href="#目的と概要">1. 目的と概要</a></li>
            <li><a href="#rのインストール">2. Rのインストール</a></li>
            <li><a href="#rstudioのインストール">3. RStudioのインストール</a></li>
            <li><a href="#rstudioの使い方">4. RStudioの使い方</a></li>
            <li><a href="#変数">5. 変数</a></li>
            <li><a href="#関数">6. 関数</a></li>
            <li><a href="#ベクトル">7. ベクトル</a></li>
            <li><a href="#行列">8. 行列</a></li>
            <li><a href="#配列">9. 配列</a></li>
            <li><a href="#データフレーム">10. データフレーム</a></li>
            <li><a href="#リスト">11. リスト</a></li>
            <li><a href="#データの抽出">12. データの抽出</a></li>
            <li><a href="#時系列データts">13. 時系列データ(ts)</a></li>
            <li><a href="#ファイルからのデータ読み込み">14. ファイルからのデータ読み込み</a></li>
            <li><a href="#乱数の生成">15. 乱数の生成</a></li>
            <li><a href="#繰り返し構文とforループ">16. 繰り返し構文とforループ</a></li>
            <li><a href="#外部パッケージの活用">17. 外部パッケージの活用</a></li>
            </ul></li>
            <li><a href="#章-データの要約">2-2章: データの要約</a>
            <ul>
            <li><a href="#度数度数分布ヒストグラム">2. 度数・度数分布・ヒストグラム</a></li>
            <li><a href="#カーネル密度推定">3. カーネル密度推定</a></li>
            <li><a href="#算術平均">4. 算術平均</a></li>
            <li><a href="#中央値四分位点パーセント点">5. 中央値・四分位点・パーセント点</a></li>
            <li><a href="#共分散とピアソンの積率相関係数">6. 共分散とピアソンの積率相関係数</a></li>
            <li><a href="#自己共分散自己相関係数コレログラム">7. 自己共分散・自己相関係数・コレログラム</a></li>
            </ul></li>
            <li><a href="#章-ggplot2によるデータの可視化">2-3章 ggplot2によるデータの可視化</a>
            <ul>
            <li><a href="#ggplot2の基本">2. ggplot2の基本</a></li>
            <li><a href="#データの読み込み">3. データの読み込み</a></li>
            <li><a href="#ヒストグラムとカーネル密度推定">4. ヒストグラムとカーネル密度推定</a></li>
            <li><a href="#グラフの重ね合わせと一覧表示">5. グラフの重ね合わせと一覧表示</a></li>
            <li><a href="#箱ひげ図とバイオリンプロット">3.6 箱ひげ図とバイオリンプロット</a></li>
            <li><a href="#散布図">3.7 散布図</a></li>
            <li><a href="#折れ線グラフ">3.8 折れ線グラフ</a></li>
            </ul></li>
            <li><a href="#の補足ggplot2の考え方rグラフィックブック付録a">2-3の補足：ggplot2の考え方(Rグラフィックブック付録A)</a>
            <ul>
            <li><a href="#wideフォーマットとlongフォーマット">wideフォーマットとlongフォーマット</a></li>
            <li><a href="#ggplotの用語">ggplotの用語</a></li>
            <li><a href="#基本的な使い方">基本的な使い方</a></li>
            </ul></li>
            <li><a href="#章-stanの基本">2-4章 Stanの基本</a>
            <ul>
            <li><a href="#stanのインストール">2. Stanのインストール</a></li>
            <li><a href="#サンプルとmcmcサンプル">3. サンプルとMCMCサンプル</a></li>
            <li><a href="#ここで推定するモデルの構造">4. ここで推定するモデルの構造</a></li>
            <li><a href="#rとstan">5. RとStan</a></li>
            <li><a href="#stanファイルの書き方">6. Stanファイルの書き方</a></li>
            <li><a href="#stanファイルの実装例">7. Stanファイルの実装例</a></li>
            <li><a href="#rファイル実装の流れ">8. Rファイル実装の流れ</a></li>
            <li><a href="#分析の準備">9. 分析の準備</a></li>
            <li><a href="#データ読み込み">10. データ読み込み</a></li>
            <li><a href="#list形式でデータをまとめる">11. list形式でデータをまとめる</a></li>
            <li><a href="#stanと連携してmcmc実行">12. Stanと連携してMCMC実行</a></li>
            <li><a href="#結果の確認">13. 結果の確認</a></li>
            <li><a href="#収束の確認">14. 収束の確認</a></li>
            <li><a href="#ベクトル化">15. ベクトル化</a></li>
            <li><a href="#モデルの図式化">16. モデルの図式化</a></li>
            </ul></li>
            <li><a href="#stanコーディングの詳細">2-6. Stanコーディングの詳細</a>
            <ul>
            <li><a href="#stanファイルの構造">2. Stanファイルの構造</a></li>
            <li><a href="#変数の宣言">3. 変数の宣言</a></li>
            <li><a href="#代入">4. 代入</a></li>
            <li><a href="#サンプリング文">5. サンプリング文</a></li>
            <li><a href="#弱情報事前分布の設定">6. 弱情報事前分布の設定</a></li>
            <li><a href="#mcmcの実行">2. MCMCの実行</a></li>
            <li><a href="#mcmcサンプルの抽出">3. MCMCサンプルの抽出</a></li>
            <li><a href="#mcmcサンプルの代表値の計算">4. MCMCサンプルの代表値の計算</a></li>
            <li><a href="#トレースプロットの描画">5. トレースプロットの描画</a></li>
            <li><a href="#事後予測チェックの概要">10. 事後予測チェックの概要</a></li>
            <li><a href="#事後予測チェックの対象となるデータとモデル">11. 事後予測チェックの対象となるデータとモデル</a></li>
            </ul></li>
            <li><a href="#stanコーディングの詳細-1">2-6. Stanコーディングの詳細</a>
            <ul>
            <li><a href="#stanファイルの構造-1">2. Stanファイルの構造</a></li>
            <li><a href="#変数の宣言-1">3. 変数の宣言</a></li>
            <li><a href="#代入-1">4. 代入</a></li>
            <li><a href="#サンプリング文-1">5. サンプリング文</a></li>
            <li><a href="#弱情報事前分布の設定-1">6. 弱情報事前分布の設定</a></li>
            <li><a href="#対数密度加算文">7. 対数密度加算文</a></li>
            <li><a href="#平均値の差の評価とgenerated-quantitiesブロック">8. 平均値の差の評価とgenerated quantitiesブロック</a></li>
            <li><a href="#練習問題">練習問題</a></li>
            </ul></li>
            <li><a href="#章-1">3章</a></li>
            <li><a href="#章-一般化線形モデルの基本">3-1章: 一般化線形モデルの基本</a>
            <ul>
            <li><a href="#目的と概要-1">1. 目的と概要</a></li>
            <li><a href="#複雑なモデルを構築する際の手続きの標準化">2. 複雑なモデルを構築する際の手続きの標準化</a></li>
            <li><a href="#確率分布線形予測子リンク関数">3. 確率分布・線形予測子・リンク関数</a></li>
            <li><a href="#一般化線形モデルの例-説明変数が無く正規分布を仮定するモデル">4. 一般化線形モデルの例: 説明変数が無く、正規分布を仮定するモデル</a></li>
            <li><a href="#単回帰モデル-説明変数が1つだけあり正規分布を仮定するモデル">5. 単回帰モデル: 説明変数が1つだけあり、正規分布を仮定するモデル</a></li>
            <li><a href="#分散分析モデルダミー変数を利用するモデル">6. 分散分析モデル：ダミー変数を利用するモデル</a></li>
            <li><a href="#正規線形モデル正規分布を仮定するモデル">7. 正規線形モデル：正規分布を仮定するモデル</a></li>
            <li><a href="#ポアソン回帰モデル">8. ポアソン回帰モデル</a></li>
            <li><a href="#ロジスティック回帰モデル-二項分布を仮定するモデル">9. ロジスティック回帰モデル: 二項分布を仮定するモデル</a></li>
            <li><a href="#一般化線形モデルの行列表現">10. 一般化線形モデルの行列表現</a></li>
            <li><a href="#補足データの表記とベクトル行列">11. 補足：データの表記とベクトル・行列</a></li>
            <li><a href="#補足行列の基本的な演算">12. 補足：行列の基本的な演算</a></li>
            <li><a href="#行列の掛け算">13. 行列の掛け算</a></li>
            <li><a href="#一般化線形モデルのさまざまなトピック">14. 一般化線形モデルのさまざまなトピック</a></li>
            <li><a href="#例題-伊丸岡研の希望人数に実験科目を担当していたかがどう影響するか">例題: 伊丸岡研の希望人数に実験科目を担当していたかがどう影響するか</a></li>
            <li><a href="#目的と概要-2">2.1 目的と概要</a></li>
            <li><a href="#分析の準備-1">2.2 分析の準備</a></li>
            <li><a href="#データ読み込みと可視化">2.3 データ読み込みと可視化</a></li>
            <li><a href="#モデルの構造">2.4 モデルの構造</a></li>
            <li><a href="#単回帰モデルのためのstanファイルの実装">2.5 単回帰モデルのためのStanファイルの実装</a></li>
            <li><a href="#mcmcの実行-2.7-事後分布の可視化">2.6 MCMCの実行, 2.7 事後分布の可視化</a></li>
            <li><a href="#まとめ">2.8 まとめ</a></li>
            </ul></li>
            <li><a href="#章-一般化線形モデルの基本-1">3-1章: 一般化線形モデルの基本</a>
            <ul>
            <li><a href="#目的と概要-3">1. 目的と概要</a></li>
            <li><a href="#複雑なモデルを構築する際の手続きの標準化-1">2. 複雑なモデルを構築する際の手続きの標準化</a></li>
            <li><a href="#確率分布線形予測子リンク関数-1">3. 確率分布・線形予測子・リンク関数</a></li>
            <li><a href="#一般化線形モデルの例-説明変数が無く正規分布を仮定するモデル-1">4. 一般化線形モデルの例: 説明変数が無く、正規分布を仮定するモデル</a></li>
            <li><a href="#単回帰モデル-説明変数が1つだけあり正規分布を仮定するモデル-1">5. 単回帰モデル: 説明変数が1つだけあり、正規分布を仮定するモデル</a></li>
            <li><a href="#分散分析モデルダミー変数を利用するモデル-1">6. 分散分析モデル：ダミー変数を利用するモデル</a></li>
            <li><a href="#正規線形モデル正規分布を仮定するモデル-1">7. 正規線形モデル：正規分布を仮定するモデル</a></li>
            <li><a href="#ポアソン回帰モデル-1">8. ポアソン回帰モデル</a></li>
            <li><a href="#ロジスティック回帰モデル-二項分布を仮定するモデル-1">9. ロジスティック回帰モデル: 二項分布を仮定するモデル</a></li>
            </ul></li>
            <li><a href="#章-単回帰モデル">3-2章: 単回帰モデル</a>
            <ul>
            <li><a href="#分析の準備---8.-まとめ">2. 分析の準備 - 8. まとめ</a></li>
            </ul></li>
            <li><a href="#章-モデルを用いた予測">3-3章: モデルを用いた予測</a>
            <ul>
            <li><a href="#分析の準備-2">2. 分析の準備</a></li>
            <li><a href="#単回帰モデルにおける予測の考え方">3. 単回帰モデルにおける予測の考え方</a></li>
            <li><a href="#予測のためのデータの整理">4. 予測のためのデータの整理</a></li>
            <li><a href="#予測のためのstanファイルの修正">5. 予測のためのStanファイルの修正</a></li>
            <li><a href="#mcmcの実行-1">6. MCMCの実行</a></li>
            <li><a href="#予測分布の可視化">7. 予測分布の可視化</a></li>
            </ul></li>
            <li><a href="#章-デザイン行列を用いた一般化線形モデルの推定">3-4章: デザイン行列を用いた一般化線形モデルの推定</a>
            <ul>
            <li><a href="#分析の準備-3">2. 分析の準備</a></li>
            <li><a href="#デザイン行列を使ったモデルの数学的な表現">3. デザイン行列を使ったモデルの数学的な表現</a></li>
            <li><a href="#formula構文を用いたデザイン行列の作成">4. formula構文を用いたデザイン行列の作成</a></li>
            <li><a href="#デザイン行列を使うためのstanファイルの設定">5. デザイン行列を使うためのStanファイルの設定</a></li>
            <li><a href="#mcmcの実行-2">6. MCMCの実行</a></li>
            </ul></li>
            <li><a href="#brmsの使い方">3-5. brmsの使い方</a>
            <ul>
            <li><a href="#brmsとは">2. brmsとは</a></li>
            <li><a href="#本書での実装の方針">3. 本書での実装の方針</a></li>
            <li><a href="#分析の準備-4">4. 分析の準備</a></li>
            <li><a href="#brmsによる単回帰モデルの推定">5. brmsによる単回帰モデルの推定</a></li>
            <li><a href="#brmsの基本的な使い方">6. brmsの基本的な使い方</a></li>
            <li><a href="#事前分布の変更">7. 事前分布の変更</a></li>
            <li><a href="#補足brmsの基本的な仕組み">8. 補足：brmsの基本的な仕組み</a></li>
            </ul></li>
            </ul>
          </div>
          <div data-position="sidebar:post-end" class="InjectedComponents"><div class="dark-theme-toggler"><div class="toggle "><div class="toggle-track"><div class="toggle-track-check"><img  src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16"></div> <div class="toggle-track-x"><img src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16"></div></div> <div class="toggle-thumb"></div></div> <input type="checkbox" aria-label="Switch between Dark and Default theme" class="toggler-screen-reader-only"></div></div>
        </div>
        <div class="Main">
          <div class="Content" id="content"> 
   
   
      
      <div class="navbar navbar-default  navbar-fixed-top" role="navigation">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">my public memo</a>
          </div>
          <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li>
        <a href="index.html">Home</a>
      </li>
      <li>
        <a href="baba.html">馬場本</a>
      </li>
      <li>
        <a href="psytech.html">技術部</a>
      </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              
            </ul>
          </div><!--/.nav-collapse -->
        </div><!--/.container -->
      </div><!--/.navbar -->
        
      <h1 class="title">馬場本</h1>
      
      <p class="authors">
           <span class="glyphicon glyphicon-user"></span> Toshihide Imaruoka
      </p>
              

   
      
   
<!-- Don't indent these lines or it will mess pre blocks indentation --> 
<div class="page-content has-page-title">
<div id="章ベイズ統計モデリングの基本" class="section level1">
<h1>1-1章：ベイズ統計モデリングの基本</h1>
<div id="統計モデリング" class="section level2">
<h2>2. 統計モデリング</h2>
<ul>
<li>身長の分布</li>
</ul>
</div>
<div id="統計モデルの有用性" class="section level2">
<h2>3. 統計モデルの有用性</h2>
<ul>
<li>一部のデータから全体を推測</li>
</ul>
</div>
</div>
<div id="章統計学の基本" class="section level1">
<h1>1-2章：統計学の基本</h1>
<div id="記述統計と推測統計" class="section level2">
<h2>2. 記述統計と推測統計</h2>
<ul>
<li>記述統計：データの要約</li>
<li>推測統計：全体の推測</li>
</ul>
</div>
<div id="データの種類" class="section level2">
<h2>3. データの種類</h2>
<ul>
<li>量的データと質的データ
<ul>
<li>量的データ・数量データ</li>
<li>質的データ・カテゴリデータ</li>
</ul></li>
<li>尺度
<ul>
<li>名義尺度</li>
<li>順序尺度</li>
<li>（感覚尺度）</li>
<li>（比率尺度）</li>
</ul></li>
<li>連続型データと離散型データ</li>
<li>時系列データとトランザクションデータ</li>
</ul>
</div>
<div id="母集団と標本" class="section level2">
<h2>4. 母集団と標本</h2>
<ul>
<li>母集団：興味ある対象全体</li>
<li>標本：母集団の部分集合, サンプリング（標本抽出）によって得る。サンプリングサイズ＝1回のサンプリングのデータ個数。</li>
<li>全数調査と標本調査</li>
<li>単純ランダムサンプリング＝無作為抽出：母集団からのランダムな抽出。方法などを特定しない。</li>
</ul>
</div>
<div id="確率変数と確率分布" class="section level2">
<h2>5. 確率変数と確率分布</h2>
<ul>
<li>確率変数：何らかの確率的法則にしたがって値が変化する量
<ul>
<li>そのときの「何らか」が確率分布? -&gt; 1-4でも説明</li>
</ul></li>
<li>実現値：確率変数の具体的な値。確率変数<span class="math inline">\(X\)</span>の具現値<span class="math inline">\(x\)</span>。<span class="math inline">\(P(X=x)X\)</span>が<span class="math inline">\(x\)</span>となる確率<span class="math inline">\(P\)</span>。コインの表裏の確率 -&gt; {<span class="math inline">\(P(X=1)\)</span>, <span class="math inline">\(P(X=0)\)</span>}={0.5, 0.5}。</li>
</ul>
</div>
<div id="単純ランダムサンプリングたまたまの意味" class="section level2">
<h2>6. 単純ランダムサンプリング：「たまたま」の意味</h2>
</div>
</div>
<div id="章確率の基本" class="section level1">
<h1>1-3章：確率の基本</h1>
<div id="標本空間と事象" class="section level2">
<h2>2. 標本空間と事象</h2>
<ul>
<li>試行：観測や実験</li>
<li>標本空間：試行によって<u>起こりうる</u>結果の集合＝Ω（オメガ）</li>
<li>事象：標本空間の部分集合＝試行の集合の一部
<ul>
<li>和集合：A⋃B または</li>
<li>積集合：A⋂B かつ</li>
<li>排反事象</li>
<li>空事象</li>
</ul></li>
</ul>
</div>
<div id="確率" class="section level2">
<h2>3. 確率</h2>
<ul>
<li>事象Aが生起する確率 -&gt; <span class="math inline">\(P(A)\)</span></li>
<li>主観確率：&lt;-&gt;客観確率。Wikipediaによると哲学的問題。</li>
<li>確率の功利主義的定義
<ul>
<li>全ての事象：<span class="math inline">\(0≤P(A)≤1\)</span></li>
<li>標本空間全体を対象とすると確率は1：<span class="math inline">\(P(\Omega)=1\)</span></li>
<li>排反事象の<u>どれか</u>が起きる確率は、それら事象の確率の和</li>
</ul></li>
</ul>
</div>
<div id="確率の加法定理" class="section level2">
<h2>4. <u>確率の加法定理</u></h2>
<ul>
<li><span class="math inline">\(P(A1\cup A2)=P(A1)+P(A2)\)</span>、ただしA1とA2が排反事象のとき</li>
<li>背反ではないときは<span class="math inline">\(P(A\cup B)=P(A)+P(B)-P(A\cap B)\)</span></li>
</ul>
</div>
<div id="条件付き確率" class="section level2">
<h2>5. 条件付き確率</h2>
<ul>
<li><span class="math inline">\(P(A|B)\)</span>: 事象Bが起きた下での事象Aの条件付き確率</li>
<li><span class="math inline">\(p(A|B)=\frac{P(A\cap B)}{P(B)}\)</span></li>
<li><u>やや直感的ではない部分。分母にP(B)がくるので、分子の確率よりは必ず大きくなる。雨が降ったという条件の下で雷がなる確率という例が分かりやすい。</u></li>
</ul>
</div>
<div id="確率の乗法定理" class="section level2">
<h2>6. <u>確率の乗法定理</u></h2>
<ul>
<li><span class="math inline">\(P(A\cap B)=P(A|B)P(B)\)</span></li>
<li><u>雷が落ちて、かつ雨が降る確率。雨が降った時に雷がなるという条件付き確率に雨が降る確率をかける。</u></li>
</ul>
</div>
<div id="独立" class="section level2">
<h2>7. 独立</h2>
<ul>
<li>事象Aと事象Bが独立なら、</li>
<li><span class="math inline">\(P(A\cap B)=P(A)P(B)\)</span></li>
<li><span class="math inline">\(P(A|B)\)</span>を<span class="math inline">\(P(A)\)</span>と同じだと考えているということと同義。事象Bが起きたという条件での<span class="math inline">\(P(A)\)</span>だけど、事象Bと事象Aは独立（関係ない）ので、<span class="math inline">\(P(A|B)\)</span>と<span class="math inline">\(P(A)\)</span>は同じということ。</li>
<li>簡単のため、独立という仮定を置くことも多い</li>
</ul>
</div>
</div>
<div id="章確率分布の基本" class="section level1">
<h1>1-4章：確率分布の基本</h1>
<div id="確率分布" class="section level2">
<h2>2. 確率分布</h2>
<ul>
<li>確率分布：確率変数とそれに対応する確率≒分布</li>
<li><span class="math inline">\(X~P(x)\)</span>: 確率変数Xが、ある確率分布P(x)に従うという意味</li>
<li><span class="math inline">\(x~P(x)\)</span>と書いたりもする</li>
</ul>
</div>
<div id="離散型の確率分布と確率質量関数" class="section level2">
<h2>3. 離散型の確率分布と確率質量関数</h2>
<ul>
<li>質的データや離散型データ -&gt; 離散型の確率分布を使う</li>
<li>確率質量関数（<span class="math inline">\(pmf\)</span>）：<span class="math inline">\(P(X=xi)\)</span>(&lt;-確率変数Xがある実現値xiを取る確率)を計算できる関数<span class="math inline">\(f(xi)\)</span>のこと
<ul>
<li>公理より</li>
<li><span class="math inline">\(f(x)\ge0\)</span>: ある事象が起きる確率は0以上</li>
<li><span class="math inline">\(\sum f(x)=1\)</span>: 標本空間確率の和は1</li>
<li><span class="math inline">\(P(a≤X≤b)=\sum_{i=1}^b f(xi)\)</span> iはaからbまで</li>
<li>Xがa以上b以下である確率はP(a)からP(b)までの和と等しい</li>
</ul></li>
</ul>
</div>
<div id="連続型の確率分布と確率密度関数" class="section level2">
<h2>4. 連続型の確率分布と確率密度関数</h2>
<ul>
<li>連続型データには連続型の確率分布</li>
<li>ある値に<u>厳密に</u>一致する確率は0</li>
<li>確率密度という考え方</li>
<li>Δx -&gt; 0のとき：xの増加量が0のとき、<span class="math inline">\(x\ge X\ge x+\Delta x\)</span>を考えると、<span class="math inline">\(P(x\ge X\ge x+\Delta x)\)</span>は次のように表される
<ul>
<li><span class="math inline">\(P(x\le X\le x+\Delta x)=f(x)\cdot \Delta x\)</span>：このときΔxは非常に小さいだけで0ではない。Proability Density Function <span class="math inline">\(pdf\)</span>。</li>
<li>一般化：<span class="math inline">\(P(a\le X\le b)=\int_a^bf(x)dx\)</span> aからbまでの積分</li>
<li>xの範囲が全てだと積分値は1
<ul>
<li>pmfとの違いは実はΣが∫になっただけ（なのでイメージ的には同じようなもの）</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="確率変数の期待値" class="section level2">
<h2>5. 確率変数の期待値</h2>
<ul>
<li>離散型Xの期待値：<span class="math inline">\(E(X)=\sum_{x_i=1}^N f(x_i)\cdot x_i\)</span>（xiになる確率 × xiをiが1からNまで足す）</li>
<li>連続型Xの期待値：<span class="math inline">\(E(X)=\int_{-\infty}^\infty f(x)\cdot x dx\)</span></li>
</ul>
</div>
<div id="確率変数の分散と標準偏差" class="section level2">
<h2>6. 確率変数の分散と標準偏差</h2>
<ul>
<li>離散型：<span class="math inline">\(V(X)=\sum_{i=1}^Nf(xi)\cdot(xi-E(X))^2\)</span> （期待値を平均とした通常の分散の式）</li>
<li>連続型：<span class="math inline">\(V(X)=\int_\infty^\infty f(x)\cdot(x-E(X))^2 dx\)</span></li>
<li><span class="math inline">\(SD = \sqrt V(X)\)</span></li>
</ul>
</div>
<div id="確率変数のパーセント点中央値四分位点" class="section level2">
<h2>7. 確率変数のパーセント点・中央値・四分位点</h2>
<ul>
<li>パーセント点：Xがxiより小さくなる確率が例えば10%のとき、xiを10％点と呼ぶ。50%のときが中央値。このように?%より小さくなる点のことを下側パーセント点とも呼び、この本では下側パーセント点のみ使われる。</li>
</ul>
</div>
<div id="同時分布周辺分布条件付き分布" class="section level2">
<h2>8. 同時分布・周辺分布・条件付き分布</h2>
<ul>
<li>同時確率分布＝同時分布＝結合分布：2つの確率変数が同時にある値xiとyiを取る確率分布。確率分布なので確率質量関数の和は1（今は離散的な変数のことを考えている）。
<ul>
<li><span class="math inline">\(\sum_{i=1}^{m}\sum_{j=1}^{n}P(X=x_i, Y=y_j)=\sum_{i=1}^{m}\sum_{j=1}^{n}p_{ij}=1, i=1,2,...m, j=1,2,...n\)</span></li>
</ul></li>
<li>周辺化: 同時分布からある変数を消去する計算のこと。例えば上の例からYを消去する。
<ul>
<li>周辺分布：<span class="math inline">\(P(X=x_i)=\sum_{j=1}^nP(X=x_i,Y=y_j)=\sum_{j=1}^{n}p_{ij}\)</span>　(シグマはjが1からnまで。Xをxiで固定しておいてy1からynまでの和。P37の具体例を見るべき。)</li>
</ul></li>
<li>条件付き確率分布＝条件付き分布：片方の確率変数を固定した条件での他方の確率分布のこと。yjに固定されているという条件下でのXの確率分布。
<ul>
<li><span class="math inline">\(P(X=x_i|Y=y_j)=P(X=x_i,Y=y_j)/P(Y=y_j)=P_{ij}/P_j P(X|Y)\)</span>とも書く。</li>
<li>Yがyjという条件下でのXの確率分布のこと。</li>
<li>上の式を変形する（Yの条件付きXの確率分布＝XYの同時分布/Yの確率分布という式をXYの同時分布＝Yの条件付きXの確率分布・Yの確率分布に変形）</li>
<li><span class="math inline">\(P(X=x_i,Y=y_j)=P(X=x_i|Y=y_j)P(Y=y_j)\)</span></li>
<li>そうすると、周辺化の式も書き換え可能</li>
<li>周辺化によるXの確率分布：<span class="math inline">\(P(X=xi)=\sum_{j=1}^nP(X=x_i|Y=y_j)P(Y=y_j)\)</span>
<ul>
<li>Xの確率分布=Xの条件付き分布・Yの確率分布</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="離散型の確率分布離散位置用分布" class="section level2">
<h2>9. 離散型の確率分布：離散位置用分布</h2>
<ul>
<li>すべてが同じ確率を持つ分布。サイコロの目。</li>
</ul>
</div>
<div id="離散型の確率分布ベルヌーイ分布" class="section level2">
<h2>10. 離散型の確率分布：ベルヌーイ分布</h2>
<ul>
<li>2つの結果しか生じないもの。コインの裏表。
<ul>
<li>一方を成功確率と呼ぶ。</li>
</ul></li>
<li>一方の確率が高いことを認める（そういう場合もある）
<ul>
<li>成功率p, 成功を1、失敗を0としたとき</li>
<li><span class="math inline">\(Bernoulli(X=1)=p\)</span></li>
<li><span class="math inline">\(Bernoulli(X=0)=1-p\)</span></li>
</ul></li>
</ul>
</div>
<div id="母数" class="section level2">
<h2>11. 母数</h2>
<ul>
<li>母数＝パラメータ
<ul>
<li>例：ベルヌーイ分布の場合、成功確率pが母数</li>
</ul></li>
</ul>
</div>
<div id="離散型の確率分布二項分布" class="section level2">
<h2>12. 離散型の確率分布：二項分布</h2>
<ul>
<li>ベルヌーイ分布に従う独立な試行を複数回実施したときの確率分布</li>
<li>表が出る確率pのコインをN回投げる、のような状況で、表がx回出る確率
<ul>
<li><span class="math inline">\(Binom(X|N,p)={}_N C_x\cdotp^x\cdot(1-p)^{N-x}\)</span>: 母数pのN回の試行でXがxになる確率分布。</li>
<li>e.g., 0.2の確率で表が出るコインを10回投げて10回表が出る確率、のような事象</li>
<li>matlab関数だと
<ul>
<li>x=0:10;<br />
</li>
<li>y=binopdf(x,10,0.5)</li>
<li>figure, line(x,y)</li>
</ul></li>
</ul></li>
<li>期待値：E(X)=Np</li>
<li>分散：V(X)=Np(1-p)</li>
</ul>
</div>
<div id="二項分布" class="section level2">
<h2>★二項分布</h2>
<pre class="r"><code># 式から
p&lt;-0.3
N&lt;-8
x&lt;-c(0:N)
y&lt;-choose(N,x)*p^x*(1-p)^(N-x)
plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-1-1.png" width="768" /></p>
<pre class="r"><code># 関数で
x&lt;-c(0:8)
y&lt;-dbinom(x,8,0.3)
plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-2-1.png" width="768" /></p>
</div>
<div id="離散型の確率分布ポワソン分布" class="section level2">
<h2>13. 離散型の確率分布：ポワソン分布</h2>
<ul>
<li>0または正の整数をとるデータの確率分布
<ul>
<li>ただし、Nが大きく、λが非常に小さいときにポアソン分布に従うとされる
<ul>
<li>野外で特定の虫を発見する確率：探す事象（N）は大きい。特定の虫を発見できる確率（<span class="math inline">\(\lambda\)</span>)は非常に小さい</li>
<li>クラス内でのテストの得点の場合、Nもさほど大きくなく、特定の点数になる確率が非常に小さいわけでもないので、ポアソン分布には従わない。</li>
</ul></li>
</ul></li>
<li>発見個体数Xが期待値λ（ラムダ）のポアソン分布に従うとき、
<ul>
<li>Poisson(X|λ)=(e<sup>-λ</sup>x)/x!</li>
</ul></li>
</ul>
</div>
<div id="ポワソン分布" class="section level2">
<h2>★ポワソン分布</h2>
<pre class="r"><code>    # 式から
    lambda&lt;-5
    x&lt;-c(0:20)
    y&lt;-exp(-lambda)*lambda^x/factorial(x)
    plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-3-1.png" width="768" /></p>
<pre class="r"><code>  # 関数で
  lmbd&lt;-5
  x&lt;-c(0:20)
  y&lt;-dpois(x,lambda=lmbd)
  plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-4-1.png" width="768" /></p>
</div>
<div id="連続型の確率分布連続一様分布" class="section level2">
<h2>14. 連続型の確率分布：連続一様分布</h2>
<ul>
<li>ある範囲内で常に等しい確率密度を持つ分布</li>
<li><span class="math inline">\(Uniform(X|a,b)=1/b-a\)</span></li>
</ul>
</div>
<div id="連続型の確率分布正規分布とその周辺" class="section level2">
<h2>15. 連続型の確率分布：正規分布とその周辺</h2>
<ul>
<li>期待値<span class="math inline">\(\mu\)</span>、分散<span class="math inline">\(\sigma^2\)</span>のとき、下の式。
<ul>
<li><span class="math inline">\(Normal(X|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})\)</span></li>
</ul></li>
<li>標準正規分布：<span class="math inline">\(\mu\)</span>=0, <span class="math inline">\(\sigma^2\)</span>=1の正規分布</li>
</ul>
</div>
<div id="正規分布" class="section level2">
<h2>★正規分布</h2>
<pre class="r"><code>    v&lt;-1
    m&lt;-0
    x&lt;-seq(-5,5,0.01)
    y&lt;-(1/sqrt(2*pi*v))*exp(-(x-m)^2/(2*v))
    plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-5-1.png" width="768" /> - 中心極限定理 -「平均<span class="math inline">\(\mu\)</span>、分散<span class="math inline">\(\sigma^2\)</span>の、独立で同一な確率分布」から得られた<span class="math inline">\(N\)</span>個の確率変数の合計値<span class="math inline">\(X_{sum}\)</span>は、<span class="math inline">\(N\)</span>が大きいときに正規分布<span class="math inline">\(Normal(N\mu,N\sigma^2)\)</span>に従う - 個々の確率分布の平均<span class="math inline">\(mu\)</span>、分散<span class="math inline">\(sigma^2\)</span>ということが変わらず、しかも試行回数が多ければ、個々の分布の形がどのようなものでも、その合計値<span class="math inline">\(X_{sum}\)</span>は平均<span class="math inline">\(N\mu\)</span>, 分散<span class="math inline">\(N\sigma^2\)</span>の正規分布に従う＝個々の試行で得られる平均値は平均<span class="math inline">\(\mu\)</span>、分散<span class="math inline">\(\sigma^2\)</span>の正規分布に従うことになる（Nで割るから）。 - 正規分布：無数の誤差の反映と考える - 対数正規分布：Xが正の値しか取らない場合の正規分布 - <span class="math inline">\(f(X)=\frac{1}{\sqrt{2\pi\sigma^2}x}exp(-\frac{(log(x)-\mu)^2}{2\sigma^2})\)</span></p>
</div>
<div id="対数正規分布" class="section level2">
<h2>★対数正規分布</h2>
<pre class="r"><code>    v&lt;-1
    m&lt;-0
    x&lt;-seq(0,3,0.01)
    y&lt;-1/(sqrt(2*pi*v)*x)*exp(-(log(x)-m)^2/(2*v))
    plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-6-1.png" width="768" /></p>
<ul>
<li>ガンマ分布
<ul>
<li><span class="math inline">\(f(X)=\frac{1}{\Gamma(k)\theta^k}x^{k-1}e^{-\frac{x}{\theta}}\)</span>
<ul>
<li><span class="math inline">\(\Gamma(z)=\int_0^\infty t^{z-1}e^{-t} dt\)</span></li>
</ul></li>
<li>ガンマ関数の実装が分からないのでガンマ分布関数を使ってプロット
<ul>
<li>shape: shape paremeter</li>
<li>scale: scale parameter</li>
<li>期待値</li>
<li><span class="math inline">\(\mu=shape * scale\)</span></li>
<li><span class="math inline">\(\sigma^2=shape * scale^2\)</span></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="ガンマ分布" class="section level2">
<h2>★ガンマ分布</h2>
<pre class="r"><code>    shp&lt;-2
    scl&lt;-2
    x&lt;-seq(0,10,0.01)
    y&lt;-dgamma(x,shape=shp, rate=1/scl)
    plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-7-1.png" width="768" /></p>
</div>
</div>
<div id="章統計モデルの基本" class="section level1">
<h1>1-5章：統計モデルの基本</h1>
<div id="モデルとは何か" class="section level2">
<h2>2. モデルとは何か</h2>
<ul>
<li>モデル：観測したデータを有無出す確率的な過程を簡潔に記述したもの (Upton and Cook, 2010)</li>
<li>モデリング＝モデルを作る行為</li>
<li>現象の理解、将来の予測
<ul>
<li>数理モデル：数式</li>
<li>確率モデル：確率的な表現を使った数理モデル</li>
<li>統計モデル：データに適用するように作られた確率モデル</li>
</ul></li>
</ul>
</div>
<div id="コイン投げモデルと白玉黒玉抽出モデル" class="section level2">
<h2>3. コイン投げモデルと白玉黒玉抽出モデル</h2>
<ul>
<li>どちらも二項分布で表現できる</li>
<li><span class="math inline">\(Y\sim Binom(10,p)\)</span>: 表が出る回数Yは試行回数10で成功確率（ここでは表）pの二項分布に従う</li>
</ul>
</div>
<div id="確率分布と確率密度関数確率質量関数" class="section level2">
<h2>4. 確率分布と確率密度関数、確率質量関数</h2>
<ul>
<li>確率分布＝データをうみ出す過程
<ul>
<li>確率は確率密度関数・確率質量関数で計算できる</li>
</ul></li>
</ul>
</div>
<div id="正規分布を用いたモデル" class="section level2">
<h2>5. 正規分布を用いたモデル</h2>
<ul>
<li>ビールの売り上げを正規分布でモデル化</li>
<li><span class="math inline">\(\mu\)</span>と<span class="math inline">\(\sigma^2\)</span>という2つのパラメータ（母数）</li>
<li><span class="math inline">\(Y\sim Normal(\mu,\sigma^2)\)</span></li>
</ul>
</div>
<div id="説明変数を導入したモデル" class="section level2">
<h2>6. 説明変数を導入したモデル</h2>
<ul>
<li>応答変数、説明変数</li>
<li>ビールの売り上げ
<ul>
<li>気温0℃のときの売り上げ：<span class="math inline">\(\beta_0\)</span></li>
<li>気温1℃上昇ごとの売り上げ増加：<span class="math inline">\(\beta_1\)</span></li>
<li><span class="math inline">\(\mu_i\sim \beta_0 + \beta_1 + x_i\)</span></li>
<li><span class="math inline">\(Y_i\sim Normal(\mu_i,\sigma^2)\)</span></li>
</ul></li>
<li>個人的にもう一つピンときてないのでやってみた。
<ul>
<li>下の2つのヒストグラムを描いてみる</li>
<li>平均が (850 x 気温 + 3500)円、標準偏差が1000円 の正規分布に従うデータ。気温は平均20℃、標準偏差3の正規分布に従うこととし、ある気温のときに100データ、100種類の気温について集め、合計10000データ。</li>
<li>平均が20000円、標準偏差が1000円の正規分布に従うデータを100個ずつ、100回取得。合計10000データ。</li>
<li>結果起きたこと</li>
<li>10000データの平均値はあまり違いはない</li>
<li>分散が大きく異る</li>
<li>ただし、どちらも正規分布に従うように見える</li>
<li>データだけから考えると、単に分散が大きい正規分布に見える
<ul>
<li>けど、実は温度というパラメータの影響を受けている</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="正規分布に従うけど気温による線形の影響も受ける売り上げの分布" class="section level2">
<h2>★正規分布に従うけど、気温による線形の影響も受ける売り上げの分布</h2>
<pre class="r"><code>b0&lt;-3000
b1&lt;-850
layout(matrix(1:2, ncol=2))
rdata1&lt;-numeric()
rdata2&lt;-numeric()
tp&lt;-numeric()
for (rp in 1:100){
  tp[rp]&lt;-rnorm(1,mean=20,sd=3)
  rdata1&lt;-append(rdata1,rnorm(100,mean=20000,sd=1000))
  rdata2&lt;-append(rdata2,rnorm(100,mean=b1*tp[rp]+b0,sd=1000))
}
hist(rdata1,xlim=c(min(rdata2),max(rdata2)),main=mean(rdata1))
hist(rdata2, xlim=c(min(rdata2),max(rdata2)),main=mean(rdata2))</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-8-1.png" width="768" /></p>
</div>
<div id="確率モデルとデータの対応づけ" class="section level2">
<h2>7. 確率モデルとデータの対応づけ</h2>
</div>
<div id="尤度" class="section level2">
<h2>8. 尤度</h2>
<ul>
<li>尤度：パラメータが所与であるという条件における、標本が得られる確率
<ul>
<li><span class="math inline">\(P(y|\theta)\)</span>: パラメータ<span class="math inline">\(\theta\)</span>のときに<span class="math inline">\(y\)</span>となる確率</li>
<li>標本<span class="math inline">\(y\)</span>を固定するとパラメータ<span class="math inline">\(\theta\)</span>の関数とみなせる＝尤度関数</li>
<li><a href="https://ja.wikipedia.org/wiki/%E5%B0%A4%E5%BA%A6%E9%96%A2%E6%95%B0#:~:text=%E5%B0%A4%E5%BA%A6%E9%96%A2%E6%95%B0%EF%BC%88%E3%82%86%E3%81%86%E3%81%A9,%E5%8D%98%E3%81%AB%E5%B0%A4%E5%BA%A6%E3%81%A8%E3%82%82%E3%81%84%E3%81%86%E3%80%82">Wikipediaの尤度関数</a>は比較的分かりやすい気がする</li>
<li>得られたデータがあって、そこからパラメータを考える</li>
</ul></li>
</ul>
</div>
<div id="確率モデルと尤度の関係" class="section level2">
<h2>9. 確率モデルと尤度の関係</h2>
<ul>
<li>モデル<span class="math inline">\(Y\sim VBinom(10,p)\)</span>: 二項分布に従う確率pの事象が10回中にでる回数Y
<ul>
<li>2回出たとすると、尤度関数は</li>
<li>尤度関数:<span class="math inline">\({}_{10} C_2\cdot\theta^2\cdot(1-\theta)^{10-2}\)</span></li>
<li>これを解いて<span class="math inline">\(\theta\)</span>を求める</li>
</ul></li>
</ul>
</div>
</div>
<div id="章ベイズ推論の基本" class="section level1">
<h1>1-6章:ベイズ推論の基本</h1>
<div id="不確実性を確率で表現" class="section level2">
<h2>2. 不確実性を確率で表現</h2>
<ul>
<li>不確実性の定量化：確率を使う</li>
</ul>
</div>
<div id="事前確率と事後確率" class="section level2">
<h2>3. 事前確率と事後確率</h2>
<ul>
<li>事前確率：データがない状態（データを取る前）に想定する確率</li>
<li>事後確率：データを得た後に想定する確率→データを所与とした条件付き確率として表す
<ul>
<li>正しいコインとイカサマコイン。イカサマコインは表が出やすい。どちらのコインか分からない状態。イカサマコインであるという仮説<span class="math inline">\(H_1\)</span>、正しいコインであるという仮説<span class="math inline">\(H_2\)</span>。一度コインを投げたら表が出た。このデータをDとする。</li>
<li>事前確率<span class="math inline">\(P(H_1)\)</span></li>
<li>事後確率<span class="math inline">\(P(H_1|D)\)</span>Dが得られたもとで<span class="math inline">\(H_1\)</span>であるという確率</li>
</ul></li>
</ul>
</div>
<div id="理由不十分の原則" class="section level2">
<h2>4. 理由不十分の原則</h2>
<ul>
<li>多くの場合事前情報はない（コインがイカサマか正しいものかに関する情報がない）</li>
<li>理由不十分の原則：事前情報がなかったら、各仮定に等しい確率を与える
<ul>
<li><span class="math inline">\(P(H_1)=0.5, P(H_2)=0.5\)</span></li>
</ul></li>
</ul>
</div>
<div id="尤度周辺尤度" class="section level2">
<h2>5. 尤度、周辺尤度</h2>
<ul>
<li>尤度（復習）：あるパラメータ条件で標本が得られる確率＝ある仮定のもとで、データが得られる確率
<ul>
<li>例えば、正しいコインであるという仮定のもとで、表が出る確率</li>
</ul></li>
<li>周辺尤度：データが得られる平均的確率
<ul>
<li>表が出る確率：イカサマコイン＝0.75, 正しいコイン＝0.5</li>
<li>周辺尤度<span class="math inline">\(P(D)=P(D|H_1)P(H_1)+P(D|H_2)P(H_2)=0.625\)</span></li>
</ul></li>
</ul>
</div>
<div id="ベイズの定理" class="section level2">
<h2>6. ベイズの定理</h2>
<ul>
<li><span class="math inline">\(P(H_1|D) = \frac{P(D|H_1)P(H_1)}{P(D)} = P(H_1)\frac{P(D|H_1)}{P(D)}\)</span></li>
<li><span class="math inline">\(事後確率 = 事前確率 \times \frac{尤度}{周辺尤度}\)</span></li>
<li><span class="math inline">\(表が出たという事象のもとでイカサマコインである確率 = データを取る前のイカサマコインである確率 \times \frac{イカサマコインであるという仮定のもとで表が出る確率}{表が出る平均的確率}\)</span></li>
<li>コインの例で表が出た後の事後確率：<span class="math inline">\(P(H_1|D)=0.5\times \frac{0.75}{0.625}=0.6\)</span></li>
<li>ベイズ更新：データから、ベイズの定理をもとに事前確率を事後確率に更新すること</li>
<li>ベイズ推論：ベイズ更新によって興味の対象となる条件付き確率などを得ること</li>
<li>次の試行ではさっきの事後確率を事前確率として計算する</li>
</ul>
</div>
<div id="ベイズの定理の導出" class="section level2">
<h2>7. ベイズの定理の導出</h2>
<ul>
<li><span class="math inline">\(P(D\cap H_1) = P(D|H_1)P(H_1) = P(H_1|D)P(D)\)</span>
<ul>
<li><span class="math inline">\(D\)</span>でかつ<span class="math inline">\(H_1\)</span>という確率＝<span class="math inline">\(H1\)</span>のもとで<span class="math inline">\(D\)</span>が得られる確率<span class="math inline">\(\times H1\)</span>である確率=<span class="math inline">\(D\)</span>であるときに<span class="math inline">\(H_1\)</span>である確率<span class="math inline">\(\times\)</span>Dである確率</li>
<li><span class="math inline">\(P(H_1)\)</span>=0.5, <span class="math inline">\(P(D|H_1)\)</span>=0.75, <span class="math inline">\(P(H_1|D)\)</span>=0.6, <span class="math inline">\(P(D)\)</span>=0.625</li>
</ul></li>
<li><span class="math inline">\(P(D|H_1)P(H_1) = P(H_1|D)P(D)\)</span>をP(D)で割る</li>
<li><span class="math inline">\(P(H_1|D)P(D)=\frac{P(D|H_1)P(H_1)}{P(D)}\)</span>&lt;-ベイズの定理</li>
<li>さらに周辺尤度を展開</li>
<li><span class="math inline">\(P(H_1|D)P(D)=\frac{P(D|H_1)P(H_1)}{\Sigma_{i=1}^{2}P(D|H_i)P(H_i)}\)</span></li>
</ul>
</div>
<div id="ベイズの定理と統計モデルの関係" class="section level2">
<h2>8. ベイズの定理と統計モデルの関係　</h2>
<ul>
<li>パラメータは確率分布であると想定、連続型
<ul>
<li>事前確率分布、事前分布（さっきの例のように事前確率0.5というんじゃなく、ということ？）</li>
<li>事後確率分布、事後分布</li>
</ul></li>
</ul>
</div>
<div id="無情報事前分布" class="section level2">
<h2>9. 無情報事前分布</h2>
<ul>
<li>理由不十分の原則みたいなもの</li>
<li>事前分布に何の想定もおけないときは、無情報事前分布を使う
<ul>
<li>分散が大きい正規分布とか幅の広い一様分布</li>
<li>パラメータがどういう値は分からないという状態</li>
<li>ベイズの定理を使って（データをもとにベイス推論を行うことで）分布を狭くする</li>
<li>この本では幅の広い連続一様分布を使うことが多い</li>
<li>でもパラメータの範囲がわかっている部分（例えば0より大きい値をとる）はそれを使う</li>
</ul></li>
</ul>
</div>
<div id="事後分布の計算例と事後分布のカーネル" class="section level2">
<h2>10. 事後分布の計算例と事後分布のカーネル(?)</h2>
<ul>
<li>5つの売り上げデータ<span class="math inline">\(x_1=2.4, x_2=3.2, x_3=2.2, x_4=4.6, x_5=3.3\)</span></li>
<li>ベイスに必要なのは事前確率（事前分布）、尤度、周辺尤度</li>
<li>確率モデルとして平均不明、分散1の正規分布を想定
<ul>
<li><span class="math inline">\(X\sim Normal(\theta, 1)\)</span>
<ul>
<li><span class="math inline">\(\theta\)</span>の事後分布を求めたい</li>
</ul></li>
<li>事前分布：分散が10000の正規分布(通常はもっと大きい分散にするらしい)</li>
<li>まずは尤度関数(標本を固定したときのパラメータの関数)を数式で表す
<ul>
<li><span class="math inline">\(Normal(X|\theta, 1)=\frac{1}{2\pi}exp(-\frac{x-\theta^2}{2})\)</span>: 通常の正規分布, 分散が1だから簡単になってる</li>
<li>尤度は各データ分の確率の積
<ul>
<li>尤度は「ある仮定が所与という条件のもとでデータが得られる確率」</li>
<li>ここではデータが5つ得れらていて、確率分布があるから、それらの確率が分かる。全ての積が尤度となる。</li>
</ul></li>
<li><span class="math inline">\(f(D|\theta)=\Pi^5_{i=1}\frac{1}{2\pi}exp(-\frac{(x_i-\theta)^2}{2})\)</span>: iが1から5までの総乗</li>
</ul></li>
<li>次は事前分布
<ul>
<li><span class="math inline">\(f(\theta)=\frac{1}{\sqrt{20000\pi}}exp(-\frac{\theta^2}{20000})\)</span>: 分散が20000, 平均が<span class="math inline">\(\theta\)</span>の正規分布</li>
</ul></li>
<li>事後分布は<span class="math inline">\(尤度\times 事前分布\)</span>に比例するという式を書く。比例するは<span class="math inline">\(\propto\)</span>で。
<ul>
<li><span class="math inline">\(f(\theta|D)\propto(D|\theta)f(\theta)\)</span></li>
<li><span class="math inline">\(= [\Pi^5_{i=1}\frac{1}{\sqrt{2\pi}}exp(-\frac{(x_i-\theta)^2}{2})]\cdot[\frac{1}{\sqrt{20000\pi}}exp(-\frac{\theta^2}{20000})]\)</span>: 尤度<span class="math inline">\(\times\)</span>事前分布</li>
</ul></li>
<li>上の式の右辺をカーネルと呼ぶ（尤度を周辺尤度で割ってない）
<ul>
<li>周辺尤度を省略してもいい。その理由。
<ul>
<li>周辺尤度の計算は難しい</li>
<li>難しいものを求めなくてもいい</li>
</ul></li>
<li><span class="math inline">\(x_i\)</span>にはデータが入る（事後だから）ので、カーネルは<span class="math inline">\(\theta\)</span>の関数</li>
<li><span class="math inline">\(Kernel(\theta)\)</span></li>
<li>周辺尤度は正規化定数
<ul>
<li>正規化定数：確率の合計を1にするように指定。パラメータを含まない。積分計算で出るけど、大変。</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="モデルに基づく現象の解釈" class="section level2">
<h2>11. モデルに基づく現象の解釈</h2>
<ul>
<li>ビールの売り上げの例
<ul>
<li><span class="math inline">\(\mu_i=\beta_0+\beta_1\cdot x_i\)</span></li>
<li><span class="math inline">\(Y\sim Normal(\mu_i,\sigma^2)\)</span></li>
</ul></li>
<li>パラメータ<span class="math inline">\(\beta_0, \beta_1\)</span>がどういう値を取るか＝データをとったあとの事後分布はどうなるかを知ることができれば解釈に繋がる。特に<span class="math inline">\(\beta_1\)</span>。</li>
<li>事後分布の分散が小さいと使えるけど、大きいと使えない（-10から10まで分布してたらどういう値か分からない）</li>
<li>データとの適合度も重要。</li>
</ul>
</div>
<div id="ベイズ推論の難点とmcmc" class="section level2">
<h2>12. ベイズ推論の難点とMCMC</h2>
<ul>
<li>パラメータが多いと事後分布の計算が大変。積分できないこともある。積分できないと確率が求まらない。</li>
<li>そこで登場するのがMCMC。次章へ。</li>
</ul>
</div>
</div>
<div id="章-mcmcの基本" class="section level1">
<h1>1-7章: MCMCの基本</h1>
<div id="概要" class="section level2">
<h2>1. 概要</h2>
<ul>
<li>MCMCと統計モデリング</li>
<li>MCMCの乱数生成の基本</li>
<li>MCMCの利用方法</li>
</ul>
</div>
<div id="mcmcとは何か" class="section level2">
<h2>2. MCMCとは何か</h2>
<ul>
<li>マルコフ連鎖モンテカルロ法（Markov Chain Monte Carlo）</li>
<li>乱数生成の手法としてマルコフ連鎖を使う</li>
<li>離散時間マルコフ連鎖: ある時点の値は1時点前の値<span class="math inline">\(\textbf{のみ}\)</span>に依存</li>
<li>モンテカルロ法：疑似乱数を使って何らかの性質を求める方法</li>
<li>確率的に変化するランダムな値の例↓ 平均m 分散vの正規分布（左）に従ってn個生成された乱数のヒストグラム（右）</li>
</ul>
</div>
<div id="確率分布に従う乱数の例" class="section level2">
<h2>★確率分布に従う乱数の例</h2>
<pre class="r"><code>layout(matrix(1:2, ncol=2))
m&lt;-0
v&lt;-1
n&lt;-10000
x&lt;-seq(m-sqrt(v)*4,m+sqrt(v)*4,0.01)
y&lt;-(1/sqrt(2*pi*v))*exp(-(x-m)^2/(2*v))
plot(x,y,type=&#39;l&#39;)
rdata&lt;-rnorm(n, m, sqrt(v))
hist(rdata, breaks=12)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-9-1.png" width="768" /></p>
</div>
<div id="mcmcと統計モデリングの関わり" class="section level2">
<h2>3. MCMCと統計モデリングの関わり</h2>
<ul>
<li>そもそも
<ul>
<li>MCMC -&gt; 単に乱数の生成方法の一つ</li>
<li>ただし、事後分布（6章「データが得られた後に想定する分布」）に従う乱数の生成に使えるところが偉い。</li>
<li>ベイズの定理に従って作られた（パラメータの）事後分布は複雑な場合が多い（＝パラメータに関して何らかの情報を得るのが難しい。前章のビールの例のようにパラメータ<span class="math inline">\(\beta_1\)</span>の<span class="math inline">\(2.5%\)</span>点の値はコレ、とか分かればいいけど、普通は分からない）</li>
<li>なので、その分布に従う乱数を生成。乱数をもとに事後分布を作成。＝分布を評価するのではなく、分布に従って生成した値たちを評価＝対象が式じゃなくて値たちなら、点推定もできるし評価が簡単。
<ul>
<li>ここで点推定が出てきて個人的にはちょっと混乱した（パラメータの点推定はしないんじゃないの？）けど、生成した確率分布の代表値を点推定で出すことは普通にあるということっぽいです。</li>
</ul></li>
</ul></li>
<li>ここで発表はちょっと脇道に逸れます。ここからしばらくは頻度主義（求めたいパラメータは真の値を持つ、という考え方の統計）の例ですが、<a href="https://www.amazon.co.jp/dp/400006973X">緑本</a>から：<a href="#%E3%81%AE%E8%A3%9C%E8%B6%B3-%E7%B7%91%E6%9C%AC%E3%81%AEmcmc">MCMCを理解するための補足説明</a></li>
</ul>
</div>
<div id="モンテカルロ法" class="section level2">
<h2>4. モンテカルロ法</h2>
<ul>
<li>乱数を利用した計算法（緑本, P177）</li>
<li>乱数を生成する手法（馬場本）</li>
<li>乱数生成する方法はたくさんあるけど、事後分布に従う乱数を発生できるのがMCMCということ</li>
</ul>
</div>
<div id="モンテカルロ積分" class="section level2">
<h2>5. モンテカルロ積分</h2>
<ul>
<li>第6章「事後分布の期待値を出すためには、その確率密度関数を積分しなきゃいけないけど、すごく大変」</li>
<li>ここではそれをどう回避しているかを説明</li>
<li>事後分布のパラメータ<span class="math inline">\(\theta\)</span>の期待値を知りたいとき、事後分布に従う乱数<span class="math inline">\(\hat{\theta}\)</span>が十分な数（例えば1000個）生成されるなら、<span class="math inline">\(\theta\)</span>の期待値は<span class="math inline">\(\frac{\Sigma^{1000}_{i=1} \hat{\theta}}{1000}\)</span>。つまり乱数<span class="math inline">\(\hat{\theta}\)</span>の平均値。ということで積分計算が不要になる。</li>
</ul>
</div>
<div id="マルコフ連鎖" class="section level2">
<h2>6. マルコフ連鎖</h2>
<ul>
<li>時点によって変化していく確率変数</li>
<li>遷移核：1時点前の値を所与としたと条件付き確率</li>
<li>スマホの例</li>
<li>ある時点でスマホユーザーがとる選択は
<ol style="list-style-type: decimal">
<li>同じ会社のものを使い続ける</li>
<li>別な会社のものに乗り換える</li>
</ol></li>
<li>ある時点<span class="math inline">\(t\)</span>で、どの会社のスマホを使ってるかは、それまで使っていたスマホ会社を所与とした条件つき確率</li>
<li>このとき遷移核
<ul>
<li>A社だった人がA社：<span class="math inline">\(P(X_t=A社|X_{t-i}=A社)=0.4\)</span></li>
<li>A社だった人がB社：<span class="math inline">\(P(X_t=B社|X_{t-i}=A社)=0.6\)</span></li>
<li>B社だった人がB社：<span class="math inline">\(P(X_t=B社|X_{t-i}=B社)=0.1\)</span></li>
<li>B社だった人がA社：<span class="math inline">\(P(X_t=A社|X_{t-i}=B社)=0.9\)</span></li>
</ul></li>
</ul>
</div>
<div id="定常分布" class="section level2">
<h2>7. 定常分布</h2>
<ul>
<li>さっきのスマホの例だと、最終的にA社が多くなって落ち着きそう -&gt; A社60%で落ち着くらしい</li>
<li>やってみよう</li>
</ul>
</div>
<div id="スマホユーザーの例" class="section level2">
<h2>★スマホユーザーの例</h2>
<pre class="r"><code># a地域とb地域では初期比が異なるけど、遷移核が同じならそのうち同じ値に収束するという例
na&lt;-1 # a地域人数
nb&lt;-1 # b地域人数
aAi&lt;-0.9 # a地域におけるA社初期比
aBi&lt;-1-aAi # a地域におけるA社初期比
bAi&lt;-0.2 # b地域のA社初期比
bBi&lt;-1-bAi　# b地域のB社初期比

nrp&lt;-30 # 繰り返し数
rAA&lt;-0.4 # 以下の4行は遷移核
rAB&lt;-0.6
rBB&lt;-0.1
rBA&lt;-0.9
naA&lt;-numeric(nrp)
naB&lt;-numeric(nrp)
nbA&lt;-numeric(nrp)
nbB&lt;-numeric(nrp)
naA[1]&lt;-na*aAi
naB[1]&lt;-na*aBi
nbA[1]&lt;-nb*bAi
nbB[1]&lt;-nb*bBi
for(rp in 2:nrp){
  naA[rp]&lt;-naA[rp-1]*rAA+naB[rp-1]*rBA
  naB[rp]&lt;-naA[rp-1]*rAB+naB[rp-1]*rBB
  nbA[rp]&lt;-nbA[rp-1]*rAA+nbB[rp-1]*rBA
  nbB[rp]&lt;-nbA[rp-1]*rAB+nbB[rp-1]*rBB
}
layout(matrix(1:2, ncol=2))
plot(naA, type=&#39;l&#39;,col=&#39;red&#39;,ylim=c(0,1.0))
par(new=T)
plot(naB, type=&#39;l&#39;,col=&#39;blue&#39;,xlab=&#39;&#39;,ylab=&#39;&#39;,ylim=c(0,1.0))
plot(nbA, type=&#39;l&#39;,col=&#39;red&#39;,ylim=c(0,1.0))
par(new=T)
plot(nbB, type=&#39;l&#39;,col=&#39;blue&#39;,xlab=&#39;&#39;,ylab=&#39;&#39;,ylim=c(0,1.0))</code></pre>
<p><img src="baba_files/figure-html/mobile%20phone-1.png" width="768" /></p>
</div>
<div id="mcmcが目指すこと" class="section level2">
<h2>8. MCMCが目指すこと</h2>
<ul>
<li>このようなユーザーからダンラムに選んで調査をすればきっと6:4になるだろう、と推測できる</li>
<li>遷移核を適切に決めることができれば、「何か」に従う乱数の生成が可能</li>
<li>遷移核をどう適切に決めるか。</li>
</ul>
</div>
<div id="メトロポリスヘイスティングス法mh法" class="section level2">
<h2>9. メトロポリス・ヘイスティングス法（MH法）</h2>
<ul>
<li>乱数生成アルゴリズムの一つ。</li>
<li>ここではランダムウォークMH法</li>
<li>MH法のアルゴリズム
<ul>
<li>この例での変数の使い方
<ul>
<li>パラメータ<span class="math inline">\(\theta\)</span>の分布を生成</li>
<li>t番目の乱数: <span class="math inline">\(\hat{\theta_t}\)</span></li>
<li>初期値: <span class="math inline">\(\hat{\theta_1}\)</span></li>
<li>事後分布: <span class="math inline">\(f(\theta|D)\)</span>
<ul>
<li>データ<span class="math inline">\(D\)</span>が得られたという条件のもとで、<span class="math inline">\(\theta\)</span>が取りうる値の確率分布</li>
</ul></li>
<li>事前分布: <span class="math inline">\(f(\theta)\)</span>
<ul>
<li>情報がない状態での<span class="math inline">\(\theta\)</span>の確率分布</li>
</ul></li>
<li>尤度関数: <span class="math inline">\(f(D|\theta)\)</span>
<ul>
<li><span class="math inline">\(\theta\)</span>がある確率分布に従うという条件のもとでデータ<span class="math inline">\(D\)</span>が得られることの尤もらしさ</li>
</ul></li>
<li>カーネル: <span class="math inline">\(Kernel(\theta)\)</span>
<ul>
<li><span class="math inline">\(f(\theta|D)\propto f(D|\theta)f(\theta)=Kernel(\theta)\)</span></li>
<li>事後分布=尤度x事前分布<span class="math inline">\(\propto\)</span>カーネル</li>
</ul></li>
</ul></li>
<li>手順
<ol style="list-style-type: decimal">
<li>連続一様分布などに従ってランダムに初期値を決める</li>
<li>平均<span class="math inline">\(0\)</span>, 分散<span class="math inline">\(\sigma\)</span>の正規分布に従う乱数を生成, <span class="math inline">\(\hat{\theta}_2^{提案}=\hat{\theta}_1+乱数\)</span></li>
<li><span class="math inline">\(f(\theta_1|D)\)</span>と<span class="math inline">\(f(\theta_2^{提案}|D)\)</span>の比を算出(<span class="math inline">\(rate\)</span>)。ただし<span class="math inline">\(rate=\frac{f(\hat{\theta}_2^{提案}|D)}{f(\hat{\theta}_1|D)}=\frac{Kernel(\hat{\theta}_2^{提案})}{Kernel(\hat{\theta_1})}\)</span></li>
</ol>
<ul>
<li>ここ、本には「事後分布のカーネルがすでに得られているから、カーネルの比を取る的な書き方がされているけど、おそらく話としては、それぞれの<span class="math inline">\(\theta\)</span>のときの確率の比を取る（それには事後分布の確率密度関数が使える）というのが筋。確率が高ければ提案を採用するという話なので。そのとき、事後分布のままだと分母の正規化定数が邪魔なんだけど、定数だからそれを消したカーネルの比でOKですよ、ということだと思う。</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li><span class="math inline">\(rate\)</span>が1より大きければ提案を採用、1より小さくても<span class="math inline">\(rate\)</span>の確率で採用。</li>
</ol></li>
<li>緑本のメトロポリス法との違い
<ul>
<li>乱数生成が確率1/2から正規分布に従う乱数になった、だけ?</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="mh法の計算例" class="section level2">
<h2>10. MH法の計算例</h2>
<ul>
<li>6-10の5つの売り上げデータの例</li>
<li>やってみよう!</li>
</ul>
</div>
<div id="メトロポリスヘイスティングス法の実装例" class="section level2">
<h2>★メトロポリス・ヘイスティングス法の実装例</h2>
<pre class="r"><code>layout(matrix(1:2, ncol=2))
nrp&lt;-2000
data&lt;-c(2.4,3.2,2.2,4.6,3.3)
m&lt;-0
v&lt;-1
chain&lt;-4
#knl&lt;-numeric(nrp)
#theta&lt;-numeric(nrp)
knl&lt;-matrix(0,nrow=nrp, ncol=chain)
theta&lt;-matrix(0,nrow=nrp,ncol=chain)

ratio&lt;-1
for (nc in 1:chain){
  theta[1, nc]&lt;-runif(1,min=-2,max=2) # -2から2の連続一様分布に従う乱数
  for (rp in 1:nrp){
    kp&lt;-numeric(length(data))
    for (d in 1:length(data)){
      kp[d]&lt;-exp(-((data[d]-theta[rp,nc])^2)/2)/sqrt(2)*pi
    }
    knl[rp,nc]&lt;-prod(kp)*exp(-(theta[rp,nc]^2/20000))/sqrt(20000*pi) #カーネルの計算
    
    if (rp&gt;1){
      lr&lt;-knl[rp,nc]/knl[rp-1,nc]  # カーネル比（rate）の算出
      if (runif(1)&gt;lr){ # 確率rateで提案thetaを採用
        #print(lr)
        theta[rp,nc]&lt;-theta[rp-1,nc]
        knl[rp,nc]&lt;-knl[rp-1,nc]
      }
    }
    if (rp&lt;nrp){
      theta[rp+1,nc]&lt;-theta[rp,nc]+rnorm(1,m,v) # 次のthetaの生成, 平均m, 分散vの正規分布に従う乱数を前のthetaにたす
    } 
  }
}

for (wf in 1:chain){
  if (wf&gt;1){
    par(new=T)
    plot(theta[1:nrp,wf],type=&#39;l&#39;, xlab=&#39;&#39;,ylab=&#39;&#39;, col=wf, ylim=(c(min(theta),max(theta))))
  }else{
    plot(theta[1:nrp,wf],type=&#39;l&#39;, main=mean(theta), col=wf, ylim=(c(min(theta),max(theta))))
  }
}
par(new=F)
for (wf in 1:chain){
  if (wf&gt;1){
    hist(theta[,wf], col=adjustcolor(wf, alpha.f=0.3), add=TRUE, breaks=seq(floor(min(theta)),ceiling(max(theta)),0.5))
  }else{
    hist(theta[,wf], col=adjustcolor(wf, alpha.f=0.3), breaks=seq(floor(min(theta)),ceiling(max(theta)),0.5))
  }
}</code></pre>
<p><img src="baba_files/figure-html/m-h%20method-1.png" width="768" /></p>
</div>
<div id="mh法の欠点" class="section level2">
<h2>11. MH法の欠点</h2>
<ul>
<li>乱数生成のときの分散をどう決めるか
<ul>
<li>大きすぎると提案値が大きくなることが増え、いいところに行きにくい</li>
<li>小さすぎるとなかなか変化しなくていいところに行きにくい＝受容率が低い</li>
</ul></li>
</ul>
</div>
<div id="ハミルトニアンモンテカルロ法hmc法" class="section level2">
<h2>12. ハミルトニアン・モンテカルロ法（HMC法）</h2>
<ul>
<li>MH法の欠点を改善</li>
<li>受容率をあげつつ、パラメータの変化を大きく保つ</li>
<li>提案値をランダムではなく、確率密度の高い領域から選ぶ</li>
<li>アルゴリズムの質的説明はP.72。stanにはNUTSというHMC法が実装されてるらしい</li>
</ul>
</div>
<div id="乱数の取り扱いの注意点" class="section level2">
<h2>13. 乱数の取り扱いの注意点</h2>
<ol style="list-style-type: decimal">
<li>各種設定：乱数をいくつ生成するかなど</li>
<li>収束の評価：生成された値をどう評価するか</li>
<li>乱数の代表値を求める</li>
</ol>
</div>
<div id="繰り返し数iterの設定" class="section level2">
<h2>14. 繰り返し数(iter)の設定</h2>
<ul>
<li>乱数の個数。MH法の例ではiter=2000。メトロポリス法ではiter=100000だった。</li>
<li>stanでは2000が設定されることが多い</li>
</ul>
</div>
<div id="バーンイン期間warmupの設定" class="section level2">
<h2>15. バーンイン期間(warmup)の設定</h2>
<ul>
<li>初期値に依存するので最初の方はあやしい</li>
<li>切り捨てて使わない</li>
</ul>
</div>
<div id="間引きthinの設定" class="section level2">
<h2>16. 間引き(thin)の設定</h2>
<ul>
<li>生成した乱数を間引く</li>
<li>乱数間の自己相関を下げるための工夫</li>
</ul>
</div>
<div id="チェーンchainsの設定" class="section level2">
<h2>17. チェーン(chains)の設定</h2>
<ul>
<li>収束評価のため、乱数生成を何度か繰り返す</li>
<li>代表値を比較などして評価</li>
<li>chains=4を使うことが多い</li>
</ul>
</div>
<div id="収束の判定" class="section level2">
<h2>18. 収束の判定</h2>
<ul>
<li>良く使われる判定指標：<span class="math inline">\(\hat{R}\)</span></li>
<li><span class="math inline">\(\hat{R}=\frac{同一のチェーン内での乱数の分散の平均値}{異なるチェーンも含めたすべての乱数の分散}\)</span></li>
<li>これが1.1より小さくなるまで繰り返す</li>
<li>chans=1の場合、チェーン内をいくつかに分割して計算</li>
</ul>
</div>
<div id="点推定と区間推定" class="section level2">
<h2>19. 点推定と区間推定</h2>
<ul>
<li>点推定：推定値を1点だけ提示-&gt;MED, EAP, MAPは点推定</li>
<li>区間推定：なんらかの区間を設定して、幅のある推定値を提示</li>
</ul>
</div>
<div id="ベイズ信用区間" class="section level2">
<h2>20. ベイズ信用区間</h2>
<ul>
<li>乱数を小さい値から並べて2.5%点から97.5%点に該当する範囲</li>
<li>95%ベイズ信用区間 / 95%ベイズ信頼区間</li>
</ul>
</div>
<div id="事後中央値med-posteriori-median" class="section level2">
<h2>21. 事後中央値(MED; posteriori median)</h2>
<ul>
<li>事後分布の中央値を採用</li>
</ul>
</div>
<div id="事後期待値eap-expected-a-posteriori" class="section level2">
<h2>22. 事後期待値(EAP; expected a posteriori)</h2>
<ul>
<li>事後分布の平均値を採用</li>
</ul>
</div>
<div id="事後確率最大値map-maximum-a-posteriori" class="section level2">
<h2>23. 事後確率最大値(MAP; maximum a posteriori)</h2>
<ul>
<li>事後分布において確率が最大となる点</li>
</ul>
</div>
</div>
<div id="の補足-緑本のmcmc" class="section level1">
<h1>1-7の補足: 緑本のMCMC</h1>
<ul>
<li><a href="https://www.amazon.co.jp/dp/400006973X">緑本</a> P.171 例題：種子の生存確率</li>
<li>観測データ：<span class="math inline">\(N_i個\)</span>の観察種子のうち、生きていて発芽能力があるものは<span class="math inline">\(y_i個\)</span>、死んだ種子は<span class="math inline">\(N-y_i個\)</span>」</li>
<li><span class="math inline">\(N_i\)</span>を<span class="math inline">\(8\)</span>とし、<span class="math inline">\(20\)</span>個体について調べる（8個の観察種子のうち、生きてるものは<span class="math inline">\(y_i\)</span>個、死んでるものは<span class="math inline">\(8-y_i\)</span>個。これを20本の植物について調べる）</li>
<li><span class="math inline">\(\{y_1,y_2,...,y_{20}\}=\{4,3,4,5,5,2,3,1,4,0,1,5,5,6,5,4,4,5,3,4\}\)</span></li>
<li>このとき、種子個体iの生存確率qは?</li>
<li>ある個体<span class="math inline">\(i\)</span>の生存種子数が<span class="math inline">\(y_i\)</span>である確率（ヒストグラム（下図左）を見ると過分散ではないので、<a href="baba.html#%E4%BA%8C%E9%A0%85%E5%88%86%E5%B8%83">二項分布(リンク先はq=0.3の例)</a>と考える＝統計モデル、ただしパラメータqは不明なので、データからそれを求めたい）：<span class="math inline">\(p(y_i|q)={}_8 C_{y_1} \cdot q^{y_1} \cdot(1-q)^{8-{y_1}}\)</span>
<ul>
<li>過分散：通常の（二項）分布よりも分散が大きいこと。サンプルごとに傾向に違いがあるような場合に見られる。</li>
</ul></li>
<li>尤度関数：<span class="math inline">\(L(q)=\prod_i p(y_i|q)\)</span>（パラメータqのときデータ<span class="math inline">\(y_i\)</span>が得られる確率の総乗） :パラメータq。qが変化すると尤度（モデルのもっともらしさ）が変化する。→尤度が最大になるqを求めればいい。これが真の値の推定値（頻度主義だから真の値がある）<span class="math inline">\(\hat{q}\)</span>（qハット）=最尤推定量</li>
<li>対数尤度関数：<span class="math inline">\(logL(q) = \Sigma_i\{y_ilog\ q+(8-y_i)\ log(1-q)\}+定数\)</span>（下図右）</li>
</ul>
<blockquote>
<ul>
<li>さらに脱線。尤度の説明もう一度。
<ul>
<li>緑本2.4節</li>
<li>尤度：あてはまりの良さ</li>
<li><span class="math inline">\(\lambda=3.56\)</span>のポアソン分布に従う<span class="math inline">\(y_i\)</span>が<span class="math inline">\(\{y_1,y_2,y_3\}=\{2,2,4\}\)</span>であるときの尤度は<span class="math inline">\(p(y_1=2|\lambda=3.56)=0.180\)</span>, <span class="math inline">\(p(y_2=2|\lambda=3.56)=0.180\)</span> <span class="math inline">\(p(y_3=4|\lambda=3.56)=0.190\)</span>より、<span class="math inline">\(0.180\times0.180\times0.190=0.006156\)</span>となる</li>
<li>一般化すると尤度<span class="math inline">\(L(\lambda)=\prod_{i}^{}p(yi|\lambda)=\prod_{i}\frac{\lambda^{y_i} exp(-\lambda)}{y_i!}\)</span>: 尤度は平均<span class="math inline">\(\lambda\)</span>のポアソン分布における<span class="math inline">\(y_i\)</span>の確率の総乗として表される</li>
</ul></li>
</ul>
</blockquote>
<ul>
<li>尤度関数を対数変換したとき、その値が最も大きい（＝0に近い）とき最も尤度が大きい（＝あてはまりがいい）</li>
<li>対数尤度関数の傾きが0になるqを探す（緑本2.4節参照）＝対数尤度関数を偏微分する</li>
<li>対数尤度関数をqで偏微分：<span class="math inline">\(\frac{\partial\ logL(q)}{\partial\ q} = \Sigma\{\frac{y_i}{q} - \frac{8-y_i}{1-q}\} = 0\)</span> ? （全く自信ない）で、ここから<span class="math inline">\(\hat{q}=\frac{\Sigma{y_i}}{8\times20} = \frac{73}{8\times20}=0.45625\)</span>になるらしい（<a href="https://hazm.at/mox/math/statistics/inferential/binomial-distribution.html" class="uri">https://hazm.at/mox/math/statistics/inferential/binomial-distribution.html</a>）</li>
<li>これで解析的に最尤推定値<span class="math inline">\(\hat{q}\)</span>を求めることができた!</li>
<li>下の対数尤度関数のピークとなるところの<span class="math inline">\(q\)</span>の値ということ。</li>
</ul>
<div id="緑本の-種子の例のヒストグラムと対数尤度関数" class="section level2">
<h2>★緑本の 「種子の例」のヒストグラムと対数尤度関数</h2>
<pre class="r"><code>layout(matrix(1:2, ncol=2))
data&lt;-c(4,3,4,5,5,2,3,1,4,0,1,5,5,6,5,4,4,5,3,4)
hist(data,breaks=c(-1:7))
logb&lt;-function(x) sum(log(dbinom(data, 8, x)))
q &lt;- seq(0.2, 0.7, 0.01)
plot(q, sapply(q, logb), type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-10-1.png" width="768" /></p>
<ul>
<li>ここまでで、解析的に最尤推定量<span class="math inline">\(\hat{q}\)</span>を求めることができたけど、それができない場合はどうするか。分布がややこしかったりすると尤度関数はもっとややこしくて解けなくなることがある。
<ul>
<li>ここで、モンテカルロ法的なものが登場</li>
</ul></li>
<li>ふらふら試行錯誤による最尤推定（という例；緑本P173）
<ul>
<li>qを離散化→qを連続値ではなく0.01刻みの離散値と考える</li>
<li>適当なqの初期値を決め、対数尤度を計算して評価。対数尤度関数に代入するだけ。パラメータはqだけだから計算可能。<span class="math inline">\(q=0.30\)</span>の場合、<span class="math inline">\(-46.38\)</span>になる。</li>
</ul></li>
<li>以下は「ふらふら試行錯誤の最尤推定」手順
<ol style="list-style-type: decimal">
<li>qはとなりの値にしか変化できない（ここで「となりの値」という考え方をするために、qを離散化したのだと思う）-&gt;0.30スタートなら0.29か0.31</li>
<li>2つの値のうちどちらを選ぶかはランダムに決定し、対数尤度が現在よりも大きければそちらに移動</li>
</ol>
<ul>
<li>0.31が選ばれた場合、対数尤度は-45.24となり、大きいから採用される -&gt; qは0.31になる</li>
<li>仮に0.29が選ばれていれば、対数尤度は-47.62で小さくなってるので、qは0.30に戻る</li>
</ul></li>
<li>下、適当に実装してみた例。qの初期値(qi)の値を変えても同じ値に収束するのがわかる。
<ul>
<li>緑本ではqを0.01刻みで動かしてるけど、下では0.001刻みにしている。緑本の例のように100回では収束せず400回くらいかかってるけど、当然収束した値は、より真の値に近づく。</li>
</ul></li>
</ul>
</div>
<div id="ふらふら最尤推定" class="section level2">
<h2>★ふらふら最尤推定</h2>
<pre class="r"><code>nrp&lt;-1000
qi&lt;-0.159
n&lt;-8
data&lt;-c(4,3,4,5,5,2,3,1,4,0,1,5,5,6,5,4,4,5,3,4)
logL&lt;-numeric(nrp)
q&lt;-numeric(nrp)
q[1]&lt;-qi
for (rp in 1:nrp){
  lh&lt;-numeric(length(data))
  for (d in 1:length(data)){
    lh[d]&lt;-choose(n,data[d])*q[rp]^data[d]*(1-q[rp])^(n-data[d])
  }
  logL[rp]&lt;-log(prod(lh))
  if (rp&gt;1){
    if (logL[rp]&lt;logL[rp-1]){
      q[rp]&lt;-q[rp-1]
      logL[rp]&lt;-logL[rp-1]
    }
  }
  if (round(runif(1))){
    q[rp+1]&lt;-q[rp]+0.001
  }else{
    q[rp+1]&lt;-q[rp]-0.001
  }
}
plot(q[1:nrp],type=&#39;l&#39;, main=q[nrp])</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;" /></p>
<ul>
<li>このように、ランダムに生成した値を仮のqとして尤度を計算、尤度が高くなる場合だけ値を変化させるという方法で最尤値を推定することができた。緑本に書いてるように、ここまでのアルゴリズムは分かりやすさだけを考えた非効率なもの。実際の最尤推定はもっと効率いいそうです。</li>
<li>これがモンテカルロ法（の一例）。</li>
<li>メトロポリス法（MCMCアルゴリズムの一つ）
<ul>
<li>ふらふら試行錯誤をちょっと修正</li>
</ul>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(q\)</span>の初期値を決める(<span class="math inline">\(q_i\)</span>)</li>
<li><span class="math inline">\(q\)</span>を増やすか減らすかをランダムに決め、新しい値を作る(<span class="math inline">\(q^新\)</span>とする)</li>
<li>尤度を計算。大きくなってたら<span class="math inline">\(q^新\)</span>を採用する</li>
</ol>
<ul>
<li>— ここまではふらふら試行錯誤と同じ —</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>尤度が小さくなる場合でも、確率<span class="math inline">\(r\)</span>で<span class="math inline">\(q^新\)</span>を採用して<span class="math inline">\(q\)</span>を<span class="math inline">\(q^新\)</span>に変更。そのときの確率は<span class="math inline">\(r=\frac{L(q^新)}{L(q)}\)</span>で計算する。尤度が高いほど採用される確率が高まる。手順3のように尤度が高くなっていれば確率が1より大きいから、必ず採用される。</li>
</ol></li>
<li>じゃあ実装してみよう。繰り返し回数(nrp)によってqの平均値は変わってくる。まずは10万回の例。</li>
</ul>
</div>
<div id="メトロポリス法の実装例" class="section level2">
<h2>★メトロポリス法の実装例</h2>
<pre class="r"><code>layout(matrix(1:2, ncol=1))
nrp&lt;-50000
qi&lt;-0.30
n&lt;-8
data&lt;-c(4,3,4,5,5,2,3,1,4,0,1,5,5,6,5,4,4,5,3,4)
logL&lt;-numeric(nrp)
q&lt;-numeric(nrp)
q[1]&lt;-qi
lr&lt;-1
for (rp in 1:nrp){
  lh&lt;-numeric(length(data))
  for (d in 1:length(data)){
    lh[d]&lt;-choose(n,data[d])*q[rp]^data[d]*(1-q[rp])^(n-data[d])
  }
  logL[rp]&lt;-log(prod(lh))
  if (rp&gt;1){
    lr&lt;-exp(logL[rp]-logL[rp-1])
    if (runif(1)&gt;lr){
      #print(lr)
      q[rp]&lt;-q[rp-1]
      logL[rp]&lt;-logL[rp-1]
    }
  }
  if (round(runif(1))){
    q[rp+1]&lt;-min(0.99,q[rp]+0.01)
  }else{
    q[rp+1]&lt;-max(0.01,q[rp]-0.01)
  }
}
plot(q[1:nrp],type=&#39;l&#39;, main=mean(q))
hist(q)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-12-1.png" width="768" /></p>
<ul>
<li>とりあえず緑本の感じにはなってるので実装例は良さそう。下図は生成したqのヒストグラム。
<ul>
<li>MCMCは一意の最尤値に収束するのではなく、変化する値の生成を行う。ただし、だんだんと収束していくことには変わりはない。</li>
</ul></li>
<li>定常分布
<ul>
<li>上のようなマルコフ連鎖によって生成した変数<span class="math inline">\(q\)</span>を考えたとき、
<ul>
<li>マルコフ連鎖が「一定の条件」<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>を満たしているとき、<span class="math inline">\(q\)</span>は定常分布(<span class="math inline">\(p(q|y_i)\)</span>)という確率分布に従う</li>
<li>そのため、十分な回数生成した変数の分布は定常分布に近似してくれる（上図下。ただし、上図では定常分布は書いてない。緑本p179参照。回数が少ないと定常分布から離れたヒストグラムになる。）</li>
<li>定常分布：<span class="math inline">\(p(q|y_i)=\frac{L(q)}{\Sigma_q L(q)} \propto L(q)\)</span></li>
</ul></li>
<li>ここまでの流れ
<ul>
<li>二項分布というモデルとメトロポリス法によって<span class="math inline">\(q\)</span>をたくさん生成すると、それは定常分布に近似する。
<ul>
<li>この例題では、定常分布は尤度に比例する</li>
</ul></li>
<li>定常分布は、あるデータに統計モデルを当てはめたときに<span class="math inline">\(q\)</span>がとる値の確率分布と解釈できる（緑本p184）←ただし、ここの理屈はちょっと自身がない</li>
</ul></li>
</ul></li>
<li>ベイズへ
<ul>
<li>さっきの式の右辺に事前分布をかけると、ベイズのカーネル（6章で出てきた <span class="math inline">\((D|\theta)\cdot f(\theta)\)</span>, あるいは <span class="math inline">\([\Pi^5_{i=1}\frac{1}{\sqrt{2\pi}}exp(-\frac{(x_i-\theta)^2}{2})]\cdot[\frac{1}{\sqrt{20000\pi}}exp(-\frac{\theta^2}{20000})]\)</span>(5つの売り上げデータをとるやつ)</li>
<li>さっきまでやってた例が、そもそもベイズの枠組みとして考えられていたら…
<ol style="list-style-type: decimal">
<li>植物の個体のうち生存しているものはいくつあるか</li>
<li>事前分布をおく</li>
<li>個数はパラメータ<span class="math inline">\(q\)</span>に従う二項分布と考え、20個体のデータから事後分布を作る。</li>
</ol></li>
<li>この事後分布は事前分布に尤度をかけたもの。事前分布はパラメータ<span class="math inline">\(q\)</span>（馬場本の例だと<span class="math inline">\(\theta\)</span>）の関数だけど、まあ一様分布を使ったりするし、ということで定数だとすると、事後分布＝定常分布ということになる</li>
<li>ここまでの流れによって、MCMCで得られる定常分布はベイズモデリングの事後分布であると言えることになる</li>
</ul></li>
<li><a href="#mcmc%E3%81%A8%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E9%96%A2%E3%82%8F%E3%82%8A">もとの場所に戻る</a></li>
</ul>
<script type="text/javascript">
$(function () {
var headerHight = 50; //ヘッダの高さ
$('a[href^=#]').click(function(){
    var href= $(this).attr("href");
      var target = $(href == "#" || href == "" ? 'html' : href);
       var position = target.offset().top-headerHight; //ヘッダの高さ分位置をずらす
    $("html, body").animate({scrollTop:position}, 550, "swing");　//この数値は移動スピード
       return false;
  });
});
</script>
</div>
</div>
<div id="章" class="section level1">
<h1>2章</h1>
</div>
<div id="章rの基本" class="section level1">
<h1>2-1章：Rの基本</h1>
<div id="目的と概要" class="section level2">
<h2>1. 目的と概要</h2>
<ul>
<li>Rインストール</li>
<li>基本事項</li>
<li>応用</li>
</ul>
</div>
<div id="rのインストール" class="section level2">
<h2>2. Rのインストール</h2>
</div>
<div id="rstudioのインストール" class="section level2">
<h2>3. RStudioのインストール</h2>
</div>
<div id="rstudioの使い方" class="section level2">
<h2>4. RStudioの使い方</h2>
<ul>
<li>プロジェクトの作成</li>
<li>スクリプトの作成</li>
</ul>
</div>
<div id="変数" class="section level2">
<h2>5. 変数</h2>
<ul>
<li>’&lt;-’による代入</li>
<li>print()や変数名で表示</li>
<li>因子型:</li>
</ul>
</div>
<div id="関数" class="section level2">
<h2>6. 関数</h2>
<ul>
<li>引数</li>
</ul>
</div>
<div id="ベクトル" class="section level2">
<h2>7. ベクトル</h2>
<ul>
<li>vector &lt;- c(1,2,3,4,5)</li>
<li>1:10 等差数列</li>
</ul>
</div>
<div id="行列" class="section level2">
<h2>8. 行列</h2>
<pre class="r"><code>mtrx&lt;-matrix(
  data=1:10,
  nrow=2,
  byrow=F
)
rownames(mtrx)&lt;-c(&#39;row1&#39;,&#39;row2&#39;)
colnames(mtrx)&lt;-c(&#39;c1&#39;,&#39;c2&#39;,&#39;c3&#39;,&#39;c4&#39;,&#39;c5&#39;)
print(mtrx)</code></pre>
<pre><code>##      c1 c2 c3 c4 c5
## row1  1  3  5  7  9
## row2  2  4  6  8 10</code></pre>
</div>
<div id="配列" class="section level2">
<h2>9. 配列</h2>
<ul>
<li>arry&lt;-array(data=1:30, dim=c(3,5,2))</li>
</ul>
</div>
<div id="データフレーム" class="section level2">
<h2>10. データフレーム</h2>
<ul>
<li>列ごとにっデータの種類を変えられる</li>
<li>df &lt;-data.frame()</li>
<li>nrow(df)</li>
</ul>
</div>
<div id="リスト" class="section level2">
<h2>11. リスト</h2>
<ul>
<li>さらに上位構造としてのリスト</li>
<li>lst &lt;- list( a=c(1,2,3), b=mtrx, c=df )</li>
</ul>
</div>
<div id="データの抽出" class="section level2">
<h2>12. データの抽出</h2>
<ul>
<li>[]での抽出</li>
<li>a&lt;-matrix(data=1:10,nrow=2) でa[,1]のようにすれば特定列のみ、特定行のみ抽出</li>
<li>a[1, 2:3]のようなことも可能</li>
<li>dim()で要素数、dimnamesで要素名を調べる</li>
<li>行名や列名でも指定可能</li>
<li>データフレームの場合、$で列名を指定可能</li>
<li>head(df,n)、データフレームdfの先頭n行を表示</li>
<li>listでも$を使える</li>
</ul>
</div>
<div id="時系列データts" class="section level2">
<h2>13. 時系列データ(ts)</h2>
<ul>
<li>ts()</li>
</ul>
<pre class="r"><code>df2 &lt;- data.frame(
  data=1:24
)
ts2&lt;-ts(
  df2, # 対象データ
  start = c(2010,1), #開始年月
  frequency=12 #頻度
)
print(ts2)</code></pre>
<pre><code>##      Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
## 2010   1   2   3   4   5   6   7   8   9  10  11  12
## 2011  13  14  15  16  17  18  19  20  21  22  23  24</code></pre>
</div>
<div id="ファイルからのデータ読み込み" class="section level2">
<h2>14. ファイルからのデータ読み込み</h2>
<ul>
<li>read.csv()</li>
</ul>
</div>
<div id="乱数の生成" class="section level2">
<h2>15. 乱数の生成</h2>
<ul>
<li>rnorm(n=, mean=, sd=): 正規分布に従う乱数</li>
<li>set.seed(): seedを設定すれば同じ乱数を生成できる</li>
</ul>
</div>
<div id="繰り返し構文とforループ" class="section level2">
<h2>16. 繰り返し構文とforループ</h2>
<ul>
<li>for (i in 1:3){}のような形</li>
</ul>
</div>
<div id="外部パッケージの活用" class="section level2">
<h2>17. 外部パッケージの活用</h2>
<ul>
<li>install.packages()</li>
</ul>
</div>
</div>
<div id="章-データの要約" class="section level1">
<h1>2-2章: データの要約</h1>
<div id="度数度数分布ヒストグラム" class="section level2">
<h2>2. 度数・度数分布・ヒストグラム</h2>
<ul>
<li>hist()</li>
</ul>
<pre class="r"><code>fish&lt;-read.csv(&#39;2-2-1-fish.csv&#39;)
hist(fish$length)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-16-1.png" width="768" /></p>
</div>
<div id="カーネル密度推定" class="section level2">
<h2>3. カーネル密度推定</h2>
<ul>
<li>ヒストグラムを滑らかに</li>
<li>density()</li>
</ul>
<pre class="r"><code>fish&lt;-read.csv(&#39;2-2-1-fish.csv&#39;)
plot(density(fish$length, adjust=1))</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-17-1.png" width="768" /></p>
</div>
<div id="算術平均" class="section level2">
<h2>4. 算術平均</h2>
<ul>
<li>mean()</li>
</ul>
</div>
<div id="中央値四分位点パーセント点" class="section level2">
<h2>5. 中央値・四分位点・パーセント点</h2>
<ul>
<li>median()</li>
<li>quautile(data, c(v1, v2))</li>
</ul>
</div>
<div id="共分散とピアソンの積率相関係数" class="section level2">
<h2>6. 共分散とピアソンの積率相関係数</h2>
<ul>
<li>共分散: <span class="math inline">\(\frac{1}{N} \Sigma^N_{i=1} (x_i-\bar{x})(y_i-\bar{y}))\)</span></li>
<li>ピアソンの積率相関係数: <span class="math inline">\(\rho_{xy}=\frac{\Sigma^N_{i=1}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\{\Sigma^N_{i=1}(x_i-\bar{x})^2\}\{\Sigma^N_{i=1}(y_i-\bar{y})^2\}}}\)</span></li>
<li>cor(varx, vary)</li>
</ul>
</div>
<div id="自己共分散自己相関係数コレログラム" class="section level2">
<h2>7. 自己共分散・自己相関係数・コレログラム</h2>
<ul>
<li>jikosoukannkeisuu: 時系列データにおける過去のデータとの相関
<ul>
<li>1次：1時点前との相関</li>
<li>2次：2時点前との相関</li>
<li><span class="math inline">\(\frac{1}{N}\Sigma^N_{i=1}(y_t-\bar{y})(y_{t-1}-\bar{y})\)</span></li>
<li>acf()</li>
</ul></li>
</ul>
<pre class="r"><code>acf(Nile)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-18-1.png" width="768" /></p>
</div>
</div>
<div id="章-ggplot2によるデータの可視化" class="section level1">
<h1>2-3章 ggplot2によるデータの可視化</h1>
<div id="ggplot2の基本" class="section level2">
<h2>2. ggplot2の基本</h2>
<ol style="list-style-type: decimal">
<li>データフレームにする</li>
<li>ggolot関数でグラフのベースを作る</li>
<li>ベースにグラフを追加していく</li>
<li>グラフタイトルなどを追加していく</li>
</ol>
</div>
<div id="データの読み込み" class="section level2">
<h2>3. データの読み込み</h2>
</div>
<div id="ヒストグラムとカーネル密度推定" class="section level2">
<h2>4. ヒストグラムとカーネル密度推定</h2>
</div>
<div id="グラフの重ね合わせと一覧表示" class="section level2">
<h2>5. グラフの重ね合わせと一覧表示</h2>
<pre class="r"><code>library(&#39;ggplot2&#39;)
fish &lt;- read.csv(&#39;2-2-1-fish.csv&#39;)
head(fish, n=3)</code></pre>
<pre><code>##      length
## 1  8.747092
## 2 10.367287
## 3  8.328743</code></pre>
<pre class="r"><code>ggplot(data=fish, mapping=aes(x=length))+geom_histogram(alpha=0.5, bins=20)+labs(title=&#39;ヒストグラム&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-19-1.png" width="768" /></p>
<pre class="r"><code>fish &lt;- read.csv(&#39;2-2-1-fish.csv&#39;)
head(fish, n=3)</code></pre>
<pre><code>##      length
## 1  8.747092
## 2 10.367287
## 3  8.328743</code></pre>
<pre class="r"><code>ggplot(data=fish, mapping=aes(x=length, y=..density..))+geom_histogram(alpha=0.5, bins=20)+geom_density(size=1.5)+labs(title=&#39;ヒストグラム&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-20-1.png" width="768" /></p>
<pre class="r"><code>library(gcookbook)
library(gridExtra)
p_hist&lt;-ggplot(data=fish, mapping=aes(x=length))+geom_histogram(alpha=0.5, bins=20)+labs(title=&quot;ヒストグラム&quot;)
p_density&lt;-ggplot(data=fish, mappin=aes(x=length))+geom_density(size=1.5)+labs(title=&quot;カーネル密度推定&quot;)
grid.arrange(p_hist, p_density, nrow=2)+theme(plot.title=element_text(family=&quot;Hirakaku&quot;))</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-21-1.png" width="768" /></p>
<pre><code>## NULL</code></pre>
</div>
<div id="箱ひげ図とバイオリンプロット" class="section level2">
<h2>3.6 箱ひげ図とバイオリンプロット</h2>
<ul>
<li>箱ひげ図：四分位点、中央値　geom_boxplot</li>
<li>バイオリンプロット geom_violin</li>
</ul>
</div>
<div id="散布図" class="section level2">
<h2>3.7 散布図</h2>
<ul>
<li>2変数間の関係 geom_point</li>
</ul>
</div>
<div id="折れ線グラフ" class="section level2">
<h2>3.8 折れ線グラフ</h2>
<ul>
<li>時系列データ geom_line</li>
</ul>
</div>
</div>
<div id="の補足ggplot2の考え方rグラフィックブック付録a" class="section level1">
<h1>2-3の補足：ggplot2の考え方(Rグラフィックブック付録A)</h1>
<div id="wideフォーマットとlongフォーマット" class="section level2">
<h2>wideフォーマットとlongフォーマット</h2>
<ul>
<li>属性を縦と横に配置した表: wideフォーマット</li>
</ul>
<pre class="r"><code>library(gcookbook)
simpledat</code></pre>
<pre><code>##    A1 A2 A3
## B1 10  7 12
## B2  9 11  6</code></pre>
<pre><code>* データが複数の列に入る</code></pre>
<ul>
<li>1種類のデータは1列にまとまるべき
<ul>
<li>reshapeパッケージ、melt()</li>
</ul></li>
</ul>
<pre class="r"><code>library(reshape2)
longdat&lt;-melt(simpledat)
longdat</code></pre>
<pre><code>##   Var1 Var2 value
## 1   B1   A1    10
## 2   B2   A1     9
## 3   B1   A2     7
## 4   B2   A2    11
## 5   B1   A3    12
## 6   B2   A3     6</code></pre>
</div>
<div id="ggplotの用語" class="section level2">
<h2>ggplotの用語</h2>
<ul>
<li>データ：視覚化の対象、変数で構成される</li>
<li>幾何オブジェクト：描画されるもの。データを表現したもの。</li>
<li>エステティック属性：幾何オブジェクトの視覚的プロパティ（x, yの位置、線の色など）</li>
<li>マッピング：「データの値をエステティック属性にマッピングする」</li>
<li>スケール：データ空間の値とエステティック空間の値との関係。</li>
<li>ガイド：目盛りやラベル</li>
</ul>
</div>
<div id="基本的な使い方" class="section level2">
<h2>基本的な使い方</h2>
<ul>
<li>ggplot(データ, エステティック属性)+描画オブジェクト
<ul>
<li>ggplot(longdat, aes(x=xval, y=yval))
<ul>
<li>xvalがx軸に、yvalがy軸にマッピングされる</li>
</ul></li>
<li><ul>
<li>geom_point()</li>
<li>上のものに幾何オブジェクトを足すと描画できる。この例では散布図。</li>
</ul></li>
<li><ul>
<li>geom_point(aes(colour=group))</li>
<li>このようにエステティック属性としてcolourを指定すると指定した属性を色にマッピングできる。</li>
</ul></li>
<li>+scale_x_continuous(limits=c(0,8))
<ul>
<li>xの範囲を広げる</li>
</ul></li>
<li>print(オブジェクト）
<ul>
<li>オブジェクトを明示的に表示</li>
</ul></li>
<li>ここまでの例。</li>
</ul></li>
</ul>
<pre class="r"><code>library(ggplot2)
dat &lt;- data.frame(xval=1:4,yval=c(3,5,6,9), group=c(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;B&quot;))
p&lt;-ggplot(dat,aes(x=xval,y=yval))
p2&lt;-p+geom_point(aes(colour=group))
p2+scale_x_continuous(limits=c(0,8))</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-24-1.png" width="768" /></p>
<pre class="r"><code>print(p2)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-24-2.png" width="768" /></p>
</div>
</div>
<div id="章-stanの基本" class="section level1">
<h1>2-4章 Stanの基本</h1>
<div id="stanのインストール" class="section level2">
<h2>2. Stanのインストール</h2>
<ul>
<li>done</li>
</ul>
</div>
<div id="サンプルとmcmcサンプル" class="section level2">
<h2>3. サンプルとMCMCサンプル</h2>
<ul>
<li>サンプル：抽出した標本</li>
<li>MCMCサンプル：MCMCから得た乱数</li>
</ul>
</div>
<div id="ここで推定するモデルの構造" class="section level2">
<h2>4. ここで推定するモデルの構造</h2>
<ul>
<li>ビールの売り上げ（1部5章5.5節）
<ul>
<li>売り上げ（単位：万円）を記録したデータ100個</li>
<li>売り上げデータは正規分布に従う</li>
<li>売り上げ平均<span class="math inline">\(\mu\)</span>, ばらつき<span class="math inline">\(\sigma\)</span></li>
<li><span class="math inline">\(sales \sim Normal(\mu, \sigma^2)\)</span></li>
</ul></li>
</ul>
</div>
<div id="rとstan" class="section level2">
<h2>5. RとStan</h2>
<ul>
<li>この本では
<ul>
<li>R: 基本的なデータ処理</li>
<li>Stan: MCMC</li>
</ul></li>
<li>Stanコード
<ul>
<li>拡張子stan</li>
<li>textファイルを拡張子stanで保存
<ul>
<li>RStudioでstanファイルを作成してもOK.構造が予め用意されている。</li>
</ul></li>
</ul></li>
<li>この本でのベイズ統計モデリングデータ分析
<ol style="list-style-type: decimal">
<li>Rファイル</li>
<li>Stanファイル（MCMC用）資料ではオレンジ色枠</li>
<li>標本が格納されたcsvファイル</li>
</ol></li>
</ul>
</div>
<div id="stanファイルの書き方" class="section level2">
<h2>6. Stanファイルの書き方</h2>
<ul>
<li>基本的な構造
<ul>
<li>dataブロック: データ、サンプルサイズ</li>
<li>parameterブロック：事後分布を得るパラメータ一覧</li>
<li>modelブロック：事前分布、尤度
<ul>
<li>事前分布を指定しないと<span class="math inline">\((-\infty, \infty)\)</span>の一様分布</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="stanファイルの実装例" class="section level2">
<h2>7. Stanファイルの実装例</h2>
<ul>
<li>2-4-1-calc-mean-variance.stanというファイル名で作成</li>
</ul>
</div>
<div id="rファイル実装の流れ" class="section level2">
<h2>8. Rファイル実装の流れ</h2>
<ul>
<li>2-4-Stnの基本.Rを作成
<ol style="list-style-type: decimal">
<li>パッケージ読み込みなどの準備</li>
<li>データ読み込みと確認</li>
<li>list形式でデータをまとめる</li>
<li>Stant連携、MCMC実行</li>
<li>結果確認</li>
</ol>
<ul>
<li>収束も確認</li>
</ul></li>
</ul>
</div>
<div id="分析の準備" class="section level2">
<h2>9. 分析の準備</h2>
<ul>
<li>rstan_options(auto_write=TRUE)
<ul>
<li>.rdsファイル生成</li>
<li>再度のコンパイルを不要にする</li>
</ul></li>
<li>options(mc.cores=)
<ul>
<li>計算の並列化。コンピュータのコア数に応じて指定してくれる。</li>
</ul></li>
<li>基本的にどちらもいつも指定する</li>
</ul>
</div>
<div id="データ読み込み" class="section level2">
<h2>10. データ読み込み</h2>
<ul>
<li>read.csv</li>
<li>この例では確認は省略</li>
</ul>
</div>
<div id="list形式でデータをまとめる" class="section level2">
<h2>11. list形式でデータをまとめる</h2>
<ul>
<li>Stanファイルのデータブロックに必要なデータ数Nとデータsalesをlistにしておく</li>
</ul>
</div>
<div id="stanと連携してmcmc実行" class="section level2">
<h2>12. Stanと連携してMCMC実行</h2>
<ul>
<li>stan関数
<ul>
<li>引数はP118の通り</li>
<li>実際にはMCMCサンプルは毎回異なるが、seed=1を指定することで固定。</li>
</ul></li>
</ul>
<pre class="r"><code>library(rstan)</code></pre>
<pre><code>##  要求されたパッケージ StanHeaders をロード中です</code></pre>
<pre><code>## rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)</code></pre>
<pre><code>## For execution on a local, multicore CPU with excess RAM we recommend calling
## options(mc.cores = parallel::detectCores()).
## To avoid recompilation of unchanged Stan programs, we recommend calling
## rstan_options(auto_write = TRUE)</code></pre>
<pre class="r"><code>rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())

file_beer_sales_1 &lt;- read.csv(&quot;2-4-1-beer-sales-1.csv&quot;)

sample_size&lt;-nrow(file_beer_sales_1)
data_list&lt;-list(sales=file_beer_sales_1$sales, N=sample_size)

mcmc_result&lt;-stan(
  file=&quot;2-4-1-calc.mean-variance.stan&quot;,
  data=data_list,
  seed=1,
  chains=4,
  iter=2000,
  warmup=1000,
  thin=1
)</code></pre>
</div>
<div id="結果の確認" class="section level2">
<h2>13. 結果の確認</h2>
<ul>
<li>print()でmcmcの戻り値を表示
<ul>
<li>求めるパラメータ, mu, sigma, lp__:対数事後確率</li>
</ul></li>
</ul>
<pre class="r"><code>print(mcmc_result, probs=c(0.025,0.5,0.975))</code></pre>
<pre><code>## Inference for Stan model: 2-4-1-calc.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##          mean se_mean   sd    2.5%     50%   97.5% n_eff Rhat
## mu     102.22    0.03 1.83   98.61  102.23  105.79  3283    1
## sigma   18.19    0.02 1.27   15.93   18.12   20.98  2758    1
## lp__  -336.43    0.02 0.96 -338.94 -336.13 -335.48  1905    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:50:56 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
</div>
<div id="収束の確認" class="section level2">
<h2>14. 収束の確認</h2>
<ul>
<li>traceplot関数でstan関数の戻り値を処理</li>
<li>4回の結果（4つのチェーン）が重なっていればOK</li>
<li>traceplot(mcmc_result, inc_warmup=T)
<ul>
<li>バーンイン期間も表示</li>
</ul></li>
</ul>
<pre class="r"><code>traceplot(mcmc_result)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-27-1.png" width="768" /></p>
</div>
<div id="ベクトル化" class="section level2">
<h2>15. ベクトル化</h2>
<ul>
<li><span class="math inline">\(sales[N] \sim normal(mu, sigma)\)</span> をベクトルにする</li>
<li><span class="math inline">\(sales \sim normal(mu, sigma)\)</span>
<ul>
<li>わずかに結果が変わる</li>
</ul></li>
</ul>
</div>
<div id="モデルの図式化" class="section level2">
<h2>16. モデルの図式化</h2>
<ul>
<li>モデルの構造を図式化</li>
<li>グラフィカルモデル
<ul>
<li>実際のデータ：四角形</li>
<li>確率分布：円</li>
<li>確率的な関係：波線</li>
<li>確定的関係：実線</li>
</ul></li>
</ul>
</div>
</div>
<div id="stanコーディングの詳細" class="section level1">
<h1>2-6. Stanコーディングの詳細</h1>
<div id="stanファイルの構造" class="section level2">
<h2>2. Stanファイルの構造</h2>
<ul>
<li>Stanファイルの構成
<ul>
<li>function</li>
<li>data</li>
<li>transformed data</li>
<li>parameters</li>
<li>transformed parameters</li>
<li>model</li>
<li>generated quntities</li>
</ul></li>
</ul>
</div>
<div id="変数の宣言" class="section level2">
<h2>3. 変数の宣言</h2>
<ul>
<li>型と範囲
<ul>
<li>int N</li>
<li>real beta;</li>
<li>real&lt;lower=0&gt; beta;</li>
<li>int&lt;lower=0, upper=1&gt; range;</li>
</ul></li>
<li>ベクトル、配列の宣言
<ul>
<li>ベクトル、行列
<ul>
<li>実数値型</li>
<li>vector[3] retu;</li>
<li>row_vector[10] gyou;</li>
<li>matrix[3,2] mat;</li>
</ul></li>
<li>配列
<ul>
<li>ベクトルより柔軟、データ型を複数持てる</li>
<li>int w[10];</li>
<li>real x[3,4];</li>
<li>vector[4] Y[2]; //4要素のベクトルを2つ持つ配列Y</li>
<li>matrix[3,4] Z[5,6]; //3x4の行列を要素に持つ5x6の配列Z</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="代入" class="section level2">
<h2>4. 代入</h2>
<ul>
<li>transformed dataブロックやtransformed parametersブロック</li>
<li>= 代入演算子</li>
</ul>
</div>
<div id="サンプリング文" class="section level2">
<h2>5. サンプリング文</h2>
<ul>
<li>modelブロック</li>
<li>ビール売上の例
<ul>
<li>売上平均値のパラメータ<span class="math inline">\(\mu\)</span>, ばらつき<span class="math inline">\(\sigma^2\)</span></li>
<li>売上salesは平均<span class="math inline">\(\mu\)</span>, ばらつき<span class="math inline">\(\sigma^2\)</span>の正規分布からサンプリングされたと想定</li>
<li><span class="math inline">\(sales \sim Normal(\mu, \sigma^2)\)</span></li>
<li>N: サンプルサイズとして
<ul>
<li>model{ for (i in 1:N){ sales[i] ~ normal(mu, sigma) } }</li>
</ul></li>
<li>左辺ではデータでも、未知のパラメータでもOK</li>
<li>muとsigmaの事前分布は指定できる</li>
<li>model{ mu ~ normal(0, 1000000); sigma ~ normal(0, 1000000); for (i in 1:N){ sales[i] ~ normal(mu, sigma); } }</li>
<li>事前分布を変えたときに結果（＝事後分布）がどう変わってくるかの確認作業：感度分析</li>
</ul></li>
</ul>
</div>
<div id="弱情報事前分布の設定" class="section level2">
<h2>6. 弱情報事前分布の設定</h2>
<ul>
<li>パラメータの範囲が”ある程度”分かっているとき</li>
<li>“やや狭い”事前分布
<ul>
<li>例えば-5から5が想定されるとして、
<ul>
<li>uniform(-5, 5)のように範囲が厳格に決まった一様分布よりも</li>
<li>normal(0, 5)のような緩やかに範囲が決められる決め方が良い
<ul>
<li>t分布が使われたりもする</li>
<li>Prior Choice Recommendations参照</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>======= # 2-5章 MCMCの結果の評価</p>
</div>
<div id="mcmcの実行" class="section level2">
<h2>2. MCMCの実行</h2>
<ul>
<li>4章と同じ解析を実行</li>
</ul>
<pre class="r"><code>mcmc_result&lt;-stan(
  file=&quot;2-4-1-calc.mean-variance3.stan&quot;,
  data=data_list,
  seed=1,
  chains=4,
  iter=2000,
  warmup=1000,
  thin=1
)</code></pre>
</div>
<div id="mcmcサンプルの抽出" class="section level2">
<h2>3. MCMCサンプルの抽出</h2>
<ul>
<li>rstan::extract(): stanfitクラスからmcmcサンプルを抽出する</li>
<li>mcmc_sample &lt;- rstan::extract(mcmc_result, permuted=FALSE)</li>
<li>抜き出されたmcmc_sampleオブジェクトはarrayクラス、dimsは1000（iter数-wamup数), 4(chans数), 3(mu, sigma, lp__)となる。
<ul>
<li>dim_names(mcmc_samples)で確認できる</li>
</ul></li>
<li>mcmc_sample[]で要素を見ることができる</li>
<li>mcmc_sample[,,mu]だと<span class="math inline">\(\mu\)</span>のMCMCサンプル全てを取り出せる</li>
</ul>
<pre class="r"><code>mcmc_sample&lt;-rstan::extract(mcmc_result, permuted=FALSE)
class(mcmc_sample)</code></pre>
<pre><code>## [1] &quot;array&quot;</code></pre>
<pre class="r"><code>dim(mcmc_sample)</code></pre>
<pre><code>## [1] 1000    4    3</code></pre>
<pre class="r"><code>dimnames(mcmc_sample)</code></pre>
<pre><code>## $iterations
## NULL
## 
## $chains
## [1] &quot;chain:1&quot; &quot;chain:2&quot; &quot;chain:3&quot; &quot;chain:4&quot;
## 
## $parameters
## [1] &quot;mu&quot;    &quot;sigma&quot; &quot;lp__&quot;</code></pre>
<pre class="r"><code>mcmc_sample[c(1:8),&quot;chain:1&quot;,&quot;mu&quot;]</code></pre>
<pre><code>## [1] 104.0878 104.4901 102.4625 101.3802 102.5435 104.7143 100.2602 104.0725</code></pre>
<pre class="r"><code>dim(mcmc_sample[,,&quot;mu&quot;])</code></pre>
<pre><code>## [1] 1000    4</code></pre>
<pre class="r"><code>class(mcmc_sample[,,&quot;mu&quot;])</code></pre>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
</div>
<div id="mcmcサンプルの代表値の計算" class="section level2">
<h2>4. MCMCサンプルの代表値の計算</h2>
<ul>
<li>事後分布の代表値の計算</li>
</ul>
<pre class="r"><code>mu_mcmc_vec &lt;- as.vector(mcmc_sample[,,&quot;mu&quot;])
median(mu_mcmc_vec)</code></pre>
<pre><code>## [1] 102.2262</code></pre>
<pre class="r"><code>mean(mu_mcmc_vec)</code></pre>
<pre><code>## [1] 102.2221</code></pre>
<pre class="r"><code>quantile(mu_mcmc_vec, probs=c(0.025, 0.975))</code></pre>
<pre><code>##     2.5%    97.5% 
##  98.6053 105.7918</code></pre>
</div>
<div id="トレースプロットの描画" class="section level2">
<h2>5. トレースプロットの描画</h2>
<ul>
<li>MCMCサンプルをもとにトレースプロットの描画</li>
</ul>
<pre class="r"><code>library(ggfortify)
autoplot(ts(mcmc_sample[,,&quot;mu&quot;]),
  facets = F,
  ylab = &quot;mu&quot;,
  main= &quot;トレースプロット&quot;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-31-1.png" width="768" /> 6. ggplot2による事後分布の可視化 * MCMCサンプルをまとめる＝パラメータの事後分布</p>
<pre class="r"><code>mu_df &lt;- data.frame(mu_mcmc_sample &lt;- mu_mcmc_vec)
ggplot(data=mu_df, mapping=aes(x=mu_mcmc_sample))+geom_density(size=1.5)</code></pre>
<p><img src="baba_files/figure-html/ggplot2-1.png" width="768" /> ## 7. bayesplotによる事後分布の可視化 * bayesplot便利</p>
<pre class="r"><code>library(rstan)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
library(bayesplot)</code></pre>
<pre><code>## This is bayesplot version 1.8.1</code></pre>
<pre><code>## - Online documentation and vignettes at mc-stan.org/bayesplot</code></pre>
<pre><code>## - bayesplot theme set to bayesplot::theme_default()</code></pre>
<pre><code>##    * Does _not_ affect other ggplot2 plots</code></pre>
<pre><code>##    * See ?bayesplot_theme_set for details on theme setting</code></pre>
<pre class="r"><code>mcmc_hist(mcmc_sample, parc=c(&quot;mu&quot;, &quot;sigma&quot;))</code></pre>
<pre><code>## Warning: The following arguments were unrecognized and ignored: parc</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="baba_files/figure-html/bayesplot%20combo-1.png" width="768" /></p>
<pre class="r"><code>mcmc_combo(mcmc_sample, parc=c(&quot;mu&quot;,&quot;sigma&quot;))</code></pre>
<p><img src="baba_files/figure-html/bayesplot%20combo-2.png" width="768" /> ## 8. bayesplotによる事後分布の範囲の比較 ## 9. bayesplotによるMCMCサンプルの自己相関の評価 * コレログラムも描ける</p>
</div>
<div id="事後予測チェックの概要" class="section level2">
<h2>10. 事後予測チェックの概要</h2>
<ul>
<li>推定されたモデルの総合的評価方法
<ul>
<li>例えば、仮定した事柄が現実的だったかどうか</li>
</ul></li>
<li>事後予測チェックとは？
<ul>
<li>統計モデル：観測したデータを生み出す確率的な過程を簡潔に記述したもの
<ul>
<li>ってことは、統計モデルをうまく推定できているなら、データとよく似たデータを生成できるはず</li>
<li>モデルにしたがって観測データを擬似的に生成=事後予測分布/事後分布</li>
<li>データと事後予測分布を比べる</li>
<li>その方法の一つとしての「図示」</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="事後予測チェックの対象となるデータとモデル" class="section level2">
<h2>11. 事後予測チェックの対象となるデータとモデル</h2>
<ul>
<li>小動物の発見個体数
<ul>
<li>草原の中にランダムに個体が分布</li>
<li>試行回数が大きく、発生確率が小さい二項分布＝ポアソン分布</li>
<li>間違った分布として正規分布も考えてみる</li>
</ul></li>
</ul>
<pre class="r"><code>animal_num&lt;-read.csv(&quot;2-5-1-animal-num.csv&quot;)</code></pre>
</div>
</div>
<div id="stanコーディングの詳細-1" class="section level1">
<h1>2-6. Stanコーディングの詳細</h1>
<div id="stanファイルの構造-1" class="section level2">
<h2>2. Stanファイルの構造</h2>
<ul>
<li>Stanファイルの構成
<ul>
<li>function</li>
<li>data</li>
<li>transformed data</li>
<li>parameters</li>
<li>transformed parameters</li>
<li>model</li>
<li>generated quntities</li>
</ul></li>
</ul>
</div>
<div id="変数の宣言-1" class="section level2">
<h2>3. 変数の宣言</h2>
<ul>
<li>型と範囲
<ul>
<li>int N</li>
<li>real beta;</li>
<li>real&lt;lower=0&gt; beta;</li>
<li>int&lt;lower=0, upper=1&gt; range;</li>
</ul></li>
<li>ベクトル、配列の宣言
<ul>
<li>ベクトル、行列
<ul>
<li>実数値型</li>
<li>vector[3] retu;</li>
<li>row_vector[10] gyou;</li>
<li>matrix[3,2] mat;</li>
</ul></li>
<li>配列
<ul>
<li>ベクトルより柔軟、データ型を複数持てる</li>
<li>int w[10];</li>
<li>real x[3,4];</li>
<li>vector[4] Y[2]; //4要素のベクトルを2つ持つ配列Y</li>
<li>matrix[3,4] Z[5,6]; //3x4の行列を要素に持つ5x6の配列Z</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="代入-1" class="section level2">
<h2>4. 代入</h2>
<ul>
<li>transformed dataブロックやtransformed parametersブロック</li>
<li>= 代入演算子</li>
</ul>
</div>
<div id="サンプリング文-1" class="section level2">
<h2>5. サンプリング文</h2>
<ul>
<li>modelブロック</li>
<li>ビール売上の例
<ul>
<li>売上平均値のパラメータ<span class="math inline">\(\mu\)</span>, ばらつき<span class="math inline">\(\sigma^2\)</span></li>
<li>売上salesは平均<span class="math inline">\(\mu\)</span>, ばらつき<span class="math inline">\(\sigma^2\)</span>の正規分布からサンプリングされたと想定</li>
<li><span class="math inline">\(sales \sim Normal(\mu, \sigma^2)\)</span></li>
<li>N: サンプルサイズとして
<ul>
<li>model{ for (i in 1:N){ sales[i] ~ normal(mu, sigma) } }</li>
</ul></li>
<li>左辺ではデータでも、未知のパラメータでもOK</li>
<li>muとsigmaの事前分布は指定できる</li>
<li>model{ mu ~ normal(0, 1000000); sigma ~ normal(0, 1000000); for (i in 1:N){ sales[i] ~ normal(mu, sigma); } }</li>
<li>事前分布を変えたときに結果（＝事後分布）がどう変わってくるかの確認作業：感度分析</li>
</ul></li>
</ul>
</div>
<div id="弱情報事前分布の設定-1" class="section level2">
<h2>6. 弱情報事前分布の設定</h2>
<ul>
<li>パラメータの範囲が”ある程度”分かっているとき</li>
<li>“やや狭い”事前分布
<ul>
<li>例えば-5から5が想定されるとして、
<ul>
<li>uniform(-5, 5)のように範囲が厳格に決まった一様分布よりも</li>
<li>normal(0, 5)のような緩やかに範囲が決められる決め方が良い
<ul>
<li>t分布が使われたりもする</li>
<li>Prior Choice Recommendations参照</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="対数密度加算文" class="section level2">
<h2>7. 対数密度加算文</h2>
<ul>
<li>サンプリング文は対数密度加算文という形式でも実装可能</li>
<li>例えばmu, sigmaに従う正規分布にしたがって得られるデータ</li>
<li>対数密度加算文では
<ul>
<li>model{ for (i in 1:N) target += normal_lpdf(sales[i]|mu, sigma); }</li>
</ul></li>
<li>targetに対して対数確率密度関数(log probability density function)を加算してるということ
<ul>
<li>離散型の場合、lpmf(log probability mass function)</li>
</ul></li>
<li>事前分布として広い正規分布を与える場合
<ul>
<li>model{ target += normal_lpdf(mu|0, 1000000); target += normal_lpdf(sigma|0, 1000000);
<ul>
<li>ここでtargetはlp__(対数事後確率) }</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="平均値の差の評価とgenerated-quantitiesブロック" class="section level2">
<h2>8. 平均値の差の評価とgenerated quantitiesブロック</h2>
<ul>
<li>モデル推定とは独立に乱数を得たい</li>
</ul>
<pre class="r"><code>library(ggplot2)
library(rstan)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
file_beer_sales_ab&lt;-read.csv(&quot;2-6-1-beer-sales-ab.csv&quot;)
ggplot(data=file_beer_sales_ab, mapping=aes(x=sales, y=..density.., color=beer_name, fill=beer_name))+geom_histogram(alpha=0.5,position=&quot;identity&quot;)+geom_density(alpha=0.5, size=0)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="baba_files/figure-html/mcmc_result6-1.png" width="768" /></p>
<pre class="r"><code>sales_a&lt;-file_beer_sales_ab$sales[1:100]
sales_b&lt;-file_beer_sales_ab$sales[101:200]
data_list_ab&lt;-list(
  sales_a=sales_a,
  sales_b=sales_b,
  N=100
)

mcmc_result_6&lt;-stan(file=&quot;2-6-5-difference-mean.stan&quot;,
                    data=data_list_ab,
                    seed=1
)
print(mcmc_result_6, probs=c(0.025, 0.5, .0975))</code></pre>
<pre><code>## Inference for Stan model: 2-6-5-difference-mean.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##            mean se_mean   sd    2.5%     50%   9.75% n_eff Rhat
## mu_a     102.22    0.03 1.84   98.64  102.22   99.89  4352    1
## sigma_a   18.19    0.02 1.30   15.84   18.12   16.58  3742    1
## mu_b     168.88    0.05 2.92  163.14  168.91  165.15  3627    1
## sigma_b   29.11    0.03 2.09   25.37   28.96   26.47  4374    1
## diff      66.66    0.05 3.50   59.84   66.67   62.19  4094    1
## lp__    -719.42    0.03 1.45 -723.21 -719.07 -721.34  2249    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:51:00 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
</div>
<div id="練習問題" class="section level2">
<h2>練習問題</h2>
<ul>
<li>異なる分散を仮定</li>
</ul>
<pre class="r"><code>library(rstan)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
pdata&lt;-read.csv(&quot;data_if.csv&quot;)
xdata&lt;-pdata[which(pdata$con==&quot;X&quot;),]
ydata&lt;-pdata[which(pdata$con==&quot;Y&quot;),]
ggplot(data=pdata, mapping=aes(x=syakou, y=..density.., color=con, fill=con))+geom_histogram(alpha=0.5, position=&quot;identity&quot;)+geom_density(alpha=0.5, size=0)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="baba_files/figure-html/prac1-1.png" width="768" /></p>
<pre class="r"><code>list_xy&lt;-list(datax=xdata[,2],datay=ydata[,2],Nx=length(xdata[,2]),Ny=length(ydata[,2]))
mcmc_p_res &lt;- stan(file=&quot;2-6-5-pdata.stan&quot;,
                   data=list_xy,
                   seed=1
)
print(mcmc_p_res)</code></pre>
<pre><code>## Inference for Stan model: 2-6-5-pdata.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##           mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## mu_x      5.19    0.00 0.24   4.73   5.03   5.19   5.35   5.66  3376    1
## sigma_x   1.24    0.00 0.18   0.93   1.11   1.22   1.34   1.65  3326    1
## mu_y      2.60    0.00 0.22   2.17   2.46   2.61   2.75   3.05  3890    1
## sigma_y   1.10    0.00 0.17   0.83   0.97   1.07   1.20   1.49  3012    1
## diff      2.58    0.01 0.32   1.94   2.37   2.58   2.80   3.22  3643    1
## lp__    -32.31    0.04 1.48 -35.98 -33.01 -31.98 -31.25 -30.48  1552    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:51:01 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<pre class="r"><code>library(bayesplot)
mcmc_combo(mcmc_p_res, pars=c(&quot;mu_x&quot;, &quot;mu_y&quot;, &quot;sigma_x&quot;, &quot;sigma_y&quot;, &quot;diff&quot;))</code></pre>
<p><img src="baba_files/figure-html/prac1-2.png" width="768" /></p>
<pre class="r"><code>stan_hist(mcmc_p_res)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="baba_files/figure-html/prac1-3.png" width="768" /></p>
<ul>
<li>同じ分散を仮定</li>
</ul>
<pre class="r"><code>library(rstan)
library(ggplot2)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
pdata&lt;-read.csv(&quot;data_if.csv&quot;)
xdata&lt;-pdata[which(pdata$con==&quot;X&quot;),]
ydata&lt;-pdata[which(pdata$con==&quot;Y&quot;),]

ggplot(data=pdata, mapping=aes(x=syakou, y=..density.., color=con, fill=con))+geom_histogram(alpha=0.5, position=&quot;identity&quot;)+geom_density(alpha=0.5, size=0)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="baba_files/figure-html/prac2-1.png" width="768" /></p>
<pre class="r"><code>list_xy&lt;-list(datax=xdata[,2],datay=ydata[,2],Nx=length(xdata[,2]),Ny=length(ydata[,2]))

mcmc_p_res &lt;- stan(file=&quot;2-6-5-pdata2.stan&quot;,
                   data=list_xy,
                   seed=1
)
print(mcmc_p_res)</code></pre>
<pre><code>## Inference for Stan model: 2-6-5-pdata2.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##         mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## mu_x    5.18    0.00 0.22   4.75   5.04   5.18   5.33   5.60  3458    1
## sigma   1.15    0.00 0.12   0.94   1.06   1.13   1.22   1.41  3170    1
## mu_y    2.60    0.00 0.23   2.14   2.45   2.60   2.76   3.06  3492    1
## diff    2.58    0.01 0.32   1.94   2.37   2.58   2.79   3.19  3575    1
## lp__  -32.07    0.03 1.26 -35.38 -32.66 -31.74 -31.15 -30.63  1686    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:51:03 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
</div>
</div>
<div id="章-1" class="section level1">
<h1>3章</h1>
</div>
<div id="章-一般化線形モデルの基本" class="section level1">
<h1>3-1章: 一般化線形モデルの基本</h1>
<div id="目的と概要-1" class="section level2">
<h2>1. 目的と概要</h2>
<ul>
<li>一般化線形モデル(GLM): 実践的モデル &amp; 複雑なモデルの部品</li>
<li>確率分布、線形予測子、リンク関数</li>
<li>リファレンス的に使える章</li>
</ul>
</div>
<div id="複雑なモデルを構築する際の手続きの標準化" class="section level2">
<h2>2. 複雑なモデルを構築する際の手続きの標準化</h2>
<ul>
<li>モデルをどう構築するか</li>
<li>ビールの売り上げの例
<ul>
<li><span class="math inline">\(y \sim Normal(\mu,\sigma^2)\)</span></li>
<li>これを複雑にしようとしたとき、“勝手に”やるばかりだと非効率かも</li>
<li>「モデルの方」「フレームワーク」</li>
</ul></li>
<li>一般化線形モデルにおけるモデルの変更手続き
<ol style="list-style-type: decimal">
<li>確率分布を変える</li>
<li>線形予測子を変える</li>
<li>リンク関数を変える</li>
</ol></li>
</ul>
</div>
<div id="確率分布線形予測子リンク関数" class="section level2">
<h2>3. 確率分布・線形予測子・リンク関数</h2>
<ul>
<li>確率分布
<ul>
<li>観測データを生む確率的過程を表現するためのもの。データに合わせて変える。
<ul>
<li>ビールなら正規分布</li>
<li>小動物の数ならポアソン分布</li>
<li>購入比率なら二項分布</li>
</ul></li>
</ul></li>
<li>変数
<ul>
<li>応答変数・従属変数</li>
<li>説明変数</li>
</ul></li>
<li>線形予測子
<ul>
<li>説明変数の線型結合</li>
</ul></li>
<li>リンク関数
<ul>
<li>応答変数と線形予測子を関係付けること</li>
</ul></li>
</ul>
</div>
<div id="一般化線形モデルの例-説明変数が無く正規分布を仮定するモデル" class="section level2">
<h2>4. 一般化線形モデルの例: 説明変数が無く、正規分布を仮定するモデル</h2>
<ul>
<li>ビール売り上げの例
<ul>
<li>凡例
<ul>
<li><span class="math inline">\(y_i\)</span>:売り上げデータ</li>
<li><span class="math inline">\(\mu_i\)</span>: <span class="math inline">\(y_i\)</span>の期待値</li>
<li><span class="math inline">\(_i\)</span>: 何番目のデータか</li>
<li><span class="math inline">\(g\)</span>: 恒等関数（<span class="math inline">\(g(y)=y\)</span>となる関数=何も起きない関数）</li>
</ul></li>
<li>一般化線形モデル
<ul>
<li><span class="math inline">\(g(\mu_i)=\beta_0\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu, \sigma^2)\)</span></li>
<li><span class="math inline">\(\beta_0\)</span>が線形予測子、恒等関数<span class="math inline">\(g()\)</span>がリンク関数</li>
</ul></li>
<li>書き換え
<ul>
<li><span class="math inline">\(\mu_i=\beta_0\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu, \sigma^2)\)</span></li>
</ul></li>
<li>従属変数の平均値<span class="math inline">\(\mu_i\)</span>が値<span class="math inline">\(\beta_0\)</span>をとることを想定したモデル</li>
</ul></li>
</ul>
</div>
<div id="単回帰モデル-説明変数が1つだけあり正規分布を仮定するモデル" class="section level2">
<h2>5. 単回帰モデル: 説明変数が1つだけあり、正規分布を仮定するモデル</h2>
<ul>
<li>ビールの売り上げが気温<span class="math inline">\(x\)</span>によって変化するというモデル
<ul>
<li><span class="math inline">\(g(\mu_i)=\beta_0+\beta_1x_i\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu_i, \sigma^2)\)</span></li>
<li><span class="math inline">\(\beta_0+\beta_1x_i\)</span>が線形予測子、恒等関数<span class="math inline">\(g()\)</span>がリンク関数</li>
</ul></li>
<li>書き換え
<ul>
<li><span class="math inline">\(\mu_i = \beta_0 + \beta_1x_i\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu_i, \sigma^2)\)</span></li>
</ul></li>
<li>気温<span class="math inline">\(x\)</span>が1変化すると<span class="math inline">\(\beta_1\)</span>増減する</li>
<li>単回帰モデル
<ul>
<li><span class="math inline">\(\beta_0\)</span>を切片</li>
<li><span class="math inline">\(\beta_1\)</span>を<span class="math inline">\(x\)</span>の係数・傾き</li>
</ul></li>
<li>単回帰モデルを使うことで..
<ul>
<li>説明変数と従属変数の関係の考察</li>
<li>従属変数の予測</li>
</ul></li>
</ul>
</div>
<div id="分散分析モデルダミー変数を利用するモデル" class="section level2">
<h2>6. 分散分析モデル：ダミー変数を利用するモデル</h2>
<ul>
<li>説明変数が質的変数のとき
<ul>
<li>ダミー変数を使う必要性
<ul>
<li>ダミー変数：0 / 1</li>
<li>晴れ・雨・曇りを表現する
<ul>
<li>晴れ：0/1</li>
<li>雨: 0/1</li>
</ul></li>
<li>状態-1の変数
<ul>
<li>1 0 -&gt; 晴れ</li>
<li>0 1 -&gt; 雨</li>
<li>0 0 -&gt; 曇り</li>
</ul></li>
</ul></li>
</ul></li>
<li>ビールの例
<ul>
<li>売上が天気の影響を受ける
<ul>
<li><span class="math inline">\(x_1\)</span>:晴れなら1, <span class="math inline">\(x_2\)</span>: 雨なら1, <span class="math inline">\(g()\)</span>: 恒等関数
<ul>
<li><span class="math inline">\(g(\mu_i)=\beta_0+\beta_1x_{i1}+\beta_{i2}\)</span></li>
<li>y Normal(_i, ^2)</li>
</ul></li>
<li>書き換え
<ul>
<li><span class="math inline">\(\mu_i=\beta_0+\beta_1x_{i1}+\beta_{i2}\)</span></li>
</ul></li>
<li>分散分析モデル
<ul>
<li>説明変数が質的データ</li>
<li>確率分布として正規分布</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="正規線形モデル正規分布を仮定するモデル" class="section level2">
<h2>7. 正規線形モデル：正規分布を仮定するモデル</h2>
<ul>
<li>単回帰モデルも分散分析モデルも含まれる</li>
<li>リンク関数は恒等関数</li>
<li>確率分布は正規分布</li>
<li>説明変数は量的だけ（単回帰モデル）、質的だけ（分散分析モデル）、両方とも（？）</li>
</ul>
</div>
<div id="ポアソン回帰モデル" class="section level2">
<h2>8. ポアソン回帰モデル</h2>
<ul>
<li>魚の釣果尾数のモデル化
<ul>
<li>あまり釣れないし生の数のみ、ポアソン分布に従う</li>
<li>分布のパラメータ<span class="math inline">\(\lambda\)</span>は気温と天気の影響を受ける
<ul>
<li><span class="math inline">\(p(y_i|\lambda_i)=\frac{\lambda_i^{y_i} exp(-\lambda_i)}{y_i!}\)</span></li>
<li>ここから、ちょっと馬場本の式3.10, 3.11が分かりにくく感じたので、緑本p159の説明順を参考に表現を変えます。なんでexp()なのか、logなのかの説明がなくて分からない。
<ul>
<li>パラメータ<span class="math inline">\(\lambda\)</span>が次の式に従うとする
<ul>
<li><span class="math inline">\(\lambda_i = exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)\)</span></li>
</ul></li>
<li>この式を変形すると
<ul>
<li><span class="math inline">\(log\lambda_i = \beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3\)</span></li>
<li>リンク関数: <span class="math inline">\(log\lambda_i\)</span> -&gt; 対数リンク関数</li>
<li>線形予測子：<span class="math inline">\(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3\)</span></li>
</ul></li>
<li>馬場本P159の式3.11
<ul>
<li><span class="math inline">\(\lambda=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3\)</span> (3.11)</li>
</ul></li>
<li>は誤解しそう</li>
<li>緑本のように
<ul>
<li><span class="math inline">\(\lambda=exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)\)</span></li>
</ul></li>
<li>とした方がいい気がする。</li>
<li>ポアソン回帰には対数リンク関数、ロジスティック回帰にはロジットリンク関数＝正準リンク関数
<ul>
<li>Rのglm()では特に指定しなけば確率分布ごとに異なる正準リンク関数が使われる</li>
<li>なぜポアソン回帰には対数リンク関数を使うのか？
<ol style="list-style-type: decimal">
<li>推定計算に都合がいいから(緑本P48): <span class="math inline">\(\lambda_i\)</span>がexp(線形予測子)になるので、負になることがない。都合がいい。</li>
<li>わかりやすいから（緑本P59あたり）：効果が掛け算になる。<span class="math inline">\(exp(\beta_0+\beta_1x_1)\)</span>は<span class="math inline">\(exp(\beta_0)\times exp(\beta_1x_1)\)</span>。複数の効果が掛け算で効いてくる方がもっともらしい。</li>
</ol></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="ロジスティック回帰モデル-二項分布を仮定するモデル" class="section level2">
<h2>9. ロジスティック回帰モデル: 二項分布を仮定するモデル</h2>
<ul>
<li>コインの裏表、種子の発芽率（発芽するかしないか）、商品の購入率（するしない）
<ul>
<li>二値確率変数</li>
<li>二項分布</li>
</ul></li>
<li>例：植物の種子の発芽率
<ul>
<li>10粒中発芽する種子数をモデル化
<ul>
<li>試行回数10の二項分布、成功確率<span class="math inline">\(p\)</span></li>
<li><span class="math inline">\(p\)</span>は日照の有無と栄養素の量に影響される</li>
<li><span class="math inline">\(y_i\)</span>: 10粒のうち発芽した数</li>
<li><span class="math inline">\(x_{i1}\)</span>: 日が当たっていれば1、当たっていなければ0のダミー変数</li>
<li><span class="math inline">\(x_{i2}\)</span>: 栄養素の量</li>
<li><span class="math inline">\(logit(p_i)=\beta_0+\beta_1x_1+\beta_2x_2\)</span></li>
<li><span class="math inline">\(y\sim Binom(10,p_i)\)</span></li>
</ul></li>
<li>ロジット関数<span class="math inline">\(logit()\)</span>
<ul>
<li><span class="math inline">\(logit(p)+log(\frac{p}{1-p})\)</span></li>
</ul></li>
<li>ロジット関数の逆関数＝ロジスティック関数
<ul>
<li><span class="math inline">\(logistic(x)=\frac{1}{1+exp(-x)}\)</span></li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>x&lt;-seq(-10,10,0.01)
y&lt;-1/(1+exp(-x))
plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-32-1.png" width="768" /></p>
<ul>
<li>ここで馬場本では、「二項分布のリンク関数はロジット関数なので、その逆関数であるロジスティック関数を使った回帰モデルを使う」という書き方をしてるけど、これだとやっぱりなぜリンク関数がロジット関数なのかが不明のまま。</li>
<li>緑本(P120)より
<ul>
<li><span class="math inline">\(z_i\)</span>についてのロジスティック関数<span class="math inline">\(q_i=logistic(z_i)\)</span>は上↑のような形をしているので、<span class="math inline">\(z_i=\beta_1+\beta_2x_2...\)</span>としたときの<span class="math inline">\(z_i\)</span>（つまり線形予測子）がどのような値をとっても<span class="math inline">\(0\leq q_i \leq 1\)</span>が成り立つ。だからロジスティック関数を使いたい。</li>
<li>ロジスティック関数を変形すると<span class="math inline">\(log\frac{q_i}{1-q_i}=z_i\)</span>となり、この左辺をロジット関数と呼ぶ。
<ul>
<li>だから、<span class="math inline">\(logit(p_i)=\beta_0+\beta_1x_1+\beta_2x_2\)</span>（＝線形予測子）と、ロジット関数がリンク関数となり、</li>
<li>二項分布 <span class="math inline">\(y \sim Binom(10,p_i)\)</span>のパラメータ<span class="math inline">\(p_i\)</span>が<span class="math inline">\(p_i=logistic(線形予測子)\)</span>と表せると理解すべきかと。</li>
</ul></li>
<li>このあたり、P217のポアソン回帰モデルのStanファイル、P226のロジスティック回帰モデルのStanファイル（の下の説明）ではパラメータ＝exp(線形予測子)やパラメータ＝inv_logit(線形予測子)としていて、理解しやすい。</li>
</ul></li>
</ul>
</div>
<div id="一般化線形モデルの行列表現" class="section level2">
<h2>10. 一般化線形モデルの行列表現</h2>
<ul>
<li>説明変数がj個ある、i番目のデータに関する一般化線形モデルの線形予測子は、1行j列のデータのベクトル<span class="math inline">\(x_i\)</span>とj行1列の係数のベクトル<span class="math inline">\(\boldsymbol{\beta}\)</span>の積で表すと簡潔だよっていう話</li>
<li><span class="math inline">\(\lambda=exp(x_i\beta)\)</span> # こう書ききたい。本ではここにはexp()はついていない</li>
<li><span class="math inline">\(y_i \sim Poiss(\lambda_i)\)</span> # こう書きたい。こっちにexp()がついている
<ul>
<li>ただし、データ<span class="math inline">\(x_i\)</span>はデザイン行列<span class="math inline">\(\boldsymbol{X}\)</span>の<span class="math inline">\(i\)</span>行目。</li>
</ul></li>
</ul>
</div>
<div id="補足データの表記とベクトル行列" class="section level2">
<h2>11. 補足：データの表記とベクトル・行列</h2>
<ul>
<li>データ：<span class="math inline">\(y_1, y_2, ..., y_N\)</span></li>
<li>ベクトルとスカラー
<ul>
<li>ベクトル: <span class="math inline">\(\boldsymbol{y}=[y_1\ y_2\ y_3]^T\)</span> #さすがに面倒なので列ベクトルは表示しない
<ul>
<li>ベクトルは<span class="math inline">\(\textbf{小文字太字}\)</span>で表す。Rstudioでギリシャ文字の太文字は結構めんどうで\boldsymbol{}を使うらしい</li>
<li>Tは<span class="math inline">\(transpose\)</span>転置のこと</li>
</ul></li>
<li>スカラーは量、1要素</li>
</ul></li>
<li>2つ以上の変数をまとめるときは行列とする
<ul>
<li>行列は<span class="math inline">\(\textbf{大文字太字}\)</span>で表す</li>
<li>これも面倒なので表記は省略</li>
<li>m行n列の行列という呼び方</li>
</ul></li>
</ul>
</div>
<div id="補足行列の基本的な演算" class="section level2">
<h2>12. 補足：行列の基本的な演算</h2>
<ul>
<li>行列の足し算：同じサイズの行列のみ。要素同士の足し算。</li>
<li>行列のスカラ倍：各要素<span class="math inline">\(\times\)</span>スカラ量</li>
</ul>
<pre class="r"><code>A&lt;-matrix(seq(1,6), 3, 2)
B&lt;-matrix(seq(7,12), 3, 2)
A+B</code></pre>
<pre><code>##      [,1] [,2]
## [1,]    8   14
## [2,]   10   16
## [3,]   12   18</code></pre>
<pre class="r"><code>3*A</code></pre>
<pre><code>##      [,1] [,2]
## [1,]    3   12
## [2,]    6   15
## [3,]    9   18</code></pre>
</div>
<div id="行列の掛け算" class="section level2">
<h2>13. 行列の掛け算</h2>
<ul>
<li>行列の掛け算は知ってますよね、みなさん。</li>
<li>Rでの演算子は %*%</li>
<li>*は要素同士の掛け算</li>
</ul>
<pre class="r"><code>A&lt;-matrix(seq(1,6), 3, 2)
C&lt;-matrix(seq(10,15),2,3)
A %*% C</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]   54   64   74
## [2,]   75   89  103
## [3,]   96  114  132</code></pre>
<pre class="r"><code>C %*% A</code></pre>
<pre><code>##      [,1] [,2]
## [1,]   76  184
## [2,]   82  199</code></pre>
</div>
<div id="一般化線形モデルのさまざまなトピック" class="section level2">
<h2>14. 一般化線形モデルのさまざまなトピック</h2>
<ul>
<li>交互作用：説明変数同士の影響を考えるモデル。交互作用項を作るなど。<span class="math inline">\(x_1x_2\)</span>。緑本P127</li>
<li>オフセット項：係数を1に固定することである説明変数による影響を固定する？わざ。緑本P133</li>
<li>多項ロジスティック回帰：3つ以上のカテゴリでどの比率が高くなるか、のような問題のモデル化。確率分布としてカテゴリカル分布、リンク関数としてソフトマックス関数。</li>
<li>ガンマ回帰：0以上の連続型データ。ガンマ分布、対数関数。</li>
<li>brms。</li>
</ul>
</div>
<div id="例題-伊丸岡研の希望人数に実験科目を担当していたかがどう影響するか" class="section level2">
<h2>例題: 伊丸岡研の希望人数に実験科目を担当していたかがどう影響するか</h2>
<ul>
<li>imrlab.csv
<ul>
<li>year</li>
<li>population: クラス人数</li>
<li>imrlab: 伊丸岡研希望数</li>
<li>wtnblab: 渡邊研希望数（参考）</li>
<li>basic: 基礎実験担当かどうか（ダミー変数）</li>
<li>senior: 専門実験担当かどうか（ダミー変数）</li>
</ul></li>
<li>imrlab.stan</li>
</ul>
<pre class="r"><code>DATA&lt;-read.csv(&#39;imrlab.csv&#39;)
library(rstan)
data_list&lt;-list(population=DATA[,1], applicant=DATA[,2],basic=DATA[,3],senior=DATA[,4], N=9)
mr &lt;- stan(
  file=&quot;imrlab.stan&quot;,
  data=data_list,
  iter=2000,
  warmup=1000,
  thin=1
)
print(mr,probs=c(0.025,0.5,0.975))</code></pre>
<pre><code>## Inference for Stan model: imrlab.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##               mean se_mean   sd     2.5%      50%    97.5% n_eff Rhat
## Intercept    -3.79    0.00 0.16    -4.10    -3.79    -3.46  1200    1
## b_basic       0.03    0.00 0.01     0.00     0.03     0.05  1610    1
## b_senior     -0.01    0.00 0.01    -0.04    -0.01     0.02  1490    1
## lp__      -2140.14    0.03 1.21 -2143.27 -2139.82 -2138.76  1310    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:51:04 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<pre class="r"><code>stan_trace(mr)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-35-1.png" width="768" /></p>
<pre class="r"><code>stan_dens(mr)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-35-2.png" width="768" /> # 3-2: 単回帰モデル</p>
</div>
<div id="目的と概要-2" class="section level2">
<h2>2.1 目的と概要</h2>
<ul>
<li>一般化線形モデルの初歩</li>
</ul>
</div>
<div id="分析の準備-1" class="section level2">
<h2>2.2 分析の準備</h2>
<ul>
<li>パッケージの読み込み(rstan, beysplot)</li>
<li>オプション指定</li>
</ul>
</div>
<div id="データ読み込みと可視化" class="section level2">
<h2>2.3 データ読み込みと可視化</h2>
<ul>
<li>ビールの売り上げ</li>
</ul>
<pre class="r"><code>rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
library(rstan)
library(bayesplot)
bs2&lt;-read.csv(&#39;3-2-1-beer-sales-2.csv&#39;)
sample_size&lt;-nrow(bs2)
ggplot(bs2, aes(x=temperature, y=sales)) + geom_point()+labs(title=&#39;ビールの売り上げと気温の関係&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-36-1.png" width="768" /></p>
</div>
<div id="モデルの構造" class="section level2">
<h2>2.4 モデルの構造</h2>
<ul>
<li>3部1章でやった形
<ul>
<li><span class="math inline">\(\mu_i = \beta_0 + \beta_1x_i\)</span></li>
<li><span class="math inline">\(y \sim Normal(\mu_i, \sigma^2)\)</span></li>
<li>気温によってビールの売り上げの平均値(<span class="math inline">\(\mu_i\)</span>)が増減する</li>
</ul></li>
<li>Stanで便利なように偏数名などを合わせる。恒等関数なので<span class="math inline">\(\mu_i\)</span>もまとめる。
<ul>
<li><span class="math inline">\(sales_i\sim Normal(Intercept+beta\times temperature_i,sigma^2)\)</span></li>
</ul></li>
<li>上の式に合わせてStanファイル実装</li>
</ul>
</div>
<div id="単回帰モデルのためのstanファイルの実装" class="section level2">
<h2>2.5 単回帰モデルのためのStanファイルの実装</h2>
<ul>
<li>chunkを使って書いてみる
<ul>
<li>var=beerでモデルのオブジェクトを作成、使用できる</li>
<li>rstan::samplingの第1引数でモデルオブジェクト、dataオプションでデータオブジェクトを指定。</li>
</ul></li>
</ul>
<pre class="stan"><code>data{
  int N;
  vector[N] sales;
  vector[N] temperature;
}
parameters{
  real Intercept;
  real beta;
  real&lt;lower=0&gt; sigma;
}
model{
  sales ~ normal(Intercept+beta * temperature, sigma);
}</code></pre>
</div>
<div id="mcmcの実行-2.7-事後分布の可視化" class="section level2">
<h2>2.6 MCMCの実行, 2.7 事後分布の可視化</h2>
<ul>
<li>ここでは前で作ったモデルオブジェクトを使う</li>
</ul>
<pre class="r"><code>library(bayesplot)
data_list&lt;-list(
  N=sample_size,
  sales=bs2$sales,
  temperature=bs2$temperature
)
mr&lt;-rstan::sampling(beer, data=data_list, seed=1)
print(mr, probs=c(0.025, 0.5, 0.975))</code></pre>
<pre><code>## Inference for Stan model: 31d2b526651ec414e920d1821baf3500.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##              mean se_mean   sd    2.5%     50%   97.5% n_eff Rhat
## Intercept   21.23    0.15 5.75   10.29   21.09   32.64  1420    1
## beta         2.45    0.01 0.28    1.90    2.46    2.98  1427    1
## sigma       17.07    0.03 1.21   14.89   16.96   19.67  1629    1
## lp__      -330.07    0.03 1.20 -333.26 -329.75 -328.73  1288    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:51:21 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<pre class="r"><code>mcs&lt;-rstan::extract(mr, permuted=FALSE)
mcmc_combo(
  mcs,
  parc=c(&quot;Intercept&quot;,&quot;beta&quot;,&quot;sigma&quot;)
)</code></pre>
<p><img src="baba_files/figure-html/beer-1.png" width="768" /></p>
</div>
<div id="まとめ" class="section level2">
<h2>2.8 まとめ</h2>
<ol style="list-style-type: decimal">
<li>Rパッケージ読み込み</li>
<li>データ読み込み、可視化して確認</li>
<li>Stanファイルの実装</li>
<li>MCMC実行</li>
<li>収束していることの確認（Rhatなど）</li>
<li>興味あるパラメータの事後分布確認</li>
</ol>
</div>
</div>
<div id="章-一般化線形モデルの基本-1" class="section level1">
<h1>3-1章: 一般化線形モデルの基本</h1>
<div id="目的と概要-3" class="section level2">
<h2>1. 目的と概要</h2>
<ul>
<li>一般化線形モデル(GLM): 実践的モデル &amp; 複雑なモデルの部品</li>
<li>確率分布、線形予測子、リンク関数</li>
<li>リファレンス的に使える章</li>
</ul>
</div>
<div id="複雑なモデルを構築する際の手続きの標準化-1" class="section level2">
<h2>2. 複雑なモデルを構築する際の手続きの標準化</h2>
<ul>
<li>モデルをどう構築するか</li>
<li>ビールの売り上げの例
<ul>
<li><span class="math inline">\(y \sim Normal(\mu,\sigma^2)\)</span></li>
<li>これを複雑にしようとしたとき、“勝手に”やるばかりだと非効率かも</li>
<li>「モデルの方」「フレームワーク」</li>
</ul></li>
<li>一般化線形モデルにおけるモデルの変更手続き
<ol style="list-style-type: decimal">
<li>確率分布を変える</li>
<li>線形予測子を変える</li>
<li>リンク関数を変える</li>
</ol></li>
</ul>
</div>
<div id="確率分布線形予測子リンク関数-1" class="section level2">
<h2>3. 確率分布・線形予測子・リンク関数</h2>
<ul>
<li>確率分布
<ul>
<li>観測データを生む確率的過程を表現するためのもの。データに合わせて変える。
<ul>
<li>ビールなら正規分布</li>
<li>小動物の数ならポアソン分布</li>
<li>購入比率なら二項分布</li>
</ul></li>
</ul></li>
<li>変数
<ul>
<li>応答変数・従属変数</li>
<li>説明変数</li>
</ul></li>
<li>線形予測子
<ul>
<li>説明変数の線型結合</li>
</ul></li>
<li>リンク関数
<ul>
<li>応答変数と線形予測子を関係付けること</li>
</ul></li>
</ul>
</div>
<div id="一般化線形モデルの例-説明変数が無く正規分布を仮定するモデル-1" class="section level2">
<h2>4. 一般化線形モデルの例: 説明変数が無く、正規分布を仮定するモデル</h2>
<ul>
<li>ビール売り上げの例
<ul>
<li>凡例
<ul>
<li><span class="math inline">\(y_i\)</span>:売り上げデータ</li>
<li><span class="math inline">\(\mu_i\)</span>: <span class="math inline">\(y_i\)</span>の期待値</li>
<li><span class="math inline">\(_i\)</span>: 何番目のデータか</li>
<li><span class="math inline">\(g\)</span>: 恒等関数（<span class="math inline">\(g(y)=y\)</span>となる関数=何も起きない関数）</li>
</ul></li>
<li>一般化線形モデル
<ul>
<li><span class="math inline">\(g(\mu_i)=\beta_0\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu, \sigma^2)\)</span></li>
<li><span class="math inline">\(\beta_0\)</span>が線形予測子、恒等関数<span class="math inline">\(g()\)</span>がリンク関数</li>
</ul></li>
<li>書き換え
<ul>
<li><span class="math inline">\(\mu_i=\beta_0\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu, \sigma^2)\)</span></li>
</ul></li>
<li>従属変数の平均値<span class="math inline">\(\mu_i\)</span>が値<span class="math inline">\(\beta_0\)</span>をとることを想定したモデル</li>
</ul></li>
</ul>
</div>
<div id="単回帰モデル-説明変数が1つだけあり正規分布を仮定するモデル-1" class="section level2">
<h2>5. 単回帰モデル: 説明変数が1つだけあり、正規分布を仮定するモデル</h2>
<ul>
<li>ビールの売り上げが気温<span class="math inline">\(x\)</span>によって変化するというモデル
<ul>
<li><span class="math inline">\(g(\mu_i)=\beta_0+\beta_1x_i\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu_i, \sigma^2)\)</span></li>
<li><span class="math inline">\(\beta_0+\beta_1x_i\)</span>が線形予測子、恒等関数<span class="math inline">\(g()\)</span>がリンク関数</li>
</ul></li>
<li>書き換え
<ul>
<li><span class="math inline">\(\mu_i = \beta_0 + \beta_1x_i\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu_i, \sigma^2)\)</span></li>
</ul></li>
<li>気温<span class="math inline">\(x\)</span>が1変化すると<span class="math inline">\(\beta_1\)</span>増減する</li>
<li>単回帰モデル
<ul>
<li><span class="math inline">\(\beta_0\)</span>を切片</li>
<li><span class="math inline">\(\beta_1\)</span>を<span class="math inline">\(x\)</span>の係数・傾き</li>
</ul></li>
<li>単回帰モデルを使うことで..
<ul>
<li>説明変数と従属変数の関係の考察</li>
<li>従属変数の予測</li>
</ul></li>
</ul>
</div>
<div id="分散分析モデルダミー変数を利用するモデル-1" class="section level2">
<h2>6. 分散分析モデル：ダミー変数を利用するモデル</h2>
<ul>
<li>説明変数が質的変数のとき
<ul>
<li>ダミー変数を使う必要性
<ul>
<li>ダミー変数：0 / 1</li>
<li>晴れ・雨・曇りを表現する
<ul>
<li>晴れ：0/1</li>
<li>雨: 0/1</li>
</ul></li>
<li>状態-1の変数
<ul>
<li>1 0 -&gt; 晴れ</li>
<li>0 1 -&gt; 雨</li>
<li>0 0 -&gt; 曇り</li>
</ul></li>
</ul></li>
</ul></li>
<li>ビールの例
<ul>
<li>売上が天気の影響を受ける
<ul>
<li><span class="math inline">\(x_1\)</span>:晴れなら1, <span class="math inline">\(x_2\)</span>: 雨なら1, <span class="math inline">\(g()\)</span>: 恒等関数
<ul>
<li><span class="math inline">\(g(\mu_i)=\beta_0+\beta_1x_{i1}+\beta_{i2}\)</span></li>
<li>y Normal(_i, ^2)</li>
</ul></li>
<li>書き換え
<ul>
<li><span class="math inline">\(\mu_i=\beta_0+\beta_1x_{i1}+\beta_{i2}\)</span></li>
</ul></li>
<li>分散分析モデル
<ul>
<li>説明変数が質的データ</li>
<li>確率分布として正規分布</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="正規線形モデル正規分布を仮定するモデル-1" class="section level2">
<h2>7. 正規線形モデル：正規分布を仮定するモデル</h2>
<ul>
<li>単回帰モデルも分散分析モデルも含まれる</li>
<li>リンク関数は恒等関数</li>
<li>確率分布は正規分布</li>
<li>説明変数は量的だけ（単回帰モデル）、質的だけ（分散分析モデル）、両方とも（？）</li>
</ul>
</div>
<div id="ポアソン回帰モデル-1" class="section level2">
<h2>8. ポアソン回帰モデル</h2>
<ul>
<li>魚の釣果尾数のモデル化
<ul>
<li>あまり釣れないし生の数のみ、ポアソン分布に従う</li>
<li>分布のパラメータ<span class="math inline">\(\lambda\)</span>は気温と天気の影響を受ける
<ul>
<li><span class="math inline">\(p(y_i|\lambda_i)=\frac{\lambda_i^{y_i} exp(-\lambda_i)}{y_i!}\)</span></li>
<li>ここから、ちょっと馬場本の式3.10, 3.11が分かりにくく感じたので、緑本p159の説明順を参考に表現を変えます。なんでexp()なのか、logなのかの説明がなくて分からない。
<ul>
<li>パラメータ<span class="math inline">\(\lambda\)</span>が次の式に従うとする
<ul>
<li><span class="math inline">\(\lambda_i = exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)\)</span></li>
</ul></li>
<li>この式を変形すると
<ul>
<li><span class="math inline">\(log\lambda_i = \beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3\)</span></li>
<li>リンク関数: <span class="math inline">\(log\lambda_i\)</span> -&gt; 対数リンク関数</li>
<li>線形予測子：<span class="math inline">\(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3\)</span></li>
</ul></li>
<li>馬場本P159の式3.11
<ul>
<li><span class="math inline">\(\lambda=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3\)</span> (3.11)</li>
</ul></li>
<li>は誤解しそう</li>
<li>緑本のように
<ul>
<li><span class="math inline">\(\lambda=exp(\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3)\)</span></li>
</ul></li>
<li>とした方がいい気がする。</li>
<li>ポアソン回帰には対数リンク関数、ロジスティック回帰にはロジットリンク関数＝正準リンク関数
<ul>
<li>Rのglm()では特に指定しなけば確率分布ごとに異なる正準リンク関数が使われる</li>
<li>なぜポアソン回帰には対数リンク関数を使うのか？
<ol style="list-style-type: decimal">
<li>推定計算に都合がいいから(緑本P48): <span class="math inline">\(\lambda_i\)</span>がexp(線形予測子)になるので、負になることがない。都合がいい。</li>
<li>わかりやすいから（緑本P59あたり）：効果が掛け算になる。<span class="math inline">\(exp(\beta_0+\beta_1x_1)\)</span>は<span class="math inline">\(exp(\beta_0)\times exp(\beta_1x_1)\)</span>。複数の効果が掛け算で効いてくる方がもっともらしい。</li>
</ol></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="ロジスティック回帰モデル-二項分布を仮定するモデル-1" class="section level2">
<h2>9. ロジスティック回帰モデル: 二項分布を仮定するモデル</h2>
<ul>
<li>コインの裏表、種子の発芽率（発芽するかしないか）、商品の購入率（するしない）
<ul>
<li>二値確率変数</li>
<li>二項分布</li>
</ul></li>
<li>例：植物の種子の発芽率
<ul>
<li>10粒中発芽する種子数をモデル化
<ul>
<li>試行回数10の二項分布、成功確率<span class="math inline">\(p\)</span></li>
<li><span class="math inline">\(p\)</span>は日照の有無と栄養素の量に影響される</li>
<li><span class="math inline">\(y_i\)</span>: 10粒のうち発芽した数</li>
<li><span class="math inline">\(x_{i1}\)</span>: 日が当たっていれば1、当たっていなければ0のダミー変数</li>
<li><span class="math inline">\(x_{i2}\)</span>: 栄養素の量</li>
<li><span class="math inline">\(logit(p_i)=\beta_0+\beta_1x_1+\beta_2x_2\)</span></li>
<li><span class="math inline">\(y\sim Binom(10,p_i)\)</span></li>
</ul></li>
<li>ロジット関数<span class="math inline">\(logit()\)</span>
<ul>
<li><span class="math inline">\(logit(p)+log(\frac{p}{1-p})\)</span></li>
</ul></li>
<li>ロジット関数の逆関数＝ロジスティック関数
<ul>
<li><span class="math inline">\(logistic(x)=\frac{1}{1+exp(-x)}\)</span></li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>x&lt;-seq(-10,10,0.01)
y&lt;-1/(1+exp(-x))
plot(x,y,type=&#39;l&#39;)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-38-1.png" width="768" /></p>
</div>
</div>
<div id="章-単回帰モデル" class="section level1">
<h1>3-2章: 単回帰モデル</h1>
<div id="分析の準備---8.-まとめ" class="section level2">
<h2>2. 分析の準備 - 8. まとめ</h2>
<ul>
<li>beerと気温の例の実施例</li>
</ul>
</div>
</div>
<div id="章-モデルを用いた予測" class="section level1">
<h1>3-3章: モデルを用いた予測</h1>
<div id="分析の準備-2" class="section level2">
<h2>2. 分析の準備</h2>
</div>
<div id="単回帰モデルにおける予測の考え方" class="section level2">
<h2>3. 単回帰モデルにおける予測の考え方</h2>
<ul>
<li>モデル: <span class="math inline">\(sales_i \sim Normal(Intercept + beta \times temperature_i, sigma^2)\)</span></li>
<li>モデル推定で切片とベータが分かっていれば、ある気温の売り上げを計算できる
<ul>
<li>ただし、その切片は単に「分布の代表値」</li>
</ul></li>
</ul>
</div>
<div id="予測のためのデータの整理" class="section level2">
<h2>4. 予測のためのデータの整理</h2>
<ul>
<li>予測したい気温のリストを作成</li>
</ul>
</div>
<div id="予測のためのstanファイルの修正" class="section level2">
<h2>5. 予測のためのStanファイルの修正</h2>
<ul>
<li>generated quantitiesブロックを作成
<ul>
<li>事後予測分布を取得</li>
</ul></li>
</ul>
</div>
<div id="mcmcの実行-1" class="section level2">
<h2>6. MCMCの実行</h2>
<ul>
<li>モデル推定と事後予測分布が得られる</li>
</ul>
</div>
<div id="予測分布の可視化" class="section level2">
<h2>7. 予測分布の可視化</h2>
<ul>
<li>beyesplotパッケージなどで図示
<ul>
<li>正規表現を使うための引数: regex_pars</li>
</ul></li>
<li>95%予測区間</li>
<li>予測分布</li>
</ul>
</div>
</div>
<div id="章-デザイン行列を用いた一般化線形モデルの推定" class="section level1">
<h1>3-4章: デザイン行列を用いた一般化線形モデルの推定</h1>
<div id="分析の準備-3" class="section level2">
<h2>2. 分析の準備</h2>
<ul>
<li>beerの例</li>
</ul>
<pre class="r"><code>library(rstan)
library(bayesplot)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

beerf&lt;-read.csv(&quot;3-2-1-beer-sales-2.csv&quot;)
sample_size &lt;- nrow(beer)</code></pre>
</div>
<div id="デザイン行列を使ったモデルの数学的な表現" class="section level2">
<h2>3. デザイン行列を使ったモデルの数学的な表現</h2>
<ul>
<li>ビールの売り上げ
<ul>
<li><span class="math inline">\(\mu_i = \beta_0 + \beta_1x_i\)</span></li>
<li><span class="math inline">\(y_i \sim Normal(\mu_i, \sigma^2)\)</span></li>
</ul></li>
<li>ここで期待値のベクトル<span class="math inline">\(\boldsymbol{\mu}\)</span>, デザイン行列<span class="math inline">\(\boldsymbol{X}\)</span>とすると、
<ul>
<li><span class="math inline">\(\boldsymbol{\mu} = \boldsymbol{X\beta}\)</span></li>
</ul></li>
</ul>
</div>
<div id="formula構文を用いたデザイン行列の作成" class="section level2">
<h2>4. formula構文を用いたデザイン行列の作成</h2>
<ul>
<li>formula記法</li>
<li><span class="math inline">\(formula(応答変数 \sim 説明変数)\)</span></li>
<li>model.matrix関数</li>
</ul>
<pre class="r"><code>flm &lt;- formula(sales ~ temperature)
X &lt;- model.matrix(flm, beerf)</code></pre>
</div>
<div id="デザイン行列を使うためのstanファイルの設定" class="section level2">
<h2>5. デザイン行列を使うためのStanファイルの設定</h2>
<ul>
<li>stanファイルを修正する</li>
</ul>
<pre class="stan"><code>data{
  int N;
  int K;
  vector[N] Y;
  matrix[N, K] X;
}

parameters{
  vector[K] b;
  real&lt;lower = 0&gt; sigma;
}

transformed parameters{
  vector[N] mu = X * b;
}

model{
  Y ~ normal(mu, sigma);
}</code></pre>
</div>
<div id="mcmcの実行-2" class="section level2">
<h2>6. MCMCの実行</h2>
<pre class="r"><code>N &lt;- nrow(beerf)
K &lt;- 2
Y &lt;- beerf$sales
dl &lt;- list(N = N, K = K, Y = Y, X = X)

res&lt;-rstan::sampling(beer_design, data=dl, seed=1)
print(res, probs = c(0.025, 0.5, 0.975))</code></pre>
<pre><code>## Inference for Stan model: 61434762f6b0fcc57b85a34f69371a85.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##            mean se_mean   sd    2.5%     50%   97.5% n_eff Rhat
## b[1]      20.78    0.17 5.89    9.31   20.74   32.27  1247    1
## b[2]       2.48    0.01 0.29    1.91    2.47    3.04  1245    1
## sigma     17.06    0.03 1.25   14.89   16.97   19.67  1514    1
## mu[1]     54.71    0.06 2.42   49.93   54.73   59.44  1670    1
## mu[2]     80.22    0.04 2.13   76.14   80.18   84.42  2926    1
## mu[3]     74.03    0.03 1.80   70.57   73.98   77.47  4418    1
## mu[4]     53.96    0.06 2.48   49.08   54.00   58.82  1632    1
## mu[5]     92.35    0.07 3.16   86.30   92.28   98.66  1805    1
## mu[6]     92.35    0.07 3.16   86.30   92.28   98.66  1805    1
## mu[7]     51.98    0.07 2.65   46.75   52.02   57.17  1548    1
## mu[8]     86.90    0.06 2.66   81.78   86.88   92.22  2101    1
## mu[9]     68.82    0.03 1.72   65.37   68.80   72.08  4166    1
## mu[10]    72.79    0.03 1.77   69.37   72.74   76.15  4592    1
## mu[11]    73.04    0.03 1.77   69.61   72.99   76.42  4560    1
## mu[12]    57.43    0.05 2.21   53.05   57.44   61.74  1856    1
## mu[13]    83.19    0.05 2.35   78.66   83.19   87.83  2461    1
## mu[14]    54.46    0.06 2.44   49.65   54.48   59.23  1657    1
## mu[15]    65.61    0.03 1.78   62.11   65.59   69.04  3239    1
## mu[16]    87.90    0.06 2.75   82.61   87.85   93.36  2031    1
## mu[17]    93.84    0.08 3.31   87.49   93.77  100.46  1752    1
## mu[18]    56.69    0.05 2.27   52.21   56.69   61.10  1797    1
## mu[19]    67.59    0.03 1.74   64.13   67.57   70.89  3815    1
## mu[20]    49.26    0.08 2.90   43.55   49.27   54.90  1465    1
## mu[21]    78.24    0.03 2.00   74.42   78.22   82.17  3370    1
## mu[22]    64.86    0.03 1.80   61.31   64.84   68.38  3041    1
## mu[23]    86.90    0.06 2.66   81.78   86.88   92.22  2101    1
## mu[24]    52.97    0.06 2.57   47.95   53.01   58.00  1587    1
## mu[25]    62.63    0.04 1.89   58.86   62.64   66.26  2548    1
## mu[26]    69.82    0.03 1.72   66.40   69.79   73.07  4401    1
## mu[27]    52.97    0.06 2.57   47.95   53.01   58.00  1587    1
## mu[28]    63.13    0.04 1.87   59.40   63.14   66.73  2644    1
## mu[29]    93.34    0.08 3.26   87.09   93.27   99.88  1768    1
## mu[30]    51.98    0.07 2.65   46.75   52.02   57.17  1548    1
## mu[31]    46.04    0.09 3.21   39.71   46.06   52.27  1399    1
## mu[32]    53.72    0.06 2.50   48.80   53.75   58.61  1620    1
## mu[33]    85.67    0.05 2.55   80.71   85.64   90.71  2201    1
## mu[34]    88.64    0.06 2.81   83.21   88.61   94.22  1985    1
## mu[35]    71.05    0.03 1.73   67.65   71.01   74.34  4614    1
## mu[36]    76.50    0.03 1.91   72.88   76.48   80.20  3867    1
## mu[37]    87.40    0.06 2.70   82.18   87.36   92.80  2065    1
## mu[38]    59.66    0.05 2.06   55.55   59.67   63.65  2084    1
## mu[39]    78.48    0.04 2.02   74.63   78.47   82.44  3311    1
## mu[40]    52.97    0.06 2.57   47.95   53.01   58.00  1587    1
## mu[41]    94.09    0.08 3.33   87.69   94.02  100.75  1743    1
## mu[42]    60.16    0.04 2.03   56.11   60.17   64.07  2147    1
## mu[43]    51.24    0.07 2.72   45.89   51.26   56.52  1522    1
## mu[44]    53.72    0.06 2.50   48.80   53.75   58.61  1620    1
## mu[45]    92.35    0.07 3.16   86.30   92.28   98.66  1805    1
## mu[46]    84.92    0.05 2.49   80.07   84.89   89.82  2270    1
## mu[47]    93.84    0.08 3.31   87.49   93.77  100.46  1752    1
## mu[48]    62.88    0.04 1.88   59.11   62.89   66.48  2595    1
## mu[49]    70.31    0.03 1.73   66.90   70.26   73.57  4507    1
## mu[50]    85.67    0.05 2.55   80.71   85.64   90.71  2201    1
## mu[51]    45.79    0.09 3.23   39.40   45.81   52.07  1395    1
## mu[52]    46.29    0.09 3.18   40.01   46.30   52.49  1403    1
## mu[53]    79.47    0.04 2.08   75.48   79.45   83.54  3083    1
## mu[54]    91.61    0.07 3.09   85.65   91.54   97.75  1835    1
## mu[55]    59.17    0.05 2.09   55.00   59.18   63.22  2026    1
## mu[56]    85.67    0.05 2.55   80.71   85.64   90.71  2201    1
## mu[57]    84.43    0.05 2.45   79.65   84.40   89.25  2320    1
## mu[58]    94.58    0.08 3.38   88.09   94.51  101.37  1728    1
## mu[59]    76.01    0.03 1.88   72.42   75.98   79.64  3987    1
## mu[60]    80.71    0.04 2.16   76.55   80.68   84.96  2829    1
## mu[61]    83.68    0.05 2.39   79.07   83.68   88.41  2401    1
## mu[62]    89.38    0.07 2.88   83.83   89.36   95.10  1942    1
## mu[63]    76.50    0.03 1.91   72.88   76.48   80.20  3867    1
## mu[64]    58.42    0.05 2.14   54.16   58.45   62.59  1947    1
## mu[65]    88.14    0.06 2.77   82.82   88.10   93.64  2015    1
## mu[66]    67.09    0.03 1.74   63.64   67.06   70.45  3668    1
## mu[67]    64.86    0.03 1.80   61.31   64.84   68.38  3041    1
## mu[68]    68.33    0.03 1.73   64.88   68.31   71.59  4031    1
## mu[69]    56.44    0.05 2.29   51.93   56.44   60.89  1779    1
## mu[70]    48.76    0.08 2.95   42.95   48.78   54.47  1453    1
## mu[71]    59.17    0.05 2.09   55.00   59.18   63.22  2026    1
## mu[72]    60.90    0.04 1.99   56.96   60.91   64.73  2253    1
## mu[73]    47.53    0.08 3.06   41.48   47.55   53.48  1426    1
## mu[74]    54.71    0.06 2.42   49.93   54.73   59.44  1670    1
## mu[75]    54.71    0.06 2.42   49.93   54.73   59.44  1670    1
## mu[76]    82.94    0.05 2.33   78.46   82.93   87.53  2492    1
## mu[77]    59.91    0.04 2.04   55.84   59.92   63.86  2115    1
## mu[78]    88.64    0.06 2.81   83.21   88.61   94.22  1985    1
## mu[79]    65.61    0.03 1.78   62.11   65.59   69.04  3239    1
## mu[80]    74.03    0.03 1.80   70.57   73.98   77.47  4418    1
## mu[81]    62.88    0.04 1.88   59.11   62.89   66.48  2595    1
## mu[82]    78.73    0.04 2.03   74.83   78.72   82.73  3252    1
## mu[83]    46.78    0.08 3.14   40.59   46.80   52.87  1412    1
## mu[84]    65.36    0.03 1.79   61.86   65.34   68.81  3171    1
## mu[85]    55.45    0.06 2.36   50.79   55.47   60.05  1714    1
## mu[86]    87.90    0.06 2.75   82.61   87.85   93.36  2031    1
## mu[87]    93.59    0.08 3.28   87.29   93.52  100.17  1760    1
## mu[88]    61.64    0.04 1.94   57.75   61.66   65.35  2372    1
## mu[89]    81.95    0.04 2.25   77.64   81.94   86.37  2628    1
## mu[90]    62.39    0.04 1.91   58.60   62.40   66.03  2502    1
## mu[91]    93.84    0.08 3.31   87.49   93.77  100.46  1752    1
## mu[92]    65.11    0.03 1.79   61.60   65.10   68.59  3106    1
## mu[93]    64.37    0.03 1.82   60.80   64.37   67.88  2919    1
## mu[94]    73.28    0.03 1.78   69.87   73.24   76.70  4531    1
## mu[95]    68.58    0.03 1.73   65.12   68.56   71.83  4099    1
## mu[96]    55.20    0.06 2.38   50.49   55.22   59.83  1699    1
## mu[97]    66.60    0.03 1.75   63.14   66.57   69.98  3522    1
## mu[98]    50.25    0.07 2.81   44.73   50.27   55.68  1492    1
## mu[99]    51.24    0.07 2.72   45.89   51.26   56.52  1522    1
## mu[100]   67.34    0.03 1.74   63.89   67.32   70.67  3742    1
## lp__    -330.17    0.04 1.26 -333.43 -329.85 -328.74  1154    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan 26 15:51:38 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
</div>
</div>
<div id="brmsの使い方" class="section level1">
<h1>3-5. brmsの使い方</h1>
<div id="brmsとは" class="section level2">
<h2>2. brmsとは</h2>
<ul>
<li>Stanを使ったベイジアン回帰モデル</li>
</ul>
</div>
<div id="本書での実装の方針" class="section level2">
<h2>3. 本書での実装の方針</h2>
</div>
<div id="分析の準備-4" class="section level2">
<h2>4. 分析の準備</h2>
<ul>
<li>brmsパッケージが必要</li>
</ul>
<pre class="r"><code>library(rstan)
library(brms)</code></pre>
<pre><code>##  要求されたパッケージ Rcpp をロード中です</code></pre>
<pre><code>## Loading &#39;brms&#39; package (version 2.16.3). Useful instructions
## can be found by typing help(&#39;brms&#39;). A more detailed introduction
## to the package is available through vignette(&#39;brms_overview&#39;).</code></pre>
<pre><code>## 
##  次のパッケージを付け加えます: &#39;brms&#39;</code></pre>
<pre><code>##  以下のオブジェクトは &#39;package:rstan&#39; からマスクされています: 
## 
##      loo</code></pre>
<pre><code>##  以下のオブジェクトは &#39;package:stats&#39; からマスクされています: 
## 
##      ar</code></pre>
<pre class="r"><code>rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

beersf&lt;-read.csv(&#39;3-2-1-beer-sales-2.csv&#39;)</code></pre>
</div>
<div id="brmsによる単回帰モデルの推定" class="section level2">
<h2>5. brmsによる単回帰モデルの推定</h2>
<ul>
<li>Stanファイル不要</li>
<li>指定が必要なもの
<ul>
<li>線形予測子</li>
<li>確率分布</li>
<li>リンク関数</li>
</ul></li>
<li>結果
<ul>
<li>切片、係数</li>
<li>Estimate: 点推定値</li>
</ul></li>
<li>as.mcmc(): MCMCサンプル取得</li>
<li>plot(): 事後分布、トレースプロットの図示</li>
</ul>
<pre class="r"><code>lm_brms&lt;-brm(
  formula = sales ~ temperature,
  family = gaussian(link=&#39;identity&#39;),
  data = beersf,
  seed = 1
)</code></pre>
<pre><code>## Compiling Stan program...</code></pre>
<pre><code>## Trying to compile a simple C file</code></pre>
<pre><code>## Running /usr/local/Cellar/r/4.1.2/lib/R/bin/R CMD SHLIB foo.c
## clang -I&quot;/usr/local/Cellar/r/4.1.2/lib/R/include&quot; -DNDEBUG   -I&quot;/usr/local/lib/R/4.1/site-library/Rcpp/include/&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/RcppEigen/include/&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/RcppEigen/include/unsupported&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/BH/include&quot; -I&quot;/Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/src/&quot;  -I&quot;/Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/RcppParallel/include/&quot;  -I&quot;/Users/imaru/Library/R/x86_64/4.1/library/rstan/include&quot; -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include &#39;/Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp&#39;  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/opt/gettext/include -I/usr/local/opt/readline/include -I/usr/local/opt/xz/include -I/usr/local/include -I/usr/local/opt/tbb/include   -fPIC  -Wno-implicit-function-declaration  -c foo.c -o foo.o
## In file included from &lt;built-in&gt;:1:
## In file included from /Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:
## In file included from /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Dense:1:
## In file included from /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Core:88:
## /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name &#39;namespace&#39;
## namespace Eigen {
## ^
## /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected &#39;;&#39; after top level declarator
## namespace Eigen {
##                ^
##                ;
## In file included from &lt;built-in&gt;:1:
## In file included from /Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:
## In file included from /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Dense:1:
## /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Core:96:10: fatal error: &#39;complex&#39; file not found
## #include &lt;complex&gt;
##          ^~~~~~~~~
## 3 errors generated.
## make: *** [foo.o] Error 1</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code>print(lm_brms)</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: sales ~ temperature 
##    Data: beersf (Number of observations: 100) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      21.24      6.05     9.47    33.16 1.00     3658     2784
## temperature     2.46      0.29     1.89     3.01 1.00     3850     3069
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    17.02      1.24    14.82    19.63 1.00     4060     3003
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># as.mcmc(lm_brms, combine_chains = TRUE)
plot(lm_brms)</code></pre>
<p><img src="baba_files/figure-html/unnamed-chunk-43-1.png" width="768" /></p>
</div>
<div id="brmsの基本的な使い方" class="section level2">
<h2>6. brmsの基本的な使い方</h2>
<ul>
<li>bf(): formulaをbrmの外で定義可能
<ul>
<li>lm_formula &lt;- bf(sales ~ temperature) など</li>
</ul></li>
<li>familyに使える分布
<ul>
<li>gaussian()</li>
<li>binomial()</li>
<li>poisson()</li>
<li>などなど</li>
<li>Rで関数実行すると標準で指定されているlink関数が表示される</li>
</ul></li>
</ul>
</div>
<div id="事前分布の変更" class="section level2">
<h2>7. 事前分布の変更</h2>
<ul>
<li>prior_summary(): 事前分布一覧の表示</li>
</ul>
<pre class="r"><code>prior_summary(lm_brms)</code></pre>
<pre><code>##                   prior     class        coef group resp dpar nlpar bound
##                  (flat)         b                                        
##                  (flat)         b temperature                            
##  student_t(3, 71.5, 20) Intercept                                        
##     student_t(3, 0, 20)     sigma                                        
##        source
##       default
##  (vectorized)
##       default
##       default</code></pre>
<ul>
<li>一覧
<ul>
<li>flatは一様分布?</li>
<li>切片には自由度3、中心位置71.5、分布の裾の広さ20のstudent t分布を使ってるということ</li>
<li>sigmaの分布は中心0、広さ20</li>
</ul></li>
<li>事前分布を変更したい場合</li>
</ul>
<pre class="r"><code>lm_brms2 &lt;- brm(
  formula=sales~temperature,
  family = gaussian(),
  data = beersf,
  seed = 1,
  prior=c(set_prior(&quot;&quot;,class=&quot;Intercept&quot;),
          set_prior(&quot;&quot;,class=&quot;sigma&quot;))
)</code></pre>
<pre><code>## Compiling Stan program...</code></pre>
<pre><code>## Trying to compile a simple C file</code></pre>
<pre><code>## Running /usr/local/Cellar/r/4.1.2/lib/R/bin/R CMD SHLIB foo.c
## clang -I&quot;/usr/local/Cellar/r/4.1.2/lib/R/include&quot; -DNDEBUG   -I&quot;/usr/local/lib/R/4.1/site-library/Rcpp/include/&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/RcppEigen/include/&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/RcppEigen/include/unsupported&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/BH/include&quot; -I&quot;/Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/src/&quot;  -I&quot;/Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/&quot;  -I&quot;/usr/local/lib/R/4.1/site-library/RcppParallel/include/&quot;  -I&quot;/Users/imaru/Library/R/x86_64/4.1/library/rstan/include&quot; -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include &#39;/Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp&#39;  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/opt/gettext/include -I/usr/local/opt/readline/include -I/usr/local/opt/xz/include -I/usr/local/include -I/usr/local/opt/tbb/include   -fPIC  -Wno-implicit-function-declaration  -c foo.c -o foo.o
## In file included from &lt;built-in&gt;:1:
## In file included from /Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:
## In file included from /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Dense:1:
## In file included from /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Core:88:
## /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name &#39;namespace&#39;
## namespace Eigen {
## ^
## /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected &#39;;&#39; after top level declarator
## namespace Eigen {
##                ^
##                ;
## In file included from &lt;built-in&gt;:1:
## In file included from /Users/imaru/Library/R/x86_64/4.1/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:
## In file included from /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Dense:1:
## /usr/local/lib/R/4.1/site-library/RcppEigen/include/Eigen/Core:96:10: fatal error: &#39;complex&#39; file not found
## #include &lt;complex&gt;
##          ^~~~~~~~~
## 3 errors generated.
## make: *** [foo.o] Error 1</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="r"><code>prior_summary(lm_brms2)</code></pre>
<pre><code>##   prior     class        coef group resp dpar nlpar bound       source
##  (flat)         b                                              default
##  (flat)         b temperature                             (vectorized)
##  (flat) Intercept                                                 user
##  (flat)     sigma                                                 user</code></pre>
<ul>
<li>stanコードの抽出
<ul>
<li>stancode(lm_brms2)</li>
</ul></li>
<li>データの抽出
<ul>
<li>standata(lm_brms2)</li>
</ul></li>
</ul>
</div>
<div id="補足brmsの基本的な仕組み" class="section level2">
<h2>8. 補足：brmsの基本的な仕組み</h2>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>一定の条件に関する<a href="https://www.amazon.co.jp/dp/400730789X">文献</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
</div>

   
   
              </div>
  </div>
  </div>
  </div>
   
      

  <script>
    $(document).ready(function () {

		// add bootstrap table styles to pandoc tables
	$('tr.header').parent('thead').parent('table').addClass('table table-condensed');
		
 		
	    });
  </script>



    <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
	var script = document.createElement("script");
	script.type = "text/javascript";
	script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
	document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>
  
</body>
</html>
