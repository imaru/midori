---
title: "midori4"
author: "Toshihide Imaruoka"
date: "6/14/2022"
output:
  rmdformats::downcute:
    highlight: kate
    css: mycss.css
    dev: "ragg_png"
---
# 4. GLMのモデル選択--AICとモデルの予測の良さ--
  * 良いモデルはあてはまりの良いモデルではない
    * 複雑なモデルほど当てはまるから
    * あまりにパラメータが多いモデルはおそらく妥当ではない
  * モデル選択
    * 複数の統計モデルから「良い」モデルを選ぶ
    * いろいろな方法＝基準
  * AICというモデル選択基準
    * 良い予測をするモデルが良いモデル
    * ×当てはまりの良さに基づく選択
  * 4.3までで一応の説明
  * 4.4以降は難易度高い（飛ばしてもOK）
  
## 4.1 データは一つ、モデルはたくさん
  * 第3章のデータ
    * 種子数と体サイズと施肥処理
  * モデル
    * 体サイズが影響するモデル($y\sim x$)<-glm()の第1引数
    * 施肥処理が影響するモデル($y\sim f$)
    * 体サイズと施肥処理が影響するモデル（$y\sim x+f$)
    * 一定モデル($f\sim 1$)
  * 3章では対数尤度を最大にするパラメータを求め、そのパラメータに対する対数尤度＝最大対数尤度が当てはまりの良さだとした
    * 最大対数尤度をもっとも大きいモデルが良いモデル？
    * そうではない、という話。
    
## 4.2 統計モデルのあてはまりの悪さ：逸脱度
  * 逸脱度(deviance)
    * 最大対数尤度を変形した統計量
    * 対数尤度：$logL({\beta_j})$←あるパラメータ$\beta_j$のときの対数尤度。簡単のため$logL$と表す
    * 最大対数尤度：$logL$を最大にするパラメータ$\beta_j$のときの$logL$：$logL^*$とする
    * 逸脱度D
      * $D=-2logL^*$
  * ここから例
    * 体サイズだけのモデルをxモデルと呼ぶ
      * xモデルの最大対数尤度$logL^*$は-235.4
      * D=470.8
    * glm()の結果にこんな値はない。どこにいった？
    
```{r}
dat<-read.csv('kubobook_2012-2/poisson/data3a.csv')
dat$f<-as.factor(dat$f)
f.x<-glm(y~x, data=dat, family=poisson)
print(f.x)
logLik(f.x)
D.x<-logLik(f.x)[1]*-2
print(D.x)
```
   
  * 表示されてるのは以下のような値
    * Null Deviance 
    * Residual Deviance
    * AIC
  * まずはResidual Deviance（残差逸脱度）の説明
    * 残差逸脱度＝逸脱度$D$-（ポアソン分布モデルで可能な最小逸脱度）
    * 最小逸脱度：最多のパラメータを使った作ったモデル
      * データ100個の場合、パラメータ100個とする（意味はない）
      * 意味はないけど、当てはまりは良い
      * 最大対数尤度を計算
        * dpois(dat$y[1], dat\$y[1])は、データがポアソン分布に従っているとして、ラムダがdat\$y[1]のときに、データがdat\$y[1]である確率のこと（0.16くらいになる）
        * データとパラメータが一致するので、これは考えられる中で最も高い確率。
        * その対数を全データ（100個）分足した数
        * これは他のどんなモデルよりも小さくなるはず（確率は大きいけど対数を取るから小さい）
        * これがポアソン分布で可能な最小逸脱度（今の場合、下の計算のように385.8くらいになる
        * xモデルのD（470.8）と最小逸脱度（385.8）の差が、xモデルの残差逸脱度（84.993）
      
```{r}
D.min<-sum(log(dpois(dat$y, lambda=dat$y))) * -2
D.x-D.min
```

  * 残差逸脱度：最小逸脱度を基準にした、あてはまりの悪さの相対値
  * 次に最大の逸脱度について考えてみる（図4.3の一番上）
    * もっとも当てはまりの悪いモデルのときに逸脱度は最大のはず
    * 切片だけで作られたモデルがそれにあたる
    * 最大の逸脱度は475.3くらいで、最小との差は89.5くらい
      * これがNull Deviance
  * このあたりのまとめ：表4.2
    * パラメータが増えるとあてはまりが良い
    
```{r}
f.null<-glm(y~1, data=dat, family=poisson)
print(f.null)
print(logLik(f.null)[1]*-2-D.min) # このモデルの逸脱度とフルモデルの逸脱度の差
```

## 4.3 モデル選択基準AIC
  * モデルのあてはまりが良くても、パラメータが多いと「今の」データへの特殊化をしているだけかも
    * 予測の良さを損なうかも
  * AIC: モデル選択基準の一つ
    * 予測の良さを重視するモデル選択基準
    * $AIC = -2\{(最大対数尤度)-(最尤推定したパラメータ数)\}$
      * = $-2(logL^*-k)$
      * = $D+2k$
        * $logL^*$は-D/2だから($D=-2logL^*$ p71)
    * これで計算するとxモデルがAIC最小となる（表4.3）

## 4.4 AICを説明するためのまた別の例題
  * 新しい架空データ
    * 個体$i$の種子数$y_i$と体サイズ$x_i$が50個体分
    * 応答変数$y_i$、説明変数$x_i$
    * ただし$x_i$は$y_i$とは関係なし
  * 次のようなモデルを比較
    * $log\lambda_i=\beta_1$ -- 一定モデル($k=1$)
    * $log\lambda_i=\beta_1+\beta_2x_i$ -- xモデル($k=2$)
      * ちなみに、この2つのモデルはネストしている(nested)

## 4.5 なぜAICでモデル選択してよいのか？
  * 平均対数尤度：統計モデルの予測の良さ
  * バイアス補正とは？
  
### 4.5.1 統計モデルの予測の良さ：平均対数尤度
  * ここでは、一定モデルを使って平均対数尤度を説明
    * 平均種子数$\lambda_i=exp\beta_1$
    * 最尤推定法によって、対数尤度が最大となる$\hat{\beta}_1$を求める
      * $\hat{\beta}_1$=2.04
    * 真のパラメータは2.08だった（$\lambda=8; log8=2.08$)
    * 図4.6：真のモデルからデータを生成し、データからパラメータ推定
      * 最大対数尤度$logL^*$は観測データに対する当てはまりの良さで、真のモデルに対するものではない
    * 「あてはまりの良さ」は、たまたまその時にあるデータに対するもの
    * モデルが、次に真のモデルから生成されたデータをどれくらい予測できるか、なら良さそう
    * 今の例題では真のモデルが分かってるので、予測の良さ評価用のデータを作ってやってみる
      * 真のモデルに200セット生成させる
      * それぞれに対する一定モデル($\hat{\beta_1}=2.04$)の当てはまりの良さを対数尤度で評価、平均する＝平均対数尤度＝$E(logL)$
        * パラメータ2.04は最初の1データを元に決め、その当てはまりの良さを同じデータで評価したもの（そういう決め方だから当たり前のことを言ってる）
        * でも、最初の1データは真のモデルからたまたま生成されたものだから、それだけで評価してはいけない
        * だから、別のデータも評価して、その平均($E(logL)$)を出そう、ということ。
      
### 4.5.2 最大対数尤度のバイアス補正
  * そういうことを12回繰り返す（図4.9(B)）
  * たまたまデータへの$logL^*$と$E(logL)$の大小関係はばらばら
    * この関係に関する分布を考えるため、$b=logL^*-E(logL)$を定義＝バイアス
  * バイアスbの分布は図4.10、平均1.01
* 予測用のデータをたくさん作ってやってみたら、「たまたま」のデータで評価した最大対数尤度よりも1程度大きくなることが分かった
  * この$E(logL)$はモデルの良さの指標として使えそうな気がする。
  * $E(logL)=logL^*-1$と言えそうなので、そうすればいいのでは＝バイアス補正
    * この、今の計算でバイアスが1となったのは、偶然ではなく、解析的にも導出できるらしい（平均対数尤度＝$logL^*-k$ kはパラメータ数；文献が引用されている）
    * これに-2をかけたものがAIC＝予測の悪さ
        
### 4.5.3 ネストしているGLM間のAIC比較
  * ネストしてるモデル間の比較について
  * AICが小さい方を選ぶというのが基本的な考え方（平均対数尤度$E(logL)$＝平均的な予測の良さに-2をかけたものがAICだから）
  * ただ、前の節で$E(logL)$を出したときに使った平均バイアスを求めるときのばらつきが大きかったのが気になる（図4.10：$logL^*とE(logL)の差が結構ばらつくということ$）
    * この「気になる」に対して、ネストしてるモデル間の比較ではバイアスのばらつきは小さいよということを示そうとしている
  * さっきの一定モデルとxモデルをAICで比較してみる
    * 一定モデルは$k=1$, xモデルは$k=2$（体サイズのパラメータが増えてる）
    * 増えた変数は結果に影響しないことが分かってるので、AICは2くらい大きくなる（$-2\times -k$)＝2くらい予測が悪化するはず
    * 以下、考え方の流れ
      * まず、最大対数尤度（＝「たまたま」データとの当てはまりの良さ）の比較（図4.11(A)）
        * 実際に計算してみると$xモデルのlogL^*-一定モデルのlogL^*$の平均は0.54
        * 変数を増やし、パラメータを増やしたことであてはまりの良さは良くなってしまう（無関係の変数だから良くなるはずがない＝とにかくパラメータを増やせば、「たまたま」データとの当てはまりはどんどん良くなる可能性がある）
      * 次に平均対数尤度（＝予測の良さ）を比較（図4.11(B)）
        * 今度は$xモデルのE(logL)-一定モデルのE(logL)$の平均値は-0.54
        * パラメータを増やしたことで予測が悪くなった
      * さらに一定モデルのバイアス(b)とxモデルのバイアス(b)の差の分布をみる（図4.12）
        * $xモデルのlogL^*-E(logL)-(一定モデルのlogL^*-E(logL))$（図4.13）
        * 0.54-(-0.54)なので1.08くらいになる
        * 図4.12にあるように、バイアス差の分布はあまり大きくならない＝AIC使ってもいいんじゃない？という話
  * じゃあ、無意味じゃない変数（モデルではパラメータ）を増やしたときには？
    * 図4.14を読む
      * 当てはまりの良さ（白い円）も良くなるけど、AIC（グレイ）も良くなる

## 4.6 この章のまとめと参考文献
  * 複数のモデルから最適なものを選ぶとき、当てはまりの良さ（$logL^*$)でいいか？
  * この章では当てはまりの良さではなく逸脱度$D=-2\times logL^*$で考えた
  * 意味のない変数の追加でも$logL^*$は小さくなってしまう
  * AICは$E(logL)=logL^*-b$をもとにしている。バイアス補正してるのが大きい。
  * AICに関する誤解
    * あてはまりの良さの指標ではない
    * 真のモデルを選べるわけでもない（真のモデルよりパラメータが少ないモデルを選ぶことがある）
    * FAQは[サポートサイト](https://kuboweb.github.io/-kubo/ce/FaqModelSelection.html)まで